# Codex CLI SpecKit 10X AI Coding

Published: 2025-10-02

Codeex CLI or Claude Code, a showdown to rival Pepsi and Coke, Microsoft and Apple, or if the Eagles could have just flown Frodo to Mount Doom in Lord of the Rings. Well, whatever side of those arguments you land on, GitHub's speech kit is sure to please. So, if you're new to the world of AIdriven coding, or even if you just struggle from time to time, spec driven development should be your new best friend because I've heard a lot of feedback from the AI coding universe that a lot of the times things don't just turn out the way that you would hope they would. And in my experience, that almost always comes back to how you plan and execute through that plan. which is why 20% of the videos on my channel are about vibe planning specifically. So, in this video, I'm going to show you how you can realistically 10x your output with one free tool. So, we'll break down each of SpecKit's five steps, execute them in order, and show how each stage feeds into the next one, and we're going to do it all with Codeex CLI. So again, this system is really going to be great for you if you're trying to build cool stuff, but you just feel that your systems are a little too janky to ever finalize a complete thing. So like I said, we're going to be running this project with Codeex CLI, which is a coding agent from OpenAI, which runs on your computer, much like Claw Code or Gemini CLI. Now, the reason I'm showing this with this tool specifically is that in AI coding or vibe coding or context engineering or whatever it is that you want to call it, the biggest blocker that you will hit is when it gets down to large multifile operations that rely on a lot of context to be done properly. And doing this well can be a major challenge even in a tool like Claude Code, which in my opinion does this the best out of the box. And I'm sure you've seen this in your projects before where you give it a prompt that is pretty detailed, relatively speaking, but it still messes up the execution sometimes in pretty big ways. You might say, "Hey, I need to build this new feature that does this thing and just go integrate it into my existing backend and then next thing you know, it's off the rails and it didn't really do what you wanted it to do and it didn't necessarily do it the way you wanted it done." And so with Codeex CLI, things are really no different. it can handle like individual tasks like creating this file for example pretty well but orchestrating meaningful changes across all of your files that's where things tend to fall apart especially for beginners or even intermediate level. So the challenge then if we can overcome this everything changes for you and in my experience spec driven development really does help us overcome those challenges. So the solution here, we want to use the power of a tool like codec CLI within the framework of GitHub's spec kit. So let's get in and do that. Now step number one is obviously getting this downloaded on your computer, which I have another video where I go through spec kit and show that. So I'm not going to do that right here. I'm going to assume that you have codeex or cloud code or whatever and that you also have the spec kit installed on your computer. So from there, the first stage of this process is to specify what it is that we want to build on a high level. So we'll start off by spinning up codeex. And now with speckit, the way that you do this in every other tool except for codeex is with a slash command. So you would come in here and you would type in slashsp specify and then tell it what you want to do and it would go out and do it. The problem with codeex is that right now it does not support slash commands. So, I'm going to show you how to do it a different way. Now, what we're going to do instead is we're going to type in mention. And so, then when we go up into our codeex directory in this example inside of prompts, we're going to see that we have all of these prompts that were generated when we installed this. And so, the one that we want to reference is the one called specify.mmarkdown. And so, I'm going to come in here. I'm going to type in specify.md. And now we're effectively slashcomanding that file and we can pass in arguments. So, what are we going to build in this example? So in this case, we are working inside of an existing project that I have where people store prompts and then I'm starting to add in feature by feature where we can use language models in order to like improve prompts, improve agent definitions, do research, make them generally better over time. And so what I want to do for this feature is I want to make it so that I can highlight over specific pieces of this prompt like this chunk for example and pass that in as context to a language model and then have the language model actually improve that piece of context. So it's basically a prompt improvement system is going to be like the MVP of this feature. And then once that's set up and we have like the agent orchestration going on and all that stuff, then we can go in and start adding in all of the other features like a research agent and other things we might want to have. So we can see I've typed out here what I want it to do. So it's an agentic improver which in the beginning it's just going to be a simple request to the language model. So, it's not really going to be an agent. And it operates inside of that prompt editing view we were looking at. And it allows the users to highlight sections of the markdown text. And then it passes that through to OpenAI in order to improve the prompt. It returns it returns the updated prompt in its entirety. So, we can hit go. And now what it's going to do is it's going to go out. It's going to use all of the tools, the scripts, the templates that were downloaded with this repository when you downloaded it from GitHub. and it is going to build out a specification of what we intend to build and then from there we will take it to the next stage. So now the thing to keep in mind as this thing's processing in the background is that it is leveraging the power of whatever coding tool you're using. So in this case it is using the power of codeex and codeex's coding model specifically to perform all of these tasks. And so really what we're doing with the GitHub spec kit is we just have a lot of intelligent like prompts and definitions and templates that are being passed to the system but at the end of the day it's still using the power of whatever coding model you provide to perform the ask. Okay, so this thing just finished running and now we'll notice we have this directory called specs. In my case, I've run this a few times in this project. So, I'm on to my third definition. And so, if we go into our spec.markdown, we're going to see that we have a specification for this specific feature with a little bit of instruction as to like what is this thing and what should you consider with it. Now, what we're going to notice is we get down here and we have this section for clarifications. And what this means is there are some ambiguities in the feature you want to build. A good example of this might be, you know, what happens if you have two different users with the same permission levels trying to highlight the same piece of text at the same time? Or do you want to have like a preview feature before this gets sent off? And is it really important that the actual like XML formatting is preserved? These are all very important questions for this feature that if we weren't using a tool like this, we probably would have just gone out and said, "Hey, go build this feature that does this thing." and it would have just made assumptions. And so that is ultimately what we are avoiding here. And then we get down and we can look through all of the user stories we have. Now, for purposes of this video, I'm not going to read through each one and its edge cases, but basically what we're saying is what needs to be true for us to consider that we've built this thing properly. That's basically what our acceptance scenarios are. Then we talk about some edge cases, how they should be handled. And then what are all of the different functional requirements, the different entities that we're going to need to interact with or create and so on now the obvious thing here is that well we need to clarify these features, right? And so what we do is we open up our terminal and then again we're going to use this workaround for mentioning the file and I believe it's called clarify.markdown which it is. So, we're going to run that command. And what's happening now is it read that spec file and it is asking us questions about the areas that it needed clarification for. And it's even giving us potential solutions. So, for example, can the user like highlight five different sections at the same time and send them all through or only one by one? Now, again, it gives us three options ABC or kind of alternate which is you can provide your own option. For my purposes in this, I I think I specifically want to do option C. So, I'm going to say C. And now, what it's going to do is it's going to go through and it's going to update our project specification knowing that this is how it's going to handle that specific situation and it's going to update the functional requirements. And now it's going to repeat this process for every question that it had. So, I will go through and just answer these quickly and then we'll hop into the next step. Okay. Okay. So at this step what we can do is we continue we can continue to go back through and address anything that it considers as still outstanding. So an example of that might be how are we going to handle like rate limiting as an example. Again for purposes of this I'm not going to go through that. And so we would proceed to the next step which would be mentioning in this case our plan.Mmarkdown file. And so in this section, the thing you want to do is give any important details primarily as it pertains to like the tech that you're using. So I like to just remind it that in fact this is a Nex.js application and I want you to use OpenAI as the primary language model interface for like doing these updates. Outside of that, there's not really much other tech that is going to be new here. It's going to be leveraging things we already have in place. So, I'm not super worried about specifying things out in extreme detail. The one thing that I did add in here, and I'm curious how it's going to handle this actually because I normally do this in the previous stage. So, we will see together how that goes. I'm asking it to add functionality where the user can choose between two or three popular models from OpenAI depending on the complexity of what they want to do. So, if it's a really basic ask, maybe they're going to use a basic model. But if they're doing something that's going to require a lot of thinking, they can actually choose a more expensive model. And then the last thing, because a few of these functionalities, I already have some things in place for them. And so I want to make sure that it just refactors components to be reusable when it can instead of creating new components that are just basically duplicates of code I've already done. So after we have all that specified, we're just going to hit go and we're going to let it run. Now, the thing that's cool about this is it goes through a multi-step process when it's planning. So, it does research about this topic and the tech choices that you're making. It creates our data models. It tells the system how to actually get started with using this feature. And it builds out an API contract ahead of time so that the front end knows what the back end expects and the backend knows what the front end expects back. So, this is pretty cool. And this is one of the things that really helps make this like a bulletproof system. Now, while this is running, I'm going to go and I'm going to kick off a new terminal. And the reason that I'm doing this is that there's one other stage that you technically should be running before you get deep into the planning. And that stage is constitution. Okay? So, constitution is basically creating the principles and guidelines that everything needs to follow. So if you have specific tech conventions, ways that like your APIs work, coding conventions, all of that important type of stuff, you should obviously specify all of that. And so we do that by running this slash constitution command. And technically this should be done first in the process, but hey, sometimes we do things out of order. So we are going to go back and we're just going to run that. Let that thing run through. And then once we have our plan, we will reference the plan against the constitution to make sure that we're still following the conventions that we should be following. So now that the plan is finished, what we can see is we have a lot of different files getting created and we're going to go look at them. So the first is the research, right? Because we told it we want to use OpenAI. And so it's going to go and it's going to look at the different models that it has access to and then like I asked it to, it's going to research, well, what are the three models then that the users should have access to? So, it'll give you the decision, the rationale behind why it thinks that was a good decision, and then what other alternatives did it consider in that decision it was making, and it's going to continue that process for all of the major things that it needs to create. Right? So, inside of my project, I have something called a code mirror, and it's going to research that and make sure that it it's valid relative to this plan that we're making and that there's not something else we should be using. So, it's going to go through, it's going to do that in pretty decent detail. It's then going to go through and create all of our data models, which I think is something a lot of people tend to struggle with is the backend, right? Like you create all this front-end stuff and then you start trying to send requests through to the back end and you start getting all of these key violations and you're needing to do a bunch of migrations now and you don't really understand how they work and it can become a little bit of a nightmare. And so we have all of the major tables and what the different columns and what all the different columns in those tables are going to be. And then the API contract that's specifying like, hey, we're going to make a get request to this endpoint. We make a post request to this endpoint. This is what it does. And then all of the different data schemas that it accepts and sends back as a response. And so this is key because when we go to build the front end, there isn't guesswork, right? The backend is already validated as far as what it's expecting and how that's going to work with the backend code. And now the front end is just going to go use that code. And then like I said, we have the quick start guide just showing it. Here's how you do your migrations and everything else that you might need to do. And so from there, we have our plan, right? We have a very clear plan. The next step becomes, well, we now need to now break that plan down into individualized tasks that can be executed on. And so now going back to that first step, which again if you're starting with an existing project, very valuable to do if it's a net new project, not as important if you miss it in the beginning because you haven't actually built anything or any conventions yet, but it can be helpful still to run so that you have base principles that you're starting from. But now that it's gone through and created all of these principles for us about for example how you can access the schema how the prompt ledger workflows actually work all these things that we have in our project that are important principles to conform to. I'm just going to go back and have the plan updated which is not a step that you would need to do if you had done this the first time. Okay. So now that we have all of that taken care of I'm just going to compact down the context real quick and then we're going to move into the task generation. Now, all we need to do again to do this is to just use our mention workaround task.markdown and we're going to tell it to run the workflow inside the prompt. Now, again, what's cool about this is it is taking all of the other files that we created. So, it's looking at the plan, it's looking at the data models, it's looking at the research we did, the quick start guide, everything that we have done so far, it is pulling into this stage so that it has a high degree of fidelity to our original plan. So now that this process is done, we have an entire phase byphase setup and task list to get this feature done. Now the thing that's pretty cool is we get these flags on some of these tasks that have a P in them. And what this means is that the system, if it supports it, can run all of these at the same time. So for example, if we were going to build tests that work on an individual file, there's really no harm in running them at the same time. you don't have to worry about them making the same change to the same file or different changes rather to the same file and that messing something up. So, it's pretty cool and it allows us to get through things a lot more quickly. So, now we have this giant task list. What do we do next? So, we really have two options here. Number one, again, if we were using the built-in system, we could just run slashimplement or in this case, we would have to mention the file implement and we could just run this and it will go through and actually manage running through the entire list. The other option is that we could actually just go task by task through that list and tell it to process it in phases if we wanted to be a little bit more dialed in about exactly what it was doing and what was happening at each stage. Now, a question I get from a lot of people before we run that is what do we do about all these other like agent definitions and other prompts that are pretty awesome that we've used in other videos. So, for example, for like building the UX in the UI to our actual standards. And if you want a a link to these prompts and these agent definitions, they're in the group below or sorry, they're in the link below in the description. And then I'll also have the video linked somewhere around here where you can see how we use these things. But what you can do is you can just come through here for example for our UX design philosophy and UX principles. We can come through and copy these and then this file actually accepts arguments. So we can say hey go run this file right the workflow in this file with the additional context below. And then we can actually just paste in what all of those standards were and it will integrate that in when it runs it. Or we could actually leave those in our repository and reference the file and say, "Hey, these are my UX guidelines. Reference these before you build anything that's touching the actual UI." So, we can hit go on that and let it go do its thing. All right, guys. So, it's the next day. We just let this full task implementation run through. There was a tiny bit of back and forth. I probably spent 15 minutes debugging a small little thing here that I will show you. But, let's look at what this built. So when we click into edit, we now have this section that popped up here where we can, you know, select the model that we want and then we have this option to run the improvement. And so I have a a prompt here which is like an older version of a product manager prompt. And the issue we ran into is that this highlight wasn't working. And so I had to go back and forth a little bit to be honest to get this to work. But now that we've done that, we can highlight a section and then it kind of retains it in this purple font styling. Now we can go and we can say we want to preview the improvement. And so we get this nice little UI that it's generating so we know that something is going on. And then bam, it pops back and it has exactly what we were asking it for. So we have the old prompt on the lefth hand side and then the new prompt on the right hand side. And we can see, I mean, it cut a good amount out in making this optimization. And then we can get a nice little preview of what the the improved selection actually looks like. Now, the only thing that is missing from this right now that we're going to go look at is that there's not actually a button to save that update. So, it's showing us the update, but it's not actually letting us make that update. So, that is what we are going to go do. So, we're going to pop back into codeex here and we're going to just tell it exactly that. So, that's what we're going to tell them. The change preview function is working fine, but it doesn't actually have any capacity to to save it right now. And we should have built all that with our backend endpoint. So, I'm just going to reference over here the plan that we had built out inside of SpecKit. And then we are going to let this thing go build. All right, guys. So, it looks like it actually was there the entire time. The solution was inside of us the entire time. So, if we go up and we go to preview improvement, what was happening was that my my screen was zoomed in too much. And so, once this generates, look, it looked like it wasn't there, but if you zoom out, it is there. Now, obviously, this is like a styling thing that we would need to come through and and fix and resolve, which I'm going to do, but at the end of the day, it is in fact here. So, that is that is good. So yeah, really concrete example of how we can use a tool like specket to move through and build a I mean somewhat meaningful existing feature into an application without breaking stuff. So that's it guys, a really nice straightforward system for integrating spec driven development into an existing project or you could even use this for a net new project. So my challenge to you try this out in one of your projects and let me know how it goes because the sky is the limit. And if you want feedback on what you're building, we have a free group down below in the description where people share every day almost what they are working on, asking for feedback, giving feedback. It's a great place to build your network, learn alongside other people trying to do the same thing, and honestly get traction and initial users even for some of your projects. Who doesn't want that? And oh yeah, while I'm at it, if you like practical stuff like this, make sure to drop me a subscription so that your feed becomes filled with practical tutorials that actually work in real life. So that's it for this video. I will see you in the next