# Eric Schmidt AI Biggest Threats

Published: 2025-11-11

Is America going to win the AI race? >> There are three obvious threats right now. >> Is China winning the global race to develop artificial intelligence technology? >> So, how far ahead of China do you think we are? >> Overall, I would say >> China put in 172 gawatt of solar last year, I think is the number. It's remarkable. We needed in our calculation by 2030 92 gawatt to be built. A big nuclear power plant is somewhere between 1 and 1 1/2 gawatt. The country needs more energy. And if we don't get more energy, we're not going to be able to fully exploit the lead we have in AI and AGI. It's very clear. It's probably the case that >> now that's a moonshot, ladies and gentlemen. >> Hey everybody, welcome to part two of Eric Schmidt week on moonshots. In this episode, my moonshot mate Dave Blondon is interviewing Eric Schmidt about US versus China and how to avoid crisis during this period of hyperexponential growth in AI. A heads up, uh, this this audio recording from Eric is a little bit choppy. He was on Wi-Fi from his hotel room, but guarantee you the content is valuable, so please listen in. And also, this was recorded about a month ago. It took us a while to get the footage out to all of you. All right, let's jump in this episode with Dave Blondon and Eric Schmidt. So, why don't I start you with uh is America going to win the AI race? Because I know that's a topic that you've spoken on quite a bit. It's also addressed a little bit in your new book, Genesis, AI, Hope, uh and the human spirit, uh which hopefully everybody will read, uh with Henry Kissinger, actually as a co-author. So, uh are we going to win the AI race? And you know what are the scenarios where we win and lose? >> It looks like we will. And um and let me define like so I think the San Francisco consensus which is I call it is what people in San Francisco believe which charity was you is that you're going to see a build from current agentic concion to various forms of recursive self-improvement to eventual AGI and super intelligence. Um, in order to do that, of course, I need to use enormous amount of hardware. Uh, Google TPUs, uh, the biggest ships and silver, and everybody in the audience knows that. It sure looks like the hardware restrictions that the Trump and Biden administrations have put on China are going to prevent them from competing at that space. I've been recently in Shanghai for a few days. I have good relationships with the Chinese and my conclusion is they're they're they're fighting a different game. They're ready to adopt AI in every product, every service, everything, but in a more classical way. But the merit is going to seek for AGI. I was quite worried that we would end up in a super intelligence race where you would end up with such enormous gains that one side would have to actually pre-mp. It looks like that fear from me was not well grounded. In fact, I think we're going to be okay for a few years. >> Really? What What about robotics? We seem to be pretty far behind in that front. >> Yeah. If if if it's okay for me to be completely blunt, um the Chinese are doing the same thing in robotics that they have done in electronic vehicles. Um, in case you're confused, while the current government in the US gets rid of solar and wind subsidies and promos, China put in 172 gawatt of solar last year, I think is the number. It's remarkable. So, the the Chinese race around uh solar and EVs, electronic vehicles of one kind or another, looks like they've won. They're using all of those technologies, in particular, new ways of building stepper motors and other very inexpensive, very powerful, you know, physical things. Good example is Unitry just launched the R1 uh for $6,000 available in December. I'm I've ordered one. We'll see how good it is. But the arrival of humanoid robots um is likely to be dominated by China. I'm not suggesting there won't be areas where the US will play. uh the US will still have spaces of very high-end, very sophisticated stuff. Our software is so much better than the Chinese software, but at the hardware level, I think you should assume that the world will be a wash in inexpensive Chinese robots in the same sense that there'll be a wash in inexpensive Chinese electric vehicles. Who knew? And so this is going to be my last question, but let me bump it to the front since you just beautifully segueed into it. In the race for AGI, but then also in parallel robotics, uh, China's going to be miles ahead in electricity production. And in the very short term, we're all going to be chip constrained, TPU constrained. But if you look 3 four years out, they, you know, the the fabs are running at full throttle, the chips are coming out by the millions, then you're suddenly electricity constrained. uh is there a vulnerability for America there? >> It's a huge issue. So again, let's use China versus the US as a metaphor. What are China's strengths? Uh and I'm not praising China. I'm just trying to report it. They have solved their electric power problem. They also have full control over social media. So they don't have the kind of problems that people here complain about. They have enormously talented software people and they don't have enough hardware. I think that's roughly where they are. They're also incredible capitalists. Uh they they call it um Chinese Chinese socialism with uh socialism with Chinese characteristics. But trust me, it's pure raw capitalism. Let's call it what it is. In the US, we have the many benefits everybody understands. We do not have enough electricity and our hard and our at least in our consumer stuff, the Chinese are likely to beat us. Our hardware architectures are fantastic and I'm including um the Amazon chip, obviously the embedded chips, the TPU v5, which I'm happy to say I was part of TPU version one. Um all of that stuff is incredible. So, if you think about it, uh, and I testified in Congress a month or two ago on this, we looked at the amount of electricity required in the United States to power the expected demand of data centers and we needed in our calculation by 2030 92 gawatt to be built. And for reference, a big nuclear power plant is somewhere between 1 and 1 and a half gigaww. To give you a sense at how many nuclear power plants are getting started in America, effectively zero. So we had hoped and I've hoped in my lobbying and testim testifying that the government would fast track availability of all kinds of electricity. Um and indeed they have promoted oil and gas, but they've also hobbled sto um solar and wind to a terrible degree, which is an error. The country needs more energy. And if we don't get more energy, we're not going to be able to fully exploit the lead we have in AI and AGI. It's very clear. And by the way, the obvious next question is what do we do? Well, there are scenarios. For example, the president went to Saudi and the UAE and did huge deals for multiple gigawatts. And so we might find ourselves in a situation where our training for our most important thing, the thing which are the the essence of America, which is American intelligence, is actually being developed in kingdoms and that may be the only fall back we have. >> That is really weird and that begs a very difficult question. Do you mind if I ask you a a tough one? >> Go ahead. Uh I've been, you know, uh kind of uh inspired by you for most of my adult life and uh I I really I've been watching your uh podcast where you're talking about look when you remember when you guest lectured Eric Bolson's class over at Stanford actually you said when you were running Google you felt like you made decisions three times faster than any company on the planet but then when you got into the federal government you felt like the decision-m was onethird as fast as even a slow company. So from your point of view, it's like, you know, a tiny fraction of the pace that we need to move. But you've been saying recently that, you know, one of the things that's inevitable is some kind of an AI disaster and we're hoping that it's like a 100 people that die and not a thousand or 10,000 or a million or or even 100 million. Uh but, you know, suppose that it does play out that there's a catastrophe. That's a wake-up call. What do you want to do with that wakeup call? What what's the next move for Eric Schmidt after the wakeup call? >> Well, so so the background here is that Dr. Kissinger, Henry, and I spent an awful lot of time talking about the period in the 1950s where he was a key component of all of these things. And the so so what he did was he used the fact that we had used the nuclear bomb to negotiate over about a 15-year period a set of treaties that restricted nuclear proliferation. Those treaties when they were um uh when they were negotiated have allowed us to be alive today. So these were centrally important without but without without controlling the spread of enriched uranium and the other secrets we would all be toast literally because of crazy people and so forth. Is there an analogous set of things that we can do? The problem here is or I guess the good news is we're not in a war. We haven't had a nuclear bomb. We don't have that thing to discuss. So we can talk about it but governments tend to act reactively. So let me talk. There are three obvious threats right now which I think are fairly well understood. The first is misinformation and the software that we're all collectively giving people. Um allows for all sorts of misinformation, fake videos, fake news, what have you. We all understand this. It's all open source. That's done. That's a threat to democracies and maybe to dictatorships, but certainly to democracies. The second one is cyber. And I think one way to understand cyber is that if you can write code, you can also write cyber cyber attacks. It's the same logic. And you have these incredible gains in software. It's frightening how good these so remember my career is as a programmer. These things program better than I ever did. It's like shocking, right? And then the third one is bio. And I think most people believe that one of those three will create some kind of mini crisis that will then cause the governments to say, "Hang on, let's have a conversation about how to really deal with the downsides." The upsides are incredible, right? And I want America to win, and I want us to run as fast as we can. And we're indeed doing that with the Trump administration, which is great, right? But we have to be aware that these pos these things are possible. Um the one I'm particularly worried about is biological and he goes something like this. You take some existing pathogen and using biological techniques which I won't discuss. You can modify it enough that it cannot be detected but it's still quite dangerous. That's an example of a threat. There are many others. >> Yeah, that's also the easiest I think which is scary um of of the immediate you know CBRN threat threats. So cyber, biological, radiological, nuclear. uh biological is the one you can kind of do in a basement with three people, but it's also the one that's hardest to contain. So anyway, uh I hope the theory is right. So, so then uh how do you deal with proliferation? You know, the Biden approach was okay, let's contain AGI to these five companies, you know, Google being one of them, and then let's say any model with over 1 26 training flops has to register with the federal government. And then we'll keep it all contained. Uh, so that all got scrapped immediately, you know, after the election and got replaced by the new David Saxs document, which the David Sachs document is much more about how do we move as quickly as possible and and win the race. Um, but it doesn't really address proliferation. And obviously in America, we want startups uh and researchers to have incredible access to technology and compute. On the other hand, you know, the three people in a basement making a biological weapon is is a real scary thing. So, how do you balance those? >> It turns out if you read the David Saxs President Trump announcement, they're very clear that they want to continue to study the security aspects of AI, especially in a geopolitical way. And that's code for China versus the US. And so, they continue in their proposal to fund things involving nation state attacks and so forth and so on. and I fully support that kind of stuff. Um, there's probably a difference on the misinformation social media stuff between the two, but for example, the Biden rule was simply that you had to report if you're doing a training run 10 to the 26 or greater. I was part of the group that made that number up. Uh, we made it up because we had no better number. I'm not suggesting it's the right number. And the the conclusion you come to is it's probably the case that that we know our government, I don't know this, but I'm guessing knows where the training runs are going on in in China because of espionage. And it's probably the case that the Chinese have espionage on the US knowing where our training runs are. So I'm not sure the nature of the training run runs is a secret. And frankly, everybody knows where the data centers are cuz they're immense. So, uh, we will see. Another attack on the 1026 is that the training is getting more um more costefficient. If you look at the moving, they move from something called FP16 to FP8. That means eight precision floating point. People are now moving to four fourbit floating point, which is bizarre. It turns out these training algorithms seem to be quite tolerant for floating point impre imprecision which is a shock to me. So again we're getting more efficient in training. This creates more of a proliferation problem. If I can if I can say in general the proliferation issue I'm not worried about big companies in big countries because I can count them. You know there'll be 10 huge data centers, 10 huge training runs around the world. I'm much more worried about the open- source groups which can operate in the shadows. They don't have to solve every problem. They just have to do one thing well. They can patch together the open source which is generally available and it's good enough. If you look at the quality of DeepS are R are one and now R2 coming. Sure looks like it's in 80 or 90% of these top closed models. The closed models people, which obviously includes Google, get very defensive over this because they say, "Look, those are kind of synthetic. They have diffused the models. They've trained our best information. They're not." All of that is true. They're correct, but they are nevertheless useful for specific things, and they could be used in a proliferation issue to do various forms of cyber and biological attacks. >> Well, yeah. The current rule of thumb is that distillation and transfer learning is about 1% of the cost of the original training but gets you to the same destination. So if you take you know FP4 which you mentioned you know we get an 8x performance boost over FP32. So you get an 8x on the ch on the you know the the weights and then you've got another 100x on the transfer learning. And it's really hard to draw an analogy to nuclear or chemical weapons in the past cuz you couldn't kind of shrink them a thousandx under the covers and get the same result. But AI is really weird that way. It's it's very compressible, very fluid. Uh well, again, we we we will see. Um it does not look like we have a very good solution for distillation. It looks like an opponent of a company can mask their queries to look like normal sets of users and then distill the models. One of my friends has thought about this a lot and he thinks that the eventual state in the United States is that the biggest models will never be released and that the companies will distill their own models down for that reason. That's his opinion. We'll see if that's true. And this produces a bizarre outcome where the biggest models in the United States are closed source and the biggest models in China are open- source. And the geopolitical issue there of course is that open source is free and the closed source models are not free. And so the vast majority of governments and countries who don't have the kind of money that the west does and so forth will end up standardizing on Chinese models not because they're better, but because they're free. And so we'll see if that's true or not. But I do worry about that. >> Well, this whole topic of distillation and proliferation is a good segue into a much happier topic which I really want to use want to use our remaining time on. Uh I cannot tell you how inspiring you are to the founders around Cambridge, MIT, Harvard, Northeastern where where all of our talent comes from. Um, in my perfect world, you would podcast or say something or publish something every single day and then people could turn off CNBC and just tune into what you say because well, I mean, aside from it being brilliant, you have access to knowledge that isn't in anyone else's brain as far as I can tell. You've got this really, really unique combination of perspectives and and it's incredibly valuable. So, you know, using distillation and uh as a starting point, what founder advice would you give? you know, we're seeing numbers like they're completely unprecedented at ages of founders that are also unprecedented. I mean, you saw Sergey and Larry when they were very very young, but now they're even younger. We're talking 18, 19 years years old now. So, uh, what advice would you give them? >> So, I think the the most important thing to say is that the barrier to entry to starting a company is effectively zero now. So, let's think about it. What do you need to have a company? You can register it online. You need some money to get started. You have to pay yourself. Um, you don't really need any programmers. You need a couple people to w to pay Google or Claude or what have you to uh to write the code for you. Um, so you're pretty good there. You can use third party logistics companies if you're building a hardware device and you can use essentially contract manufacturers to build whatever hardware device. So it looks to me like for hardware and software the barrier to entry is almost zero. That sounds great until you realize that as a result you're now competing against everyone all the time. So as an example in my career which has spanned more than I guess 50 55 years now doing this stuff the key thing that's true is the compression of time. The other thing I would say to founders is it's really important that everything you do be learned and not uh specified. I'm doing a couple startups on my own. We'll see how well they do. But with them, I say I know nothing. Learn everything. So you can learn how to support your customers. You can learn what the customer wants. You can learn how to and learning meaning in the AI sense of learning. Learning it as part of uh either uh supervised or unsupervised training. U and if you take a learning approach then you build a system that if it works it will explode >> because once the learning accelerates you get into a quasi monopoly position. So the philosophy of winning goes something like this. Run as fast you can get there as quickly as you can. Build it around learning and if it takes off you'll be a hero because once it learns it learns how to become stronger. Um, and eventually two or three years, you'll start to have various forms of reinforcement learning which are self-replicating. And so then you're likely to get accelerations further. That's the most likely path for the next trillion dollar company past the equivalents of anthropic, open AI, you know, etc. And so when you're looking at an investment yourself, uh, by the way, the the learning loops concept that Eric just mentioned on the Moonshots podcast that we did with Eric, which you can find online, he actually described in detail the three or four different types of learning loops that he looks for. So it's definitely worth, you know, it's a lot more than we have time for right now, but it's really, really brilliant. So, uh, aside from the actual business plan and the learning loops, what do you look for in founder dynamics, founder team team members? Um, it's always the case that the that the founders are really really smart. They're very very quick and they're very interesting to talk to. It's also true that you need them to be able to hire a network of people like them. >> And so a simple way is if you talk to them and they seem really interesting and really dynamic and you find that they're in a network of such people, you likely have winners. And then what you do is you say to them, show me, don't tell me the product, which of course is what they want to talk about. Show me how you're going to build a system that is that goes from zero to infinity. There's a lot of discussion about 0ero to one. And there it's complete compression. Get that thing done. But once you have one, how are you going to scale? Our industry makes enormous wealth for the founders when you build a platform that is scaling. That's the lesson. What is the lesson to offer? Build a platform that scales if you can't. And a platform is defined as something which others depend on that you provide. Right? And the stronger the platform, the more it is, the more interconnected it is, the stronger the network lock in. That's just generally true. It was true for Microsoft. It was true for what I did 20 years ago. It's true today. And I think if you look, I'll give you an example. Everyone's looking at where are the economics for the large LLM companies. They don't have a strong enough network lockin yet, but you could easily imagine that they would develop it and I'm sure they don't tell me what they're doing, but I'm sure that they have that in the back of their mind. That's their that's part of the reasons why their valuations are so high. >> So, we have one minute remaining and I really want to use it to milk you for a quote that we can loop on our wall in the office. Um, and I it would the perfect quote to me would be about the importance of this moment in time. And so many of the founders uh they weren't around when Microsoft could, you know, Bill Gates could wake up in the morning and decide, hey, I'm going to destroy Word Perfect today and I'm going to destroy uh Lotus 123 today cuz they just had that that that power at that time. And noll was certainly in that crosshairs, too. uh then there was this magical moment of the internet explosion where companies like Google and many many others could thrive but then after that you know things got static again and now we're in the most explosive uh time period for opportunity for entrepreneurs that I've ever experienced in my life but very few people remember all the way back to the internet explosion era so I'd love to get your your quote or your thoughts around what is the importance of this moment in time. >> So I firmly believe that that the arrival of nonhuman intelligence, AI intelligence is at the level of electricity or the invention of fire, transportation, etc. in human history. We are fortunate to be living in a time of great historical consequence. The next 10 years are probably the 10 years that will have a greater determination over the next hundred years than anything before because of the inventions of these new tools. And the tools are very very powerful power. And remember, they're powerful because they they can equal and in some cases surpass human intelligence. And human intelligence is everything for society. And so the countries and companies that embrace this non-human intelligence correctly and aggressively will be the big winners. And the companies and countries that are slow or let other people do it, they will lose because that the source of excellence, the source of leadership, the source of growth, the source of everything, the source of innovation, everything economic growth comes from the application of intelligence to discover new things, to solve new problems. We are on a huge course to accelerate that here in America and I'm very proud to be part of it.