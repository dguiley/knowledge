# Future AI Code Editors Kevin Hou Codeium Windsurf

Published: 2025-01-26

we wanted to give the users the best possible experience we don't really want to ship kind of like a half-hearted version of the product so our goal right now is to build the best possible IDE for developers if something is so painful when it's broken that's a good thing from a product standpoint does it behave as if it was a human developer like does it take the course of action that you might take if you are solving a problem welcome back to beyond the hype I'm your host Ean today's episode is all about wind Sur probably the most talked about AI code editor right now we've got Kevin hoe the head of product engineering from codium joining Julia and me to share the inside story from their early days in GPU Tech to becoming a major player in AI development tools and trust me you'll want to hear about the new features that Kevin previews at the end excited to have you on Kevin we met in the YouTube comment section right after I posted my video on went up and then you were doing Live customer on some user queries so great to see you have community at the center yep yep I'm always uh I'm always hunting I think YouTube and Twitter are probably the ones that I'm on the most but I think you know a fair bit of Engagement across all the platforms it's just nice to see people using the product honestly when I see people actually commenting or complaining I think it means people really care the worst one is absolute crickets I mean yeah I've been building products a while I can definitely relate to the nothing happens and and you're just kind of you want the attention right even if something is negative it's like if something is so painful when it's broken that's a good thing from a product standpoint could you start by telling us a bit about the history of Winder I mean when they first started with codium I know you guys were first doing GPU related work and then pivoted into coding and then a full-on IDE tell us a bit more about that story sure sure so there's a number of pivots here um the first of which I guess you can start with x a function which is the very first Inception of the codium team then there was the pivot to codium and then there was the pivot to wind surf if you want to call it that uh so to start from the very beginning I guess I was working with XA function at the time um and it was a smaller team we were building GPU virtualization software what this basically means is like you have a high throughput system you need a lot of inference think hedge funds doing like massive for in self-driving car companies my my background is in self-driving cars prior to uh my work in in this field and so any workload that had a lot of GPU load we could basically optimize and squeeze you know 20% more efficiency out of your system which for large workloads is a non-trivial amount of money saved and so that was the EXA function pitch which is basically take your existing workloads we'll optimize it we'll make it better um this was kind of the early days of AI boom I would say this was around the time when like mid journey I think was kind of taking off and yeah before Chach PT right before Chach PT and it was a good business um it did well like Revenue wise all this stuff you know in under a year did quite well but we started realizing that you know it was going to be the value was probably going to crew more on the application Level there was more to extract out of the application layer than just the infrastructure layer we had a lot of smart brains in the room and we're like all right what can we do what what kind of product can we do to actually be the end user application and like squeeze more out of the infrastructure that we've built and we landed on like as developers we landed on like the co-pilot thing and so GitHub co-pilot was out at the time but we noticed there were a lot of ergonomic things quality things you know two years ago this this technology was just not in a position where it is today and we pivoted the company to work on this new thing that we called codium and we went to Market with a free uh autocomplete extension first on vs code and then we expanded to roughly 40 different idees and our main pitch um the reason we existed was better context awareness um a lot more like ergonomic things inside of the extension itself and then we were also free and um these three things gave us like the right to exist in the market and we started our Enterprise motion which was focused on on-prem security oriented companies and so what this meant is we were taking a lot of the learnings that we had from managing GPU clusters and whatnot and actually deploying this software inside of secure Enterprises in a self-hosted way so you could run the software stack completely disconnected from the internet and that was a very compelling case for insert some you know National Defense insert a government insert um a bank or some sort of financial institution places where there's a lot of compliance regulation and just honestly like security and intellectual property and so all this to say the codium business was going quite well um but what we were running into was like the pace of AI Innovation and YouTu canesta this has just been mon like insane in the last two years and we've always had this kind of ongoing research muscle at the company and we've been discovering more and more that the amount that you could do as an agent was becoming real value um it was no longer like a a Twitter demo or a toy or something that worked like 5% of the time it was starting to get to the point where like this technology was was quite helpful and we're a skeptical company in the sense that technology optimists but a lot of us internally we are very skeptical of like new tools um and so there was a point when we started using some of the research that we the proof of concept work which ended up becoming Cascade our agent and we're like wow this is actually helpful for our efficiency in our productivity and that was the turning point where we're like okay we're probably going to need a different product surface um the patterns and paradigms of software development are going to change and we actually have the expertise the skills and the distribution to make that happen so enter wind surf where we could divorce our elves from the API constraints of vs code from a visual perspective and then also really build at the core of an editor this idea of an agent that's kind of par program Pro par programming with you where you could kind of flow in and out of the state where the agent is writing some code for you you're writing some code and you're kind of like learning and riffing off of each other so that was really the Inception story of wi surf long-winded way of saying we've gone through many different stages of the company we've learned a lot along the way but here we are we launched windsurf two months ago maybe I I forget when we got connected probably like roughly it was November I can't believe it's only been two month since wind has been out yeah and and we we started building this thing we built it in in two months and so we had two months prior we started at sometime in September finished in November launched I think it was like November 13th or something around there and uh yeah here we are we've got decent user traction people like yourself hopefully are enjoying the product and uh we're just we're kind of on a roll we're we're just shipping new features and fixing bugs and the whole thing it's the dream yeah so and one of my most exciting moments these days when I look at AI code editors is when I see that ready to update button on top oh yeah and then I especially like for wi that you guys keep the change lock button directly in there so that you have a oneclick way of saying oh what is the latest change so please don't tell me it's just performance f is it's new features new features new features we got a lot yeah we got a lot gives me a lot of satisfaction you you'll be getting a new one I guess depends on when you release this wave two will be coming out in a couple of days oh I was just about to ask about that yeah very excited for that yeah so just to close the chapter on codium um I was wondering is the extension as we knew it a year ago is it deprecated it is not deprecated I think the way that we see it internally a lot of the engineering work we've done translates nicely across surfaces the we we have this thing called a language server which is basically a language server which is basically a go binary and the way we've structured our products is that we like to make the application layer as thin as possible and really focus on the language server being the the kind of guts the brains this worked really well with extensions so we were able to ship one language server that would do a lot of the context retrieval a lot of the computation um do the inference and then give you suggestions and then it was a very simple application layer which would say all right you're in VSS code use this API you're in intellig use this API you're in Vim use this API and in this way we were able to iterate and create a lot of different extensions and so the reason why I'm telling you this is because we've still keeping that mental model where we're investing very heavily into the language server which means that an a um an IDE like jet brains it is not when surf but it inherits a lot of the quality improvements that wind surf will have the difference is that wind surf we can really control all the ways that a user might interact with our feature set we cannot do this because of API constraints on a product let's say like VSS code so it is not deprecated in the sense that we are not developing on it it's still improving but you are just not going to get the best experience and for example I don't even think the agent flow if we were to take an extreme example I think it's very hard for an agent to feel good inside of Vin and I would say the same thing about VSS code now it's going to be a little bit easier but like we wanted to give the users the best possible experience we don't really want to ship kind of like a half-hearted version of the product and in that way we've kind of doubled down on like wind surf being the way that you get that best experience does that kind of make sense I I can't imagine even for simple things like showing the diffs would be really difficult to do as an extension because you don't have access to that but I think people frequently forget how important it is to actually view the changes that AI has done so that you can check for doing well simple sense checks for it yeah I can definitely see that so based on that mental model you just described what percentage would you say is at the base layer and what percentage is at the ID layer given that you were able to do things within two months to ship when surf it feels like the ID labor maybe just like 20 10% would that be accurate um it hard to pin a percentage and as as you know you know code the number of lines of code is not necessarily a good indication of like complexity and all that sort of thing um what I will say to set some context is we we train our own models we own our own infrastructure we build our own products um and we self-host our product so there's a number of things here so our stack is incredibly wide that being said we do have a a fairly large team we're about 150 people the engineering team is um roughly like 40 or 50 and the I guess your original point was like how much is in the IDE layer there is a lot in the IDE layer I think it's just because we have more people now we've been able to kind of make that layer a bit heavier but it's not necessarily in strictly AI world like for example what you just referenced the change log and the updates being something that you look forward to and you kind of get a dopamine hit when you you click restart to update you see a change log you open it up all that sort of thing is stuff that we've customized we've thought very intentionally about and so the the scope of what is in the ID has expanded not necessarily in the AI sense but in just like how do you build a good editor we move the command pallet to the middle to make it bigger kind of like an everything bar type of pattern um we've added various features here and there into the editor itself um we've changed some typography to make things feel like fresh we've modified some of the layouts like there are a lot of things that we've done in the IDE that are not strictly related to context retrieval and whatnot but are very important for part of the end user experience yeah I definitely feel that's a trend that where it's not just about using more powerful models yeah even the existing models are plenty powerful enough to do so many things it's like Claud Sonet 3.5 has been with us for quite some time and there's still yet to be another model that does both gives you both the performance at the speed it generates and as well as the quality it generates as well right completely and the ux is what makes a difference for most developers and I 100% agree with you and especially when when so first came out the thing I I think most of AI Twitter love is the auto context part where you don't have to manually mention here's these three files you can look at so that it tries to get retrieve the right context directly from the code base that was mind-blowing and I think it was so good that I think curser had to rush to release that feature within three weeks because I can definitely feel that I like okay that this is now great competition it's it's getting very interesting now it's good for the end users right um I will still say I I sleep less you know we're we're we're always we're always grinding and uh I guess I slept a lot or I didn't sleep that much before the launch I don't sleep that much after launch so I guess nothing crazy has changed but it's definitely good for the end users right the the end experience is like AI tools just get better um people have better experiences they're able to accomplish more and that's just good for that's just good for everyone good for the industry from a team morale perspective what's it like inside the company to be under so much pressure so much competition a lot of speed you know you wake up in the morning and you see that your competitors have a pixel by pixel identical uh you're implemented how do you how do you keep morale up yeah that's a great question Julia the a lot of it is in the like it's not single actions I guess here and there that that make it it's it's kind of like we built a culture that I think is pretty resist resilient to that sort of thing um there have definitely been mornings where we wake up and like exactly like you said there's like an announcement or something and I think in the early days of the company for example co-pilot is it X or next um I think it was called X you mean the fully automated one that does the full pquest no no no this was like two years ago when they were like we're going to release a chat okay okay I forget their lab basically I remember distinct moments like that where like Julia said I like wake up I see an announcement and I'm like oh great like here we go but I think over time like as I have matured as the as the company has matured as the culture has has kind of formulated we've been able to stay focused on the things that are important and kind of like gloss over a bit of the noise from competition what that means is like we want to focus on bringing kind of these generational step changes to the industry so for example bringing Cascade to Market being the first agent that was like widely available and definitely the first IDE that would like integrate that very tightly um we could have operated at like a local minimum of competition of just trading blows back and forth on let's just say uh like a chat interface that didn't do the automatic context retrieval there's probably more app mentions and more connectors that we could have hooked up and had like little incremental gains but the team is very good at staying true to like what is the ultimate goal and like setting any larger Visions so that these kind of individual day-to-day things don't sway you um so that's one side of things and then the other side of things is I think we just have a very fun energetic group of people um we do a lot of like just fun we we spend 10 plus hours a day together uh we're our office is in Mountain View um everyone is five days a week in person and culture fit is like a big part of the interview process and so we're all just excited to hang out together and to be building a product together doesn't really feel like a job it's just like you're building something cool with your friends um and in that way morale stays High because the day-to-day is like quite exciting it's not like you're just crunching tickets or you know trying to catch up to competitors it's like you're actually just just hanging out and I think that's a big part of like staying mentally sane yeah I definitely feel the California Sunshine helps a lot if you're doing this in the UK in this day where Sun rises is at 8 and sets at half three it is so miserable would I can definitely see why Valley works so much harder than the UK is just of the California son it's a good time yeah Julie what were what were you saying uh I was gonna ask speaking of competition there's there's obviously some obvious ones like Herer I was wondering if you zoom out if you can think of other competitors that are maybe non obvious and I can give you an example um I think that bubble is actually a competitor or somebody that you could replace in the future all of these no Cod tools especially with a new generation that is more and more literate in using the command line and programming even if they're not computer scientists what are some other competitors or industries that you see replacing in the big picture oh boy Julia's good at this getting the spice uh that's why I have her on as my co-host because even in our own conversation she has all the spice this is good this is good um so software touches a lot of things and I'm not going to act like I'm a like I'm the I'm the truth when it comes to looking at the industry or whatever this is just like my vantage point um and internally I don't think we've really had a lot of discussion about this sort of thing but when I look at um when I look at companies out there like I think the no code is a very good example like lowering over time like the bar for technical competency is going to continue to decrease and the the desired quality of what you can produce will increase so for example um it'll be very easy for someone to spin up an Instagram clone right it'll become more and more important that the person instructing the agent can think about things like user experience uh growth tactics um why your product should even exist relative to other products uh and so I think it changes maybe this is more a question about like what does it what how will this change the industry and like what demands like what skill demands will there be um but like I think my general thesis is like the the barrier to entry on technical competency is going to um going to decrease I I think like website Builders are another like obvious example but I think what website builders provide is a level of taste when you look at a Squarespace site you can kind of tell that it's a Squarespace site for better for worse but what they've done is ensure a bar of tasteful quality like design quality and aesthetic that right now I don't see agents kind of like meeting necessarily um maybe get close to that it's kind of the minimalistic minimally beautiful interface that um you AI models produce very well today yeah yeah or just like it's going to demand more out of your creativity to be able to actually instruct like what you want it's not going to generate something creative for you without you providing that level of detail so yeah there's a number of like situations in businesses like this um I think uh maybe maybe another example and and you can feel free to chop this to to whatever um another example that I'm thinking of off the cuff the like small business has a demand for some sort of whether it be a website or some sort of internal tool even something like a coffee shop or like a laundry mat or like small family business right would typically have to go out and find either a consulting or like a technical consulting or contract out this sort of work I think the maybe long-term future of those businesses is potentially it'll certainly change I don't want to use the word at risk because that sounds a little bit scary but when Mom Mom and Pop Shop can now use an agent to generate you know an internal customer support portal for themselves and no longer needs to reach for either an external tool or a Consulting agency to set that up for them it changes the game on kind of this sort of small scoped custom implementation work so then do you who do you say wind sur's main target audience is right now and also how it's going to evolve say for the next three to 5 years you know the cases that you just mentioned there are Engineers who know their there are also like Mom shops who has never touched maybe even a smart smartphone right and how do you see the customers for wind of changing over the next couple of years I think we're fairly um we're fairly focused on the developer Persona right now it's very easy to try and widen the scope of who you can cater to I think at the very least a product like wind surf can help a non-technical person build websites build apps we've seen countless examples of this um we've also seen a lot of people learn how to code using winds surf that's always great to see um but the Persona that we are focused on and what we will develop for is the Persona that currently knows how to code and making Engineers of of all types just better we have not we will not probably in the in the short-term future we will not focus on um like someone who doesn't know how to use the command line or doesn't know how to use git for example I think this is an intentional decision not to say that they can't use the product but when you're building something with potentially many applications it's very easy to go searching on a bunch of these side quests and not really have Focus for what your end user Persona is that you're trying to satisfy so our goal right now is to build the best possible IDE for developers and focusing on that Persona allows us to really dial in work more efficiently um make hard calls about like what features to prioritize and all this should result in a better product for developers I think in the long-term future you know maybe 3 to 5 years the interface space through which people will be communicating with an agent like Cascade will change um don't have too much to say on that because I think there's still a lot of juice to squeeze on like just how do you build a better IDE integration with an agent um but in like let's say the fiveyear Horizon I think that will change and then that's when you know you've kind of cater you built enough for the developer let's just start like inching outwards who who are the people that you know maybe we then Target student and then you target people who are non-technical right like slowly you slowly expand but you have to have a focus so in the case when you are still targeting for developers you know there are currently case of uh Devon and the AI ID path like cursa and um wi surf how do you see those two path going forward and for wi surf is the fully autonomous way that Devon is doing something that you guys are aiming for or or is it a very different path that you think you guys will go down I think at some long-term Future these things will converge the way that I've thought about this in my head is like the market is massive and the number of people that are currently on AI developer tools if you think about how many developers there are in the world versus how many people are for example paying for an AI tool is still quite small and so the market has an appetite for a lot a lot of different solutions and customer adoption will take a long time for example you know the sales cycle for us to work with a prestigious like world renowned company like Dell takes on the order of like months and years and so distribution um is not like an overnight thing and so when we talk about kind of the Horizon through which these two things might Collide we're kind of working at a similar problem but in different directions and I think the industry is kind of slow enough to support both so it's hard to say you know kind of competitor and we're just working at the problem from different directions it's kind of like the self-driving car analogy where you have um like a company like weo who is working on um like L5 autonomy generally and are just they're they're full sending like that application use case and then you have um I don't know let's just say like the Tesla autopilot situation where they're approaching it from kind of like peace meal incremental rollout uh almost like the co the co-pilot analogy right yeah and these two things are on probably the same Horizon but I don't think there's a world where like one just like completely disappears um like a winter take all Market that's the way I see these things um if that provides any any particular yeah because even from my personal experience I feel and you know AI IDs they help you do what you already do like 5x faster yeah and then the AI coding well I mean the the fully autonomous AI coding agents like Devon they kind of take away part of that work and then just do that for you so at the end you might still you will always get the 5x but just done by very different ways yeah they're done in very different ways I guess another way of looking at this is like I don't know the exact answer to this but like when will a code editor like disappear um at what point are like agents good enough that you actually like don't need to touch the source code at all hard for me to imagine that future I guess true AGI would be solving that future but then in that future it's like you kind of got I always say like we kind of got bigger problems to worry about in terms of like what are what are we going to do as developers or just like the world is going to look very very different if you achieve that level of like quality like if there's no marginal cost to software it's like shoot like there are probably bigger fish to fry about like societal problems and whatnot and so you know that's like a future that you can kind of that we we don't focus on that much internally you know fun lunchtime discussion but like not doesn't factor into like the product Road M too much to be honest I'm sure that assembly programmers founded very hard to imagine a future in which people would not write assembly and a lot of years later were fine we found other things mhm the word is not just ones and zeros what yeah I guess like punch cards to now too I mean yeah there there's definitely like there's definitely a history of of things turning over um so you know we might get there yeah and so you know we talk about agent as a key word it's a key word for 2024 right for AI um how do you guys Define a gentic Ide at when because I think see the words throwing around too much and then the level of intelligence varies so much depending on the person that you talk to oh what's yours yeah yeah mine I I see I see an agent as something that kind of mimics human behavior I think there's a lot of like oh it it uses tools or it can like self-correct but I think that's like too narrow in definition for me it's more like how what is the overall framework through which this piece of software like this AI operates it has the characteristics of being able to use tools sure but that's almost like more of an implementation detail it has the ability to self-heal again there's a number of things that you could say along these lines but ultimately like what I go back to is does it behave as if it was a human developer like does it take the course of action that you might take if you are solving a problem an example of this is there's like so the thing that we're launching in Wave 2 that I've been working quite hard on is is like web search and web scraping so like if I need to do research that reaches for the internet like what does that look like there's an agentic way of doing this and then there is a not so agentic way of doing this um the distinction in my head was Google not an agentic search platform sure you can throw like embeddings in there you can throw some like semantic search you can throw all these other things like in there but ultimately it's like a sending out a query getting a list of results like it's a tried and true pattern like the rag style um if you want to think about this in a more agentic sense and because the models have gotten better to the point where we can support this the way that our web scraping Works our web search works is it behaves similar to like a human would if you were researching a new topic so if it feels it needs to do a web search it will do a web search after which it is not a defined path like hey let me open up the top 10 files and like open all those pages and then read all the contents and then do rag on top it's not like that instead it will kind of go step by step and say all right I got these 10 pages as if I was on Google what are the ones that have the highest promise let me like kind of rank in my head like which ones I should look at now I don't need to look at all 10 I can look at all 10 but I don't need to look at all 10 let me look at like the first one or two and then within that you kind of command you know when you open up a a stack overl I guess it's very obvious like where to look but on a blog post for example you kind of kind of like command F your way through the file you might look at different sections and so that's in my head like the agentic way of approaching web retrieval and like web search it's not it's like a very targeted very humanlike way of retrieving information so our when we built web search it does exactly that it does the search it then looks at the results um it chooses a couple pages to look at and then within those pages it can dial in and expand and in that way there's like the human element of like oh I read this page now I have another there seems to be another topic that I need to research based off of this but it's not guaranteed every time that that's going to be the case so you want the agent to be able to make that decision for itself given you know the recency of like what it's just looked at does that sort of make sense there see and there's these are two different ways of approaching the same problem one of which I would categorize as agentic and one of which I would categorize as not it sounds like you're defining agents as a system that passes the touring test for developers in particular the touring test for develop uh maybe expand on that a little bit more well the touring test basically says you're communicating with this entity fools you if it sounds like a human to you then it reached intelligence so what I'm hearing from you is I'm communicating with this entity if it acts as a developer if the output that I see could have been produced by a developer then it passes the developer touring test yeah yeah therefore it's an agent yeah I guess you could tie it back to like the outcome um ideally I guess there's a thing here like something does not have to be effective for it to be an agent maybe is like one way of putting it um I mean the hope is that these things are indeed more productive right more efficient and like built well enough that they do provide value um but I just think it's like the way that the AI goes about like solving its problem is different yeah I think we certain do see a fair share of those where oh people designing some complex agentic networks and realizing oh wait that could have been done with a big fat prompt but in the web search case in like code iteration case yeah you can't do that kind of iteration as you mentioned you know selfhealing to me that's a really crucial part because yeah it's great that AI might generate you know something accurate 90% of the time but over three iterations that's less than 70% effective which is horrible right for most engineering use cases is being able to like having that self correct like you mentioned and being having that knowledge grounded to other sources that makes it actually feel like more human because human do self-correct and computers most of the time yeah yeah and maybe maybe another distinction here is the self-correction can take on many forms right it could be a unit test it could be a lint test it could be um maybe even just following some like organizational best practices you don't every project every PR is kind of a is a little different in terms of like what are the demands for like success and when building an agent it's important that the flexibility of understanding that success criteria could be different and how to verify different types of success criteria is important if you developing something that was not agentic you would maybe say oh like let me hardcode these five different rules that have to pass for the generation to be considered successful it's like a different way of like looking at the problem one is like very constrained and one is a bit more it's like generalized intelligence yeah so uh going a bit further down the agenic rabbit hole is uh because I do love the agentic workflows it's um how much do you see that workflow being baked into uh wind surf into cascad capability and how much do you see that as being defined by the users themselves because out of a lot of recent experimentation I found that uh even without I mean from this is a Cascade version from last month right that's the main one that's been running um even with a few simple rules that added to Cascade memories yeah and say oh hey run this for your playright end to end test and do not stop until you you see the Test passing on the other end and then it then knows to go into that Loop of make the UI changes run the Play Ride test and then does it work oh it doesn't look at the error fix yeah but it's the users if they didn't know to write this into the rules file they wouldn't be able to get this kind of even more agent capability out of the exact same model exact same underlying thing totally so how do you see those Sur being totally yeah I think there's a lot of education and tuition that's built up over time for example like you knowing that you had to make or could make changes to a rules type of system in order to improve the quality or even just the general skill of being able to prompt and know when to be verbose know when to be General um for example one of the situations that came up this morning is like um knowing when to ask for a plan of action before going ahead and like starting to execute like if you're a more seasoned wind surf user Cascade user you might for something very complicated you might ask for the plan first before it goes off and tries to like muddle with your code base on something that might need some course correction in the planning stage so it's almost like building up that intuition now there are some things that we can do in order to make that process better both from like a like a kind of like normal ux standpoint and then also some of the things in the agent so an example being something that's going to ship in wave two um in a couple of days is the notion of like an autogenerated memory so the idea that let's just say you went through the flow of running your playright tests at the end of your trajectory or your conversation you made a bunch of changes then you ran it and then you kind of told it like keep going like don't don't stop and you did this in the conversation or maybe it just notices that you we we are also rolling out like an integration with the terminal so that it's more context aware on like what you're running in the terminal let's just say you kept repeatedly running your npm run playright test it will remember that automatically on your behalf and bake that into its internal understanding of your workflow um this is called like an autogenerated memory so the pattern is a little bit similar to like the rules but it is completely automatic and under the hood um you can still tweak these things if you need if you think that like a memory that was stored for example was like a bad idea but these are ways that we're trying to guide the agent into following better practices and and therefore creating better performance so in your case you wouldn't have to know that I can go into the rules it would just kind of happen on your on on your behalf yeah then for those use cases how much do you guys imagine you would be able to in the long term bake those STS in as you mentioned say the intuition to know to ask the agent to make a plan not many people would know and depending on your estimation of the feature size of oh this will be a large poal Quest therefore my intuition is I need to ask AI to make a plan can it not be done in a way that where oh the Cascade notices something that's sizable and then decides for itself that it needs to make a plan so that you know building the user intuition like passing it onto Cascade yeah I'm not sure what's your current plan around that yeah um I don't know exactly how this will become how how this will come into fruition like I think you bring up an interesting point like there's so many different personas too that might want that like for example some people want the the abstraction of not knowing it doesn't need to know everything that's going on like just just do it for me and then there's some people like my sister for example um she's non-technical uh she is learning and so she uses it with EXP instructions to like not make any edits on my behalf but like explain pretty clearly like what's going on and like lead me to the right answer and like that's an example of something that sure you could put as like a mode like a student mode but then if you follow that pattern like how many like what there's never going to be an end of like the number of personas that you kind of want to support so it's like a very hard exp user experience question like at at what level are these things should these things be baked into the proc product right and at what level do you kind of try and make a generalized system so are are autogenerated memories is an example of a way to try and generalize this where you should only ever instruct this thing once on a particular pattern or practice that it should beh be beholden to um so yeah I I mean I think these questions are like these are great questions I I don't know exactly how that they come to fruition but that's the general way that I'm thinking about it that also automatic memory feature I very much look forward to that and um it was quite funny that when I was looking at the last Cascade version and quite a few other viewers also commented that would be a really nice feature to be added to the next version and clearly I think you guys saw that and or maybe you guys were already on it way before we even suggested we're seeing the same things yeah we're seeing the same things yeah yeah but I mean ultimately like Like rules is a is a bit of an anti- pattern um as intelligence gets better I think we've always seen you know we wanted to build the manual rules because we don't live in a vacuum like people have have used cursor they've used cursor rules um people are not as uh they're just used to what they know right and so rules was an important thing for us to implement as a way to kind of introduce people to this concept or just bring some familiarity for those who are coming from other products uh but ultimately the end goal is not for you to have to instruct and like Define very clearly like hey I use single quotes instead of double quotes like these things should sort of be intuited and that goes that's a very small scale example case but the the hope is that this as intelligence gets cheaper and better we are able to int more of these things that are kind of high level you might start thinking about like larger just architectural ways that the company that you're working at adopts into their code base um and these things should not have to be explicitly named rather they should be kind of um automatically either retrieved or memorized by our system I can see that this is something that has to be built into the agent such that not just it learns from the users's behavior but even prompts users to try to see different give them different choices see how they choose and then you know at the end so rather than just oh they use it said this to me three times in the three past three workflows is it because they prefer this or is it because they don't know a better workflow yeah yeah yeah it's like a back and forth and and it's tough right you we are basically trying to take here's like Cascade and here's like the human we're trying to close the gap of of understand understanding between these two things um but then also injecting a bit of like best practice right as you're describing like is this really the best way to do things is the user really doing the right thing here it's it's just yeah it's a hard problem there's no Silver Bullet uh but you're trying where we are trying to position ourselves in in a situation where you know there are these guard rails and like features that can help improve and then over like those features will improve and then the agent will improve and then the models will improve and everything just kind of like there's like mini wins here and there that will overall just make the entire experience better yeah and you mentioned emergent behaviors right from users of you guys I'm sure you're getting loads of data and seeing how people use uh when serve in very surprising ways what was the most surprising way that you found people using Cascade or being able to achieve something that you guys didn't think was either possible are very unorthodox yeah so we we built Cascade very much for the developer for the person who works on a large code base with potentially many different projects within it and like like that was the Persona and and largely that's because we are building for ourselves we have a big code base we have many people we have different functions like we wanted it to be able to satisfy our constraints I guess what was surprising and maybe looking back it's like okay this is obvious the non-technical user really leapt on to wind surf in a way that I did not anticipate and also did things with wind surf in ways that I didn't think were possible an example being um there was someone else's parent at the company who and I use parents in the sense that like they non-technical like they're not they've never used the command line that sort of thing but they were able to kind of grapple with wind Surf and and deploy a site to production right going all the way from let me build like iterate on the actual like website I don't know how to run these things on my computer but like Cascade will run it for me all the way to they were they created a it knew the the agent knew how to tell it how to create a GitHub account knew how to make a repo from that and then proceeded to push the GitHub Pages as a means of getting this into production and this is all without any guidelines from us explicitly telling it hey this is probably the way you want to do a deployment and so seeing that end to end flow of someone going from like zero technical skill and being able to like go from idea to production like they're still using Cascade to say like all right publish this change and behind the scenes Cascade is running like a git ad get commit get push type of pattern seeing the way that people have been interacting with Cascade in that way was very surprising and very cool another behavior that I thought was surprising I've had friends who tell me even for the smallest of tasks copy changes simple refactors variable renames they just go to Cascade now they don't actually like type the thing out like it surprised me how much autocomplete has basically decreased in importance and the agentic flow has increased um to the point where like you these people are smart like they can they they know how to code but it's just easier for them to then just instruct Cascade to kind of make that change in a matter of seconds as opposed to minute where they would go in and to me that was a very surprising user behavior um we know these things are possible it's just like I would have assumed that if you know how to do something like simple like that you would have just done it but it really has rewired some the way that people approach coding it sounds like you are very well in touch with your users You observe them using the product you were monitoring social media I wonder are there more automated ways in which you're learning from what the users are doing so are you logging activities are you storing the code are you training on the code yeah um I I'm doing a lot of things that are probably not scalable um I I text a lot of people that use the product I watch YouTube videos of people that are using the product I'm in the comment so I'm doing a lot of things that are not scalable um I I wish there was some way for us to get get a better pulse on like user happiness that wasn't us going out and like reading a bunch of qualitative feedback um I guess as a as the the legal disclaimer of like your question um we are not doing those things like I there's like code Telemetry stuff um there's like settings that people can can can configure in their profile um so it's not super helpful or like productive for me to kind of go in like the logs and like view people's stuff because most of the time like it's kind of off Fus skated um and so the best way that I have is through these kind of like second derivative sentiment online type of thing and just being very proactive but at some point we will need to kind of go to a more qualitative approach I guess there are ways that I can see with low granularity what is going on so an example being we have this metc called percentage of code written this is very helpful for autocomplete it's the idea of um how many characters did we write versus how many characters did the human write uh this takes into account Backspaces and all those sort of thing so we developed this a while ago and this is a way for Enterprises to see just how much value the autocomplete product brings as the modalities have changed you know autocomplete command then we had chat and now we have Cascade this number is like crazy different depending on which features you use because Cascade is going to generate 100 X more characters than an autocomplete would um and assuming that the quality is correct it should start dominating the number of characters that a human would write so we look at those sorts of metrics to just see kind of directionally like are we providing value and this gives us a good sense of like yes we are doing good work um at a very like aggregate level so we can say like all right typescript developers what is the acceptance rate of cascade changes going into the project and are we was there a regression in anything that we did so like one of the examples is like if we ship a new model or if we ship a new um a new feature we can run experiments on this thing and basically say right before and after how does it perform on those metrics like the acceptance rate of a Cascade for example and that's a way for us to get to get a pulse check on on how good things are going so given that you're not logging any of the code you're not training on the code right now um do you do you have a philosophy similar to Apple where you don't want to build a mo around people's private data or do you see a future where maybe you trade a free product in exchange of getting a license to the code that's written with the product I guess the bigger question is oh interesting do you see aote and the data that's flowing through your system and do you plan on capitalizing on it to maybe eventually compete with Sonet with anthropic in general yeah yeah yeah that's a that's a good point I mean I think the biggest benefit that we've seen from having a free product is not necessarily like the code that is generated by our users it is more that we are able to very quickly iterate on an infrastructure change or a model change like we are in the business of trying to create our own models and so we would not be we would be much slower if we didn't have a production application that was used by hundreds of thousands of people where overnight you could sample and say all right this model is better than this model let's like go with this one um so that's really like one of the biggest exploitations we found of having a very generous product I mean ultimately um like the way that we have approached our kind of go to market strategy is as individual developers we kind of empathize a bit more with like the in the solo developer or like just the the average like our friends right the um and so we've made very intentional decisions like we lose a lot ofy money on the on the individual product um I know it is an expensive product and that's like kind of the sentiment online but like we lose a lot of money on these products and like to us that is worth it because we just want to build the best product for our friends effectively and we have an Enterprise motion that is responsible for actually generating revenue and and making the business like a real business and and a long-standing business and make sure we don't disappear the amount of money that is in the Enterprise space it's kind of dwarfing the amount of money that's in kind of the prosumer individual space like a lot of good developers they just work at companies and those companies are willing to to to fund these sorts of tools so it changes a little bit of like the feature set all that to say really the goal of the consumer tier is to like build the best possible product um it's not really it's not really like a mo data collection type of thing it's just we need a space to play it's much faster much easier to play with a large hopefully happy customer base that then we can then translate into Fe features and products for an Enterprise tier makes sense so then for the consumer tier do you plan to I me right now you use Claude and gbd4 and um I'm sure you probably at one point if the pricing makes sense integrate o01 at some point and probably not in the near term but uh do you see our actually building a custom model Based on data that you guys build up over time or is it going to be still just the lay model layer that goes on top say focusing on say the application logic focus on the data context retrieval focused on you know well feeding information getting context to feed information better into the frontier models what's the plan for you guys yeah um I think if we wanted to do that we are fairly well positioned in the sense of like the experiment pattern that we talked about like the rapid iteration and being able to test these things at scale we our philosophy has always been we should give the best product I know I've been saying that a bunch of times but the way that manifests in like this specific scenario is assuming the cost and economics works right we would love to give everyone 01 there are other drawbacks to 01 that I think popular sentiment online so slow it's so right it's so slow it's so expensive so honestly is that the best product like may maybe not and that's why we haven't really integrated it um we're testing it out internally and it is it is slow and so it's the point where like if Sonic can just do it or or 40 can just do it we should just we should just do that um but we always want to use like kind of The Cutting Edge of intelligence and The Cutting Edge of intelligence like we just mentioned is across many different axes not just pure quality pure quality it's latency and it's cost and so those three things will inform what models are most relevant I don't want to be in a position where we're like married to a llama deployment that is just not the best model and suddenly you know open ai's new model comes out and it's just better on all axes like we should not be beholden to the fact that we sunk effort into this this llama model and like we built relationships there we should just be willing to always give what is best and so the amount of money that I'm seeing see going into the space these models are just going to continue getting better like like anthropic is probably cooking up something new um hiu will get better uh 03 will probably be quite good you're seeing this like deep seek stuff so like the entire industry is just kind of taking off and the models the intelligence is just getting so much better that I am I would always want to give the best experience possible so if that means a public model yeah we'll use that if that means an open source model we'll use that so that's that's really that's the way that we think about this problem internally okay that makes sense and and also when you mentioned the pro users right and sometimes maybe this might be the Super experienced IND hacker or a small three four people person team which I think we'll see tons more with the abundance of AI tooling totally you can accomplish so much more right yeah with pricing wise are you guys thinking of some thing along you know the Devon and chat gbt Pro type were giving people something way more powerful with way less limitation and um is that a direction that you guys would consider and uh it just seems that you know 20 $20 per month seems to be the ceiling for most AI consumer AI products if you go above that it's like how dare you I know the community goes on outrage but I can definitely see you know Pro users wanting a lot more yeah MH totally totally and I was actually just talking to a friend about this this morning it's like $20 is you know obviously there's different countries and and there's different currencies and everyone's in a different position but like $20 is a fair price to pay for such an increase in productivity and output um I'm not going to die on this hill because I know everyone has like different circumstances but if you think about like the US developer market for example $20 is a steal right and you know $500 I think that's the price of Devon like that becomes a bit more of a conversation but there is like a spectrum in this um if you want to do the the pulling and the research and the sentiment to see like what people's appetite would be for that I see no problem in giving people more and so when you you would be shocked at the amount of compute that actually goes into making something of this quality so we gave people the instead of these kind of like very very complicated tiering systems where we' have like a 500 and then a 200 and then a right now we have like a 60 and a 20 um instead of doing that we should just allow people to like purchase basically more credits with favorable pricing as credits as you increase more um and so there is a world where you can spend a lot of money and we see a lot of customers spending a lot of money on additional credit purchases so the ceiling is technically like infinite based on your usage of cascade if you wanted to do every change with Cascade people are out here buying hundreds of dollars worth of credits a month and they are able to to hit that kind of like prummer price tag but we don't want to like prevent people from using it if they just want to operate at kind of like a $20 a month tier so we're trying to allow for flexibility pricing is one of these things that someone's always going to be kind of upset about and so you got to kind of just like stick to your lane yeah I remember when when s was first released I looked at the price tag I was like yeah I'm going to lock in that price right now because I'm not getting anything better value than $10 per month and I'm GL I'm glad you did um yeah it's it's an interesting it's an interesting world but the nice part is and I hope this analysis is correct the cost of the current day's intelligence is going to be much cheaper let's just say a year from now um and that should just be hopefully favorable to this sort of pattern now you might say the model will get 3x better and the price will be 3x more and then in that case you know you're still kind of in the same dilemma um but yeah that's yeah hopefully we're we're in the right directional Trend I mean just last year we started the year with gp4 turbo at $15 per million input token and ended the year with deep seek V3 on similar intelligence level at 30 cents that it feels completely nuts I mean even it's like $3 yeah this is kind of what I forward to when you guys do DPC V3 and then give us a ton more even like flow actions that' be sick yeah yeah I one of my biggest priorities is just getting the cost of flow actions like a dream world of mine would be we can somehow price this thing and take into account the P99 of users and the p50 of users to somehow come out with a price that's like just don't worry about flow actions because I would agree it it it's it's tough to think about flow actions all the time and like feel like you're tied to a currency and feel like that the tool has to be always working for you um because the nature of these AI tools is that they're kind of unpredictable so I I very much empathize there the thing that is like the Holy Grail right you you remove the usage based consumption pricing and just give everyone as much as they want but so far with the current pricing it's pretty difficult yeah and there's a lot of noise online right give us 01 and all this stuff and it's like is that the full story there's a lot of stories around bring your own API key too that's another theme that we've seen part of me is like sure we'll give you your API key it's a bit of a work bit of a headache on our side but like yeah we'll give you your API key you're just going to pay 3x more than you would if you used our pricing you know so it's it's it's one of these things where it's like uh you know there's a lot of sentiment online but you just got to stay focused on like what's actually important yeah I think dealing with dealing with launches gets so much more difficult because compared to I think traditional software product AI cost scales so quickly with consumer demand and unlike software cost where your margin was already pretty high it's fine if you want to keep the price low for 4i like you look at that openi bill I'm sure you see some skyrocketing numbers in your first month I mean you wouldn't believe right like I'm sure you were tapped into this and Julia you've also used the product in this time period when we first launched like our providers have never seen a product with this level of growth right and so they they just don't have enough this is my perception they don't have enough Hardware to be able to raise our rate limits and so you're seeing people complain about oh I can't use the product like there's rate limits but it's all problems success and like people just had no idea the appetite and people's willingness to like people loved it right and it was great but you run into problems like that we like these things are Hardware constrained it's Nvidia graphics cards are are hard to find and so yeah you're kind of dealing with a lot of there's a lot of variables that go into just making the thing available yeah and I remember even just for September to October before wind Ser came out I thought oh maybe Cur has already won the game it's you know composer has been great that experience is great and then you you guys came about as like hey by the way we just did this here you go and then go oh this is so much better yeah need to beep that part out and well hopefully we're moving fast enough where we're able to provide more features I mean Wave 2 will be exciting I'm excited for you to get your hands on it I we got a number of things in there like the autogenerated memories that you just said I think the web search is actually like a a game-changing step function in terms of like the intelligence right you're suddenly unlocking anything that's available on the web GitHub links blog posts like you can literally have this thing just follow tutorials it's just you you talked about this too much can you show this to us now yeah cool okay yeah so what we basically did um all right let me give you a a good example let me find so one of the things that I've been it's like a fun thing is uh I've been using a blog post that I wrote way back on you know every now and then I like to document what I've been doing just to like put it on my personal blog so I kind of remember how things are done so one thing I was doing was taking this demo site and turning this into like I'd written a blog post on how to build a weit list and I listed out a bunch of the apis needed and all this sort of thing so one of the things that we can say is like build me a weit list page for this project that follows the instructions in this blog post so make sure in right mode there is now a thing called enable Cascade web tools um so yeah we're in it and then so this is so first it's actually going to I'll kind of walk you through what it's actually doing here so it's it's going to read the actual page and this is because I explicitly pasted a URL now you could ask a question that is more and we could do this after It'll ask a question that's a bit more like relevancy based and it'll probably do a search for it but in this case it didn't feel like it needed to do a search because we gave it a URL if that makes sense um so we've got that and then what it's doing is it's it's viewing this page can you see the oh I showed I can see oh I can't see the web page but I can see to the web page okay well yeah so there's a web page if you if you go to this link um and what it's doing is it's kind of like agentically looking through what is important so here you can see that there's three sections that are part of this um a part of this chunk right there's a section on the neon database there's a section on how to use codium chat which was at the time the way that I was kind of looked looking stuff up um and then there was also a section on how to configure an xjs uh and then there was also another chunk that it read about react hook form how to monitor the results and I I like this app called post to co so I wrote about that and then a little bit of conclusion so what it did is it looked at this it chunked it up decided that these were the relevant parts of the page that it needed to read in order to execute the query that I had so you're seeing that there's these um particular Pages close this out and then it's going off and it's summarizing a bit of what it's doing and then it's able to basically successfully oh yeah so we want to accept this um so we also have an terminal integration so there's this button called go to terminal which is quite cool um so you can actually look at this is a Cascade process so when it ran npm install it's actually running npm install inside of your environment so if you're using virtual environments or a Dev container or some sort of special setup it will recognize that um so it should be bit more seamless so in this case we're running npm install and then now it's actually going off and executing it even creates um writes out the SQL and all this stuff so it's for successfully able to follow the blog post and you're seeing that if you go to the blog post this is more or less like the instructions on on what you want to do I can now go through and like accept everything so yeah made the back end made the front end and because I wrote the blog post I kind of know that this is in line um another example so I want to show you search too uh there was a cool demo so one thing that I was doing was um let's see reset this there's another cool demo okay cool um there's another cool demo where you can ask ask it like kind of more like use the web search capability here so in order to stay relevant and like topical I was doing a demo with like squid game 2 um all my friends are talking about this this show so I was like all right let me like you know build something up this so I was able to say like build build me a voting um app that can let users select their favorite squid game 2 um character uh and then because of like training data right this stuff is not going to be available inside of its training set um I could tell it right now like look up the cast uh the current cast characters and what this will do is decide that it needs to look for information about like the actors and characters so here you're seeing um yeah so you're seeing that it's able to look at a bunch of different sites um there's this article this article Etc and then you're seeing so this is one of the drawbacks as web scraping our web scraping needs to improve but also you're seeing like a very content or a a uh sorry a design heavy site like Netflix is probably not going to yield the best results when it comes to actually like reading and web scraping so this is an example of it deciding okay this this is actually not that helpful let me go to the next one uh oh maybe that one had a pay wall who knows okay well it's I think very cool that's you didn't have to use any I mean two specific at keywords to trigger this thing that's the whole idea so that it tries to figure out it needs that addition no information to do that so much like the auto context and I feel this is the way that all of the AI coding tools uh I mean especially I think pioneered a lot of it by you guys yeah yeah I mean I think at is like a a pattern of the past I sometimes I like at because it gives me like a little bit of a dopamine hit that I'm like all right like I like I know this I know like it's really not needed and so this is an example of that like you could at web and you know we did introduce the concept of like all right like at web like you know whatever but this is the part that's agentic it's able to infer like yeah I should probably reach for search in order to do this and now you can see everything here is predicated upon um the page so this article and if you look at the article that was read like you can see this is indeed all the characters the the characters and and actors and actresses that play those characters and then it's able to use that as context going into here and now you can see you know you you know the magic of wind surf is able to successfully generate the the full stack application here um but like the these are examples of like if you ask it temporal questions like we can try again um you know what's the latest version of react and what are the breaking changes instead of looking for stuff that's in memory it's going to look online choose the best articles that hopefully best summarize this information um it's going to read content yeah looks like it's reading some of the the changes and then say even even for non-developers feels strictly better than chat GPT I I actually asked it this morning was the difference between cursor and wind Surf and it just it said I have no idea what wi do well yeah I think this is just where the agentic pattern just like differs so drastically from the non- agentic and this is like maybe a better way of just highlighting these things um trying to think of like other examples oh something I really like here um we get a lot of questions about how to use the product and so we maintained docs online so what I did is um I added an at oh is this merge in yes it did merge in okay so I was working on this last night so this is like very very new but there's winter help docs online right and one of the nice benefits of this is now because we can now scrape the web we can add it at I really see as a way to educate users on like what's possible so for example at wind surf help docs like um what is a flow action credit and now you're able to like actually rag or like I guess it's not really kind of rag it's like the agentic version of rag over the contents of our documentation and now get like self-help within the Cascade panel so here uh it read whoops um if you can see this so it's reading like the docs that we wrote about what our flow actions it read um how to view your usage like how to upgrade your clan like all these sorts of things and this is just like a nice side effect of the feature does it even analyze the me the images that gets fetched you know that's it doesn't right now um but like you can see how it pulled the information in P the information and this is what I'm excited the way we're building this it is not like how would you do this if you were not an agent you would say all right let me pull this page let me look at every single page that was linked from this page let me ingest every single image and summarize every image as well like you don't know what action to take next because it's deterministic whereas with this agent what we could say is based on this page we're looking at this content do we need to look at the image do we not need to at the image okay let's do run a multimodal on this image um cuz that is more expensive takes more time right if there's a link to another page we can decide on the Fly that's probably important for me to go look at like we had instances of this where someone will um paste in like I pasted in a nextjs doc and it was actually like I don't think you want this one I think you actually want like the one that's linked from here so it went off and like searched that one too and then gave me the right answer based on the contents of that pig page so it's really it's so it's so much more similar to how a human would interact with a web browser as opposed to Google search just one back and forth right it's like look at one do rag do the thing it's more look at the thing find more irrelevant information oh this dog is deprecated move on to the next exactly I remember having the similar issues for next js15 when it was released no agents I mean no models was trained on nextjs 15 data and they kept generating the wrong hashing formula every single time and you had to at docs or manually put it in in the rules it was very painful so I think that's like a a thing of the of the past um hopefully yeah you won't need to reach for ATS like again like I said like I said at is really just a nice way to um just like view yeah some like shortcuts in the cases where maybe five 10% case it doesn't work you know you have that backup that you can manually shove it in and say hey look at this thing exactly yeah exactly so very exciting this will be cool yeah you'll you'll use it in in a couple days yeah very exciting I think we heard a lot about you know your thoughts of future of agentic coding it's a very exciting world that we're heading into Super exciting I know it puts a lot of stress on you but Julia and I love seeing the competition in the AI coding space love watching Sidelines the progress has just accelerated over Christmas honestly you guys coming out every I mean there's lovable there's bold on you there's so many new things coming up I mean repletes and we get to watch it yeah y we're living it so I'm glad that I'm glad that you're you're seeing the benefit I mean hopefully hopefully we'll separate ourselves I mean I as a someone who's built this product I believe that we are I believe that we are superior obviously that the users have to learn that for themselves um but I'm glad that you two can use these products I like Julia you needed you should give it a shot um oh I actually did so uh I was telling epan this morning that uh three years ago I spent maybe two months with a college friend trying to build this application that would look into my personal journal and then produce statistics and find correlations between uh physical health and other aspects and uh yeah I built it this morning it's a nice uh streamlet app that's running on my desktop right now that is one of the best that I've heard that's fantastic than thanks for coming on to the podcast and I'm sure we'll be doing another one in well let's say half a year's time yeah I think things will have changed so much and I'm sure we'll be updating on a lot of our viewpoints that we talked about in this one of course yeah thanks for uh thanks for having me on it's been it's been a pleasure yeah thanks kin