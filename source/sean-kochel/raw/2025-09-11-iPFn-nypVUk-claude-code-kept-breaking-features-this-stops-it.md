# Claude Code Kept Breaking Features This Stops It

Published: 2025-09-11

I'm going to show you in this video how to create selfdocumenting AI code because the biggest issue in vibe coding is that a lot of the details of the features you build end up not getting used. Especially if you're an approve all edits type of person, you are going to miss out on those critical moments where Claude Code or Cursor or Gemini decides to gut out 50% of what you built. And of course, you didn't see it happen. So, you are none the wiser and you think, hey, it just didn't do it very well. But the reality is that under the hood, all of those features that you actually built are just gathering dust. It's kind of like the system defaulted to Honda Civic mode when you had already built the engine of a Ferrari. So, today we're going to put an end to that for good by creating self-documenting features. And I'm going to show you three levels to this system where each one is slightly more advanced than the last. So, strap in and let's get to it. So, I'm in the process of building this really cool YouTube strategy tool. And what it can do is it can analyze entire channels and then extract semantic patterns and predict the types of content that are going to be trending. And so, what we're looking at here is one specific view from that tool. And so, this feature alone took me a few hours to build. So it embeds thousands of video transcripts and then it can understand semantically ways of speaking, patterns of speaking that tend to go viral based on the performance of those videos. Now what I did when I ran into this error where the semantic chunking wasn't working is I went into my claude code and I did what most people would do. I took the error and I pasted it in here. Now what we can see is that what claude code decided to do is instead of actually fixing the function call which just wasn't using the parameters correctly. It decided to actually remove the entire semantic chunking feature. And I only caught this because I was paying attention to the exact outputs and what it was telling me it was going to do next. But if we go and we actually look at our file, we have a fully functioning file with hundreds of lines of code, almost 500 lines of code that is specifically built to handle that semantic chunking. And I had already tested this and I knew that it worked. So what happens is that instead of getting these deep content insights, we're just getting these basic timebased chunks. So it's basically like some simple keyword matching instead of something that's actually extracting meaning out of what is happening. So again, it's like a Ferrari engine sitting unused and we decide that we're going to just go ride a bicycle. If you're not paying attention to this type of stuff, you are going to get a lot of deleted features or deleted functionality where it might still be in your codebase, but your functions aren't actually calling it. And you know what? It's almost Halloween season, come to think of it. So drop me your feature deletion horror story in the comments. How many features have you lost without even knowing it at the time because you were not paying attention to the output and you didn't have that source reference of documentation? So, in order to show you this, what we're going to do is we're going to go build out really quickly this feature and then once it's done, we are going to document that feature. So, we'll let this thing ride. It's going to go out. It's going to build a feature that allows us to query our database and search for certain things. So, once this is done, we'll move on to the next step. All right, guys. So feature just finished getting built, took a few minutes, and now what we're going to say is document this feature that we just completed, how it works, what it connects to, etc. Then write a descriptive git commit. And so we'll come back in a second and check what it made. And so we can see the output of this is a pretty good feature documentation because again, we didn't really give it much guidance on specifically what we wanted to see. We just said, "Hey, build me some feature documentation about this thing that describes how it works." And so we get an overview of the architecture, the different uh components of that architecture that were made like the service layers and the API layers and what was created, how that interacts with our uh database. So the database schema updates, the different API endpoints that we made, what type of bodies they accept as part of the response, what type of response it sends back through the API like to the front end, what are some advanced functionality that we have, how does it all work, and so on. So overall, like a pretty robust documentation about how this specific feature works. And so what you're going to immediately notice when you start doing this is that any feature that you build that is based on this root core feature that you just documented is going to be done a lot more often correctly the first time. So no more having to go back and forth three and four time and revert commits and restore checkpoints because it broke something or didn't understand something. It's going to have a lot more context now about what exactly it needs to do when it uses that feature. Now that happens because we remove the ambiguity about the different features and how they function and how they connect to one another. So when the front end now goes to make a request for example or wants to hit this endpoint, it's going to have a pretty specific documentation about what it needs to send and what it should expect to receive back. So, what this is going to do is it's going to really help you cut back on the number of debugging sessions that you have to do and no more torching your codebase accidentally at 2 a.m. because you went a little too hard without real understanding of the features and how they work. Not to mention, in addition to the increased speed of being able to develop new features, you're also going to get a much higher quality out of each feature you build. So, this basic system honestly just saved us hours. But what if we were able to codify that a bit more and make the process a little bit more streamlined and predictable? So, here's some documentation from three recent projects I've been working on. This first one is a Chrome extension that I'm building which is related to this other project we've been looking at. And it's only real form of documentation is through comments, right? And so this is helpful if you're a person that's just looking at this thing, but it doesn't really explain how the system as a whole coordinates with each piece. Now, if we look at this other prompt wallet project that I was working on, we have a basic readme in like the root of the project that explains how to kick it off and how to get started, but there's zero documentation about how this tool actually works. Now in my forkcast project when claude code sees a project of this size where I have the backend repository and the front-end repository basically in the same project folder there are hundreds of files across different folders different directories multiple service layers. It really has no context about how a lot of these things actually connect in practice. The only context it has really is me making calls out to certain functions and understanding that certain pieces connect based on how the current features of the app are actually being used. So what ends up happening is it will often rewrite components that already exist which will put you in debugging hell. Terrible place to be. Or it will otherwise start breaking stuff that was already working. And so what happens is we often end up with just this really inconsistent, messy documentation across all of our features, not necessarily being updated after you make changes to those features. And it makes this entire building process very hectic. But luckily, we can overcome this through a basic slash command that can automate pieces of this process. Now in cloud code, the way a slash command works is you create this directory inside of yourclaw directory called commands. And then inside of commands, you can provide a markdown file that you can call basically at any point in time. So what you need to do is you need to first exit out of your cloud code instance and then open it back up and anything you added into that command folder will now be there. So if I was to type in doc feature, we can see that it now has this command that we had created. Okay, so we're going to let this thing run and then we're going to go look at what that prompt is. And now we can see we already have a much more structured type of documentation where we're providing direct links or references to important files that this feature kind of touches or uses, what it is meant to solve in the first place, how it solves that thing, where it fits into the overall architecture and data flow within the app so that it understands the different pieces and at what point the pieces come into play. the core components that we built, how those things actually work, the methods that we have for those, and what or when the methods should be used specifically, all of the different endpoints, and so on. It goes on and on and on and on. So, it's a lot more specific and relevant to what we would specifically need again if we were trying to work with an LLM and give it the context that it needs and nothing more. Now you could even take this up a notch and create a command that for example updates documentation after you have updated a feature that you had already built and you want to make sure that the documentation you already had gets updated accordingly and leaves notes about what it changed and why it changed it. So this type of stuff can change your entire development workflow where you go from three, four, five broken features or broken integrations every week down to zero or one. But now the obvious next question becomes, could I run this thing automatically every single time so that I don't need to provide the slash commands for it to go out and run this thing? And the answer is yes with sub aents. So what we're going to do is we're going to come in here and we're going to try to get an understanding of how far along we are complete in this. We're going to have the system complete the build of that feature and then if it is working properly, it should automatically document what we build. And so I am going to ask it to do that. So we're going to tell it based on the um specifications that we have for that specific feature. I want you to see how far along it is, if it's complete or not, finish what is not done yet, and then document everything is what it should do. I didn't tell it to document it, but again, if our agent is working properly, it should run. So this system here should work with any IDE that supports sub aents. So, if you're using a coding tool that allows you to kick off sub agents, you should be able to use some version of this. I'm obviously doing it with claude code. Now, the prompts for the slash command and this agent definition are available for free below the video, so you can go check those out and look at them in more detail. I'm going to cover the high levels for a second while this thing's going. So, first things first, this thing should proactively kick off anytime we're building a new feature, making a significant code change to an existing feature, or when we're creating text specifications for something that was not in the original project scope. So, if we're starting to branch out from the architecture and the user stories and all that stuff that we had already started the project with. And so we're providing a few things, links and references to other files that are important for this feature to function properly, where it fits into the overall app architecture, what are all of the primary components that we built as part of this feature, and what does it receive? What is it meant to output? Where does it live? How does it connect to everything else that we are building? What are the different dependencies that it has? How does it need to be configured? Was there anything we needed to change in our database? Right? So, we're going on and on and on just giving a lot of really detailed guidance around what this feature is and how it's meant to function. And now that this thing is done, we can see again really robust feature documentation. All of the all the different files that were updated as part of this change, which is great, right? Because if something were to break now, I know that I can just go back and reference these files specifically and ask where it might have broken, for example, in those files specifically. We then get down and we can look at, for example, the actual architecture of the app and where this fits in specifically. So in the context of like this YouTube tool, it integrates with the current YouTube transcription service, the Q processing system that I have in place, the environment variable configuration had to be changed, right, to use this proxy service. We now have an understanding of exactly where the data flows through this system from end to end. We get into the core components of what it actually built and how those things work. So for example the manager for the actual proxy configuration what does it take in what goes out where is the location of that change and what are the key features implemented as part of that change. So again, really detailed documentation about what exactly we built and how exactly it works, which is really helpful for us to go back and reference, but again also for a system to reference when we want to go debug this feature down the line or add something on top of it. And we can say, "Hey, before you go and build this next stage, I need you to go reference the IP rotation systems technical specifications." Now, if you pair this with automated Git messages, you're on your way to being a true Vibe Chad. So, these types of systems are the ones that will enable you to build a lot faster, but also with much better quality. Whether your dream goal is to tinker and build for yourself, or you want to build something that might actually turn into a business one day, processes like these are going to be critical to your success. So, if you want to take active steps toward being an advanced vibe coder, self-documenting loops like this are the easiest tool for you to add to your arsenal. So, there you have it. Three approaches to self-documenting code that you can use no matter your experience level. This will help you build faster, sure, but more importantly, it's going to help you build with more confidence and more quality in what you do because outside of it providing additional context maybe to a language model, it's going to be great for you to be able to actually look at a feature when you need to and actually understand how it works. So, it's not just about token efficiency and whether or not the documentation we built was the most efficient with the tokens. It's about how we're using that to develop systems that can code for us autonomously where we can become the director of that process instead of being in the weeds in that process. So, if you like videos like this one, make sure to subscribe to the channel so that you can get more in-depth, grounded, down-to-earth tutorials like this one. So, that's it. I'll see you in the next