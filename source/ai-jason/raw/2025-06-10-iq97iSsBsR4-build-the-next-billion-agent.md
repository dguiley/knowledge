# Build the next Billion Agent

Published: 2025-06-10

I want to show you how can you build your own cursor for X a genic software that can complete specific task in certain vertical you're familiar with one of the most interesting thing in 2025 is that vertical aenic software going to be where the value going to capture AI coding is the first agent use case that hit a real part of market fit and we saw some insane reu growth across almost all AI coding tools but what I believe is there will be so many different vertical agents to be built for the next 24 months and your capacity was talking about cursor for slice should exist but didn't. Then immediately we start seeing people building prototypes for this cursor for slice part and there will also be cursor for spreadsheets, cursor for design and cursor for video editing. There will be so many different vertical agents that can be built that streamline the whole end to end process and integrate deeply for certain type of knowledge work. And that's why today I want to show you how can we actually build such cursor for X a genic software. So how do you build a cursor or a Jenga software? The most common and adopt a pattern is that you need to build agent that has access to different tools and assistance to be able to complete certain valuable tasking and workflow. The example for cursor is that it's able to write codes create new file run command line and even do get push search for the latest dog stuff like that. So this is the agent that you need to build and on the other side you will need some sort of specialized playground or canvas to help users to review track progress of the work that agent delivered as well as co-working with agent. Again if I take cursor as example this playground canva is a code editor where users can see the result comes through and jumping in to make changes if they want and all the context on the left side will be automatically bring to the agent chat. So agent will always have a context about what a user is seeing here and there are many examples from cursor wind surf to Google stitchy which is UI generation platform or even software like clava which is building cursor for video editing you still have this kind of chat experience on the left side for user to interact with AI but on the right side you can design best UX for user to review the result and I personally believe there's just so many opportunities to build cursor for X it could be cursor for writing cursor for video editing cursor for even planning a PRD. That's why today I want to showcase how do you build such cursor for X system. But before we dive in, if you're a soloreneur who are serious about building AI startups fast and on budget, there's an insanely good free resource you need to check out called How to Build an AI startup in three hours with less than $500 by Greg Eisenberg. If you don't know Greg Eisenberg, I've done a podcast with him last year showcasing my AI coding workflow and he always had ton of great idea about what type of product idea to build as solopreneur. In this free resource, he walk us through a real five-step framework using agents to replace devs, marketers, PMs, literally building a whole star solo with AI. He talks through platforms and places where he go to research and find the right product idea to build as well as his specific process of how to scope out the MVP the minimum variable product so you can bring your idea to market as fast as possible using tools like manus lindy and even cursor itself as well as his secret source of how to do vibe marketing. Everything in this PDF aligns perfectly with what I'm going to show you in ter of building this agent software. So if you're a soloreneur who are trying to build a product fast and shipping smarter with AI agents, definitely go and check out this free resource. I have put a link in the description below for you to get this awesome resource for free. Now without further ado, let's get into how to build such cursor for X platform. So we're going to build the whole agentic system using Versel AI SDK. If you don't know Versel AI SDK, it is open source package created by Versel. They allow to build aic software including backend, front end in Typescript. There are a lot of companies like Perplexity Vzero all built based up pawn AI SDK. So it's production ready and extremely simple to set up. And if you're not familiar with TypeScript also don't worry I'll take you through step by step. So Versail AI SDK has two main parts. One is core which allow you to set up aic or large learning model and UI which allow you to stream results to the front end very easily. With AI SDK core you can connect to different large learning model provider. Traditionally, each provider has its own syntax. And with AISDK core, you can swap out different models without changing the underlying logic in your codebase. So this will allow you to experiment different models much easier and they also provide you ways to build agents connect to different tools and MCPS as well. So this AI SDK core on the other side, they also have AI SDK UI. It will enable you to stream the results no matter whether it's text structured output like JSON or to call on the front end in a very efficient way. So you can build production level a genetic applications. I'll cover both parts. In the end you will be able to build a cursor type of software is helping you generate PRD and learning content. Firstly let's cover the AI SDK core. So vers SDK provide a few different functions for generate text generate object which is structure output as well as tool code. So you can convert that to into a agent very easily. To demonstrate that I will open new folder in cursor and do pmppm init to firstly set up a typescript project. Then we're going to install AI SDK. Just pmppm install AI. This will add the versel AI SDK and I can create a main.ts file. So to use that I can do import entropic from AI SDK and tropic. As we mentioned before vers SDK allow you to call different model provider. All you need to do just install separate package for different model provider. So if I'm using entropic here I will open terminal and do pmppm install at AI SDK/entropic. But if you want to use open AI, you can just change this to be open AAI instead and import that from the package. Then I can define the model entropic by passing on the model name here. Next, I will import generate text from AI package and create a function answer question where we're passing on the prompt and inside this function, we just call this generate text function and passing on model and prompt. This will return object that including text property which is a string. So we're going to return text and we can call this function in the end. So that's pretty much it. I will quickly create a Menv file and add my entropic API key here and in my TypeScript I will import this EMV file and also do npm installv. So now I can test run this script. I can do ts node main.ts and when you run this function you will see the result showing here. If you haven't installed ts node it is basically package that allow you to compile your typescript file into javascript and then run the javascript. You can do pmppm at ts node typescript. So this is how you can use AI SDK to generate text. As I mentioned before, they allow to do the streaming extremely easy. So we can just change this generate text to be stream text and instead of using text, it will be a text stream. Then we can do a for loop to print out the result in console log. So text stream will continue stream the result back. If we run this, you can see that it will actually return the stream out the result. So you can reduce the latency and provide much better UX. So this is basically the AI SDK core. Very simple. You can also pass a system prompt here like you always return in all caps and if we do it again it will behave differently. Meanwhile, one really cool thing is that it'll allow you to do structured output but also stream the structured output and this is quite difficult to do with Python or I wouldn't aware of very easy way to do that Python but with Bristol AI SDK is extremely easy. So I can change this to be stream object. All we need to do is just passing on a additional property called schema. So if you're familiar with Python you probably use uh like pandantic but in Typescript you'll be using zot. So open terminal and do pmppm install zot zot is basically pandatic in typescript. So I can do zobject title z dot string and then passing on a specific schema with title author data and content. And you can also add description as well. So the author I can just add describe the author is always JSON and if you're familiar with the concept of structure output those description as well as title here will basically help agent to understand how to generate those data and instead of text string it will include one thing called partial object string it's basically partial JSON so if I run this again it will return a JSON and stream the result here. So this how you can stream structure output but more than that I will also show you how easy it is to build an agent with AI SDK. I'm going to change this to string text and we can pass on tools as additional properties. So our import tool from the AI SDK again and we can define a tool called weather by giving the description the parameters which is input and the function it needs to execute and our swap text to response response including everything like the message as well as two calls. So if I run this you can see that it has message here that assistant called the tool and tool got executed as well. And what's really cool about this is that you can actually change this to be an agent by passing on a property max steps. So if I set a max step as 10 and run again, this time it actually run a for loop where it generate two call it call tools and finally generate the final message. So you actually don't need to build your own agent runtime. All you need to do just pass on this max steps. So this is kind of fundamental of AI SDK core. If you want to learn more in depth, I have a whole section in AI builder club about how to build production ready large language model application where I will take you through step by step in depth of some advanced tips in terms of using cell AI SDK to build such a generic software effectively. I put a link in the description below for you to join if you're interested. Now I'll also show you how to use AI SDK UI to quickly build a web application with this chat agent. So I'm going to open cursor again and this time let's set up a nextJS project. Uh I'm going to use chassen as a UI library. So we can do mpm dlx chassen as latest initial in it. I'll choose next.js and name could be cursor for x and you can choose any color and I'll do cursor cursor for x. This will open cursor in that specific folder. So now you'll see that this nextjs app has been set up. Your homepage will be in this page.tsx. So if we run pmppm devaf you can see this page has been loaded which is whatever displaying here. So now let's say want to build such a system where users can chat to the agent and agent will be able to do some task present result in the canva on the right side. So structure is that on any web application you have front end which is one you see here that rendering the UI for the user and back end which is actual functionality. So we will set up API endpoint first where it will use a stream text to create that agent back end which is similar to what we just showed you earlier and then on the front end I'm going to show you how do we use AI SDK the UI part to get the results from stream text and present on the front end. So firstly we will need to create a API endpoint and the normal structure is that we'll create a API folder and inside there we will create another folder called chat and inside we will create a route.ts ts our import openai zod stream text data structure return as we see earlier looks something like this it have row content and also two invocation so two invocation will be showing the two call and it will have different state so partial two call means it is still generating the two call inputs and the state call means it finished the two call now it's actually executing the function and result means it actually get result back so you can use this to display different sort of UI for the function and here we just created interface which is define the data structure so you can use to validate any function to and making sure passing on the right data structure and then let's say we want to give agent two different tools one is get location another is get a weather here I will just create two mock function for demonstration so we're define the latitude and longitude then this is just syntax in typescript for it to define the type so it can automatically validate if it is actually passing number as latitude same for get weather then we can define the actual endpoint by doing function post so When we call this API endpoint, we're probably passing through message. This is syntax in Typescript for you to get a specific property from this JSON. This is same as getting data and then getting specific property within this data. Then we can call this stream text passing on the model system prompt message as well as the tools which is similar to what we just showed you earlier. And we'll return result two data stream results. Here I forgot to add the type check for the message. So this is the API endpoint for chat. Then we can go to your homepage let's say and I'm going to replace this uh firstly I will do use client to indicate that this is a front end client component because that typescript at default is always server side then I will do import use chat from AI SDK react so this use chat is a component that allow us to stream the result by calling this use chat passing on API which means it will send the request to our chat API endpoint and set max step to be five so it will be a for loop autonomous agent that run max five steps and we will get a few things back. So message is actual message history which it contain the data that we're going to use to render on front end. So input and set input is a state that use chat return to indicate what type of value is inside the chat input now and a pen will basically send a new message to the agent. Then we can write a front end here where it has input the value is the input of this chat and every time when the input change it will set input here and if a user do enter then we will trigger the agent and passing on the latest message and in the end this message map will show all the message from the agent. So now let's try to run this by open terminal and do pmppm dev. And now if I open terminal so UI here you can't see anything but you will see that this input on the top left corner and if I do hi you can see that the result has been showing here and prompt check my weather it will call to and return me the result. So this example of how to build a chat interface and obviously the interface looks really bad but this is kind of easy part. We can also render the two call better as well. So this quick version ask cursor to do if the message has two invocations then we'll display those two invocations inside this two invocation render. So each two invocation will have two name two call ID state arguments which is input as well as result. So if the state is partial call or call then we will show it loading state the two name as well as the inputs. But if it's already completed then we will show the inputs as well as a read off. And now you get this pretty good chat agent experience where it can talk to you and complete actions return results. But those are just some more simple functionality. Quite often you want your agent to call another sub aent or using a tool that is actually calling large language model that can take a while for it to run. In this type of experience you actually want it to stream the results back to the front end while the tool is running. And how can you do that? Versel AI SDK natively doesn't support that. You do need to update a little bit and here is how you can do it. So I can create a function here called generate prd that is calling another large language model. So if the agent just call this tool this stream text is not going anywhere and what do you need is this create data stream response function from versel AI SDK. This allow to merge multiple different stream together and push custom data to front end. So for this endpoint instead of calling the stream text directly we're going to return this create data stream response and inside this function we will have this execute function. it will have this data stream writer that allow to send more data. But let's say we have this tool called generate PRD inside this generate PRD execution. I'll call the generate PRD function that we defined earlier which should return the stream text object. Then I will have this for loop for each chunk from the PDF stream. We'll do PDF stream for string. This will return all the stream events and for each chunk from the streaming if the stream type equal to text delta which means it's getting new text then we will do this data stream writer.r write data send a new text delta into the data stream and this will basically send new text data as we go but I would suggest you add more metadata here so you will know what this data is about and then we'll join all the text chunk together so we get the final prd content and in the end we'll do result merge into data stream with this data stream writer so result is the original stream text of our parent agent and merge into data stream will connect two data stream together so with this one You can basically send any source of data back to the front end. But those data won't be showing as part of message. You need to get a new property from result called data. This will contain those custom data that send from the endpoint. So in our case, I can create a new function called PRD display. So here we will filter out all the data with this type PRD content and then we'll group all the content based on different tool call ID and in the end join all the chunk of data together and display the full content and there are some logics to render it on the front end as well. So here is a quick demo. If I give a task generate PRD for to-do app it recording this tool but here is a mock I put in here that will stream the results of the nest to call. So this example of how can you stream the two core response back to the front end. So got agent part working well and stream the data. Next we need to build a playground or canvas to create a space for user to review the results from the agent and co-working with agent. So to implement the playground on the right side we need to create a UI component for the playground. And in our case we can build a simple text editor for helping people build PRD. But apart from the UI itself, we also need a way for agent chat to communicate data back to the playground. So that when agent try to generate like a PRD doc, it can safely generate data into database. So next time we open the page, it's already showing up in the playground. But apart from long-term persistent database, we also need something called state. So state is almost some sort of short-term memory that share across different components or within a component. For example, now we probably have a state called current PRD doc as well as set current PRD doc. Those states can be shared across those components. And why do we need state is because it's much faster since we want to stream out the result as we go. But meanwhile, we are also going to store that into probably a PRD doc in the database as well as a conversation message. And to implement this just to keep the application more maintainable, putting all the logic into one page.tsx file, we will first restructure this page into different components. I have a project page that has this kind of split panel layout and I will turn our current chat UI into this chat panel and the content panel to the right side and then we'll implement a state to share across this two panels and in the end we'll connect to superbase to set up a back end. So for this UI restructure I think the requirement is pretty clear already. What I'm going to do is I'm going to ask cursor to do it. So I'll give a prompt. Now let's do a UI restructure. I want to create a project/p project id page. So this is just syntax in next.js JS means the URL will look something like perjury id and inside project id page it has split view left side is chat right side is content panel showing the prd doc generated and create a chat paneltsx component and create content panel component and in the end create a state that is shared between chat panel and content panel so we can stream a data result to content panel I will trigger that okay now we have this new application UI that has two different components left chat and right size documents and this one folder per id has been created and here we have a shared state called per data so state you can consider as a short-term database or short-term memory every time the state chain it will trigger the UI to be rerendered and normally comes in pair it will define the state data and a function to set a state data so here we define this project data with a set function to set a message data and it's loading then we'll pass this set data to chat panel so that when chat panel receive those additional streaming data from the API endpoint. It can set the project data which we'll be using to render on the content panel. And now if we go inside the chat panel, it will have those functions still to render the tool response message and the actual chat panel function will receive project ID and set project data function. And we will do this use effect. So use event you can consider uh as a kind of event listener. It will always monitor those data that you put in here. So every time when message lens change or data lens change or is loading state change it will trigger list of function you define here. So here we're basically saying every time a message or data changed then let's set a project data again and the rest is kind of similar to what we have before and inside the content panel we'll create this prd display is join all the chunk of prd dog into one and display on this content panel. So now we have a split view. I can ask it to generate prd for me for a to-do app. Then on the right side it will be start streaming the data. I can view those content. It will automatically generate V1 V2 based on time stamp. So if I ask it to generate again with some charts. Now it will switch to V2 and show me the list of data here. So this how you can create a genic system that has both chat experience and playground using Versel AI. If you want to learn more, there's a one section in the AI builder club called build production launch language model applications. And there's one section I just added for Versel AI SDK that has detailed step-by-step breakdown of how to build a system that I just showcase you. And I will also attach a GitHub repo there as well. I'll cover in a different video about how to connect this to superbase back end and set up a user OS and usage based pricing tier. So if you're interested, you can click on the link in the description below to join AI builder club where we're going to have a 30 days challenge for you to build a cursor for X application. And for every week during the months, I will take you through specific parts of how to build such system. Meanwhile, I also made a new version of SAS launch kit that already have the authentication and usage based drive haven built-in. So you can focus on just building the agent itself. I hope you enjoyed this video. If you want to see more of this type of content, please comment below. Thank you and I see you next time.