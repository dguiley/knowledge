All right, here we go. I just returned home from the AI Engineer World's Fair in San Francisco, and wow, was it intense. This is the largest conference for applied AI engineering in the world with 3,000 of us, including founders, AI engineers, and traditional ML AI researchers in attendance. To quote several of the keynote speakers up on stage in front of all of us, "Software engineering as we know it, for veterans and newbies alike, is dead. We are no longer building for humans, but rather for agents, from software architecture to the new BTOA economy, which I'll explain in a sec, to swarms of containerized agents doing work on behalf of us. From A to Z, the world is changing. In light of all of that, I knew I needed to give a talk to this group called Foundations where I spent a lot of time in Seattle alongside about 220 other founders. The biggest insights and takeaways that I came back with from the conference. These are the four core things I thought were the most exciting, also the most scary, but for sure the most transformational. I had to narrow this list down from about 50 items. So, without further ado, here they are. Bye. Bye for Yeah, it's it is funny uh just the amount of granola recording that was happening. So I I feel like I'm trying to embody that uh to give you guys a sampling here. Um well, hey everybody. Uh yeah, I'm Patrick Ellis. One thing that just kind of framed the conference, there were about 3,000 engineers there or AI engineers, you know, founders, other uh types of folks. And um we had, I think, 224 talks in total. So it was uh a lot. Obviously, there were like 10 running at the same time for the most part. So, we're doing our best to give a summary. But one quick uh kind of tip for conferences and uh everything I found is basically scraping the website for all the information about the talks and the general um uh categories and then uh using Gemini along with all the granola notes that I recorded from all the talks, my manual notes and then like other key takeaways to help kind of form and like pull out ideas. I feel like that really helps frame things and then you can also use that uh to help shape further exploration or apply those ideas to your startup and like your current road map which has been really helpful. But yeah, the first of the four uh themes I wanted to highlight is that context is everything and it's your new IP or intellectual property. One of the most influential talks from my perspective was the actually the very end talk by um one of the OpenAI members. I've got it linked down below. Uh I also have a QR code at the very end of these slides that will link you to the AI engineer uh YouTube channel and they've got all the content or eventually well they don't yet uh from the conference that will be posted there. So if you're interested in any of these topics going there sorting by popularity and uh uh searching can be really helpful but yeah so uh the spec is everything. The idea the analogy was to a binary where you have your source code and you compile that into a binary. That's essentially what OpenAI and others are kind of thinking about in terms of all the context the business processes the uh specific workflows the all the data that we put into shaping a great prompt is kind of like the source code now and the output is a much more ephemeral. we're kind of uh you know vibe coding in some cases these different products that come out of that uh process. So really heavily investing in the process and the actual prompts and the MCPs and everything that feeds data in your organization to the software development life cycle based around using LLM to generate software is becoming critical and really not just throwing away the prompts which is kind of crazy if you think about it as source code but having a way to manage and uh hydrate that with as much context as possible. One of the other things uh I wanted to highlight is just the importance of giving the LLM's context. Context is everything. One strategy is almost closing your eyes for 30 seconds and then kind of waking up and thinking, okay, if I was the LLM and I only had what the person just like gave me into this little box I'm in, could I do the task? And a lot of times it's pretty unreal how little context we're giving these LLMs. But if you have tools through an MCP, if you have a you know well-written prompt with a lot of context, access to the repo and the other services that the the uh the the startup is using and like of course your own uh road map and other product docs so much more helpful. So just thinking about having empathy for the the model and giving it what it needs to perform. Another one is MCP is is everywhere as you guys have all seen at Microsoft build native and Windows uh Gemini OpenAI obviously anthropic everybody's adding support and one of the coolest insights was the businessto aagent economy in the future if you're not discoverable by agents via MCP most likely or as an MCP then you're not going to be a part of that environment that economy so being able to be LLM first in your design for example having markdown uh options like one giant markdown file or an LLM.txt file in your documentation is critical in addition to having MCPs to allow the agents to kind of self-negotiate and find these tools. One idea and the startup uh is already doing this. I think I've got it here. Yeah. Is um uh being able to actually make purchase decisions. And if you think about it, they're already aiding us, these agents, these LLMs, in making purchase decisions as we're researching and thinking about what vendors, what uh cloud software uh we want to use, what open source packages. But in the future, they'll probably literally be transacting and actually making like end to end those purchase decisions. So starting to uh expose ourselves to that method of distribution, the agent economy through LLM primarily, but also things such as having an LLM.txt txt file which is basically a site map but for LLMs and other things Carpathy's quote I love from a tweet LLM don't click uh don't like to click they like to curl is a really great one of they're not using your UIUX like a human would of course they're they're just curling uh using Bash or whatever uh tool to get the mark or the um XML and HTML from your site but it's way easier for them to understand and to not have all that distraction being able to have just like a pure XML or markdown file for example. Uh so Carpathy actually had the idea of uh copying all docs to clipboard um which is really helpful. And then uh the last point here is the thinking about your engineering team for not just people not just humans but also agents thinking about us as orchestrators. We're providing the context. We're providing the the tooling, the environment for these LLMs, not just for engineering, but for business strategy, for marketing, for more and more of the parts of what we do day-to-day, especially as startups and lean teams. Giving them access and creating an environment where they can thrive and have all the tooling that's needed is is uh core to think about. I also have recommendations under each of these slides uh for ways to take action on these different topics. And then uh there's a GeekWire article with 11 takeaways we had from the conference. and then the AI YouTube uh uh engineer channel that I had mentioned earlier which I'd highly recommend. [Applause] Thanks for watching. I have a massive amount of insights and other resources from the conference. So, if you're interested in hearing more, please let me know down below. And with that, make sure to subscribe if you're interested in following along our journey as we continue to scale one of the very first fully AI native startups. And as I share more principles that I've learned as I've gone from being a fullsack software engineer to an AI engineer, it is an exciting time but overwhelming as well. So I hope this helps.