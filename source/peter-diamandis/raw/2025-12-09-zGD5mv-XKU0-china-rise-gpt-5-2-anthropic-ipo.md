# China Rise GPT-5.2 Anthropic IPO

Published: 2025-12-09

China [music] is accelerating its push to become independent of Nvidia with uh Cambercon planning to triple output to a half a million accelerators in 2026. [music] >> I fully expect as I've mentioned on the pod in the past that we're just going to see >> having an open-source model that you can test as you're developing it really closes the feedback loop a lot more aggressively here. And most of the Chinese models are optimizing around this very sparse [music] type structure with deepsek and similar arches with muon [music] kind of acceleration. So you're getting towards one architecture that they can just engineer and output industrially. And who's the best at industrial manufacturer? >> The challenge with China is people don't trust it. I think we're going to see a Cambrian explosion, no pun intended, [music] of architectures coming out of China now that China has been effectively decoupled from the US [music] tech stack. >> So, stepping up a level, is this good for humanity or not? >> I think the big question is what does the finish line look like? >> Now, that's a moonshot, ladies and gentlemen. >> Anyway, I'll I'll get us going in a second, but what a fun a fun day yesterday. We were all in Seattle. Uh Sem, we missed you. You were in Brazil. Good morning. You arrived from Brazil. What? At 6:00 a.m. this morning. >> Yes. >> Yeah. >> And got an hour and a half of sleep and so I'm foggy as f. >> All right. Well, hey, that means we all have a shot at you. >> But I'm I'm just back from Rome and Ahmad's in London. Let's let let's kick off with the uh the covering the world we've got going here. >> Yeah. Fantastic. >> And uh Alex was just back from San Diego. >> Yeah. And God knows >> Yeah. I just got back from Vietnam and Japan yesterday. Look at us traveling. >> Globe trotting, gentlemen. It's like uh you know, no time for sleep. >> It really is. [clears throat] I mean, I feel like we're going 24/7. I don't know about you guys, but >> Well, look, if you want to transform the world, you have to go out into the world, right? And and I think that's what we're all doing. >> Yeah. >> I think that's a good opener, too, cuz Peter, you just got back late last night from Seattle, and that'll come out in a couple days. >> Yeah. >> If we just mention the whole world that we've covered in the last week, that's pretty good. globe trotting. But uh a lot going on. Uh shall we jump in? >> Yeah. >> Is that enthusiastic? Yes, everybody. >> Yeah. [clears throat] Let's get in game time. >> Make it happen. Engage. >> Trying to trying to find my neocortex. >> It's there someplace. Don't worry about it. It'll show up. All right, everybody. Welcome to Moonshots. This is the conversation that's changing the world. Uh hopefully we can help you get ready for the future. Uh, and this is the news that if you're not watching the Crisis News Network and you have time to watch Moonshots, we hope we'll deliver to you sort of what's going on, what's happened the last week in AI, robotics, data centers, energy. Uh, it's a lot uh here with all of my incredible moonshot mates. We have a uh let's see a five-fold increase in capabilities here today because not only do we have AWG, we have EMOD as well, SEM, DB2. Uh it's going to be amazing. All right. Uh going to jump into our first stories. We're going to start with where AWG was last week, Nurup's 2025. So, Alex, this is you. >> Yeah. >> Yeah. Uh Nurups this year was a bonanza. I've called it in in past Woodstock for AI. A few observations. It had more than 29,000 registrants this year, which is almost 50% increase over last year. It was enormous. >> The Alibaba, the the Chinese lab, had 146 papers accepted, including best paper award. Anecdotally, the language that I heard the most in the hallways was Mandarin. There was a a sense that the frontier labs have all the resources, the academic labs do not. And the frontier labs were at NERIPS mostly to recruit academics. American again this is sort of uh sense of the the conference if you will. The the frontier labs and the frontier research coming out of the labs has largely gone dark. So what was being shown on the research end was largely coming from academic resources or academically resourced labs that are lacking the resources. There was on the sidelines even though Frontier Labs were there to recruit the the publications and the oral presentations at this point largely not coming from Frontier Labs except for Chinese Frontier Labs which is also >> So what is Nurip stand for? First of all let's start with that. So, Nurips, [clears throat] formerly NIPS, stands for neural information processing systems. So, it it is the largest AI conference in the world. It's held once per year, every December, and I it is where some of the the most striking AI research historically has been published. It's also the place the the one time per year where all of the frontier labs are all under one roof and and you get really a sense of of the pulse of of the AI space just from from being there. Some of the most interesting meetings happen in the hallways. Uh Optimus Gen 3 humanoid robots there in force. You you also see a a sense of the the vibes the the the zeitgeist of AI right now. So you can see um these are a bunch of photos and and video I took from from the conference. We've talked on the pod in past about how Chen Zuckerberg initiative is now pivoted to solving all disease with AI. And that that solve everything mentality that math, science, engineering, medicine are just going to be solved imminently with AI was very much on the show floor to the point where it made banners. It it was it really I think such a wonderful wonderful way to tap the zeitgeist of the space. >> Amazing. We should >> It's interesting to see that a lot of it is hardware, not and much more than you'd expect. >> There's a lot of hardware and and the the feeling of the moment is that robotics in particular is the next big thing after agents. I should also mention a lot of the attendees watch and are fans of moonshots. Uh and I I think there would probably be a lot of interest if we were to do a recording in the future from Europe's or ICML or ICLR. >> Well, it's a global thing. I don't know what all over the world. >> It's kind of like the Olympics. It's in a different city all over the world every every session. So, it just happened to be in America this year. But where is it next year if we want to record? >> I don't think they've announced that yet. >> It's in San Diego again. >> Is it really back to back? >> That's that's easy. New reps 2026, here we come. All right, let's let's move on. >> There's something interesting that I think I should point out. So ICLR which is another similar conference the number of first author affiliated Chinese papers went from 9% in 2021 to 30% this year and the US number went from 52% down to 36%. I think we saw something similar with Nurups but it'd be good to crunch those numbers. I I think we can't emphasize that dynamic enough. And I Amad, I'd be curious to hear if you have a different take on this, but but my take on the floor was that American frontier labs have basically gone dark and are are largely no longer publishing all of their internal results. Chinese labs continue continuing to publish in the same way that they're continuing to push openweight models. And so that the gap the the research publication gap is being filled in part with Chinese labs. >> I got a question for you on that. So I know I know exactly why the US is going dark. You know every everybody working on these big frontier models is a former Googler. Not everyone but almost all of them. And you know and and the billion dollar signing offers are are a real problem for and we saw that yesterday at Microsoft too. It's it's just recruiting warfare. So Google has explicitly gone dark you know after being very open and publishing everything for years. So I I know why that's happening, but why are the Chinese still being super open? >> Well, it's because the Chinese are backing open source now, aren't they? Uh it's like deploy, use open source to make it more efficient and then that's how we'll win. Uh in terms >> that's how the models propagate. >> Yeah. Strategically, it's it's it's great to differentiation if if you have really strong American frontier models that are largely hidden behind APIs under the spirit of commodify your compliment, release lots of openweight models >> and it's a it's a land grab at this point, right? If uh if lot of nations and entrepreneurs and companies are beginning to use the Chinese models, uh they have a foothold. >> It's it's it's also I think there's an integration angle. So if again under the the banner of commodify your complement a classic economic strategy there is much more to AI than just the models there's integration with society and the economy. So if if there's strategically if you're at a disadvantage on the model front open weight open release all of the models and focus your attention focus your economy on deeply integrating all of those openweight models and that becomes the competitive advantage. Every week, my team and I study the top 10 technology meta trends that will transform industries over the decade ahead. I cover trends ranging from humanoid robotics, AGI, and quantum computing to transport, energy, longevity, and more. There's no fluff, only the most important stuff that matters that impacts our lives, our companies, and our careers. If you want me to share these meta trends with you, I write a newsletter twice a week, sending it out as a short two-minute read via email. And if you want to discover the most important metat trends 10 years before anyone else, this report's for you. Readers include founders and CEOs from the world's most disruptive companies and entrepreneurs building the world's most disruptive tech. It's not for you if you don't want to be informed about what's coming, why it matters, and how you can benefit from it. To subscribe for free, go to dmmandis.com/tatrends to gain access to the trends 10 years before anyone else. All right, now back to this episode. All right, let's jump into our first article. Is this one from Nurups? Uh, Google's Titans and Miris are helping AI have long-term memory. Google's Titan is a new architecture with deep neural long-term memory that updates itself in real time. Uh, do you want to jump into this? Uh, Alex. >> Yeah. Uh so the one of the many blockades to radical progress in terms of advancing AI models is obviously the context window size. It would be miraculous if we could have say a billion tokens in context or a trillion tokens in context. If we could have the entire web in context or the entire human genome in context. Imagine the reasoning powers we'd gain and all of the problems that we could solve. problem is, as folks in in the space have have long used to motivate just about every recent paper on the archive, the quadratic complexity associated with increasing the the number of tokens in the context, but it's really painful to to increase a conventional vanilla transformer past a few million tokens in context. So we result to techniques like rag retrieval, augmented generation and other techniques to try to effectively increase the amount of working memory if you will that an AI model can keep. So Titans and Miras or Moras, these are Google's latest attempt to get past that bottleneck. And as uh as we've talked about in in the past on the pod, there are variety of techniques, architectural techniques to try to break the context window limit uh like recurrent neural networks. Popular example, they don't have any explicit context window limitations, but they forget. So the approach that that Titans and Morass propose is sort of biologically inspired, distinguishing between short-term memory and long-term memory. It's sort of ironic given that the attention mechanism itself that's powering basically the whole economy at this point was originally designed for differentiable long-term memory. We we found ourselves back there. The the idea is to use surprise some a numerical metric of surprise to decide what to commit to long-term memory and what not to. And turns out scales really well without catastrophic forgetting. And just to give people a sense of this, uh the models historically, right, uh GPT4 and 40 had about 128,000 tokens as a as a context window. Uh 2 million tokens, which we're talking about here, is about 3,000 pages of text. Uh 16,000 novel or 16 novels if you would. And you mentioned the the human genome, right? Uh which is 3.2 billion base pairs. uh that you know that would fit you know 2 million tokens only hits about 6% uh or 0.06% of the entire human genome. So uh will we actually get to a near infinite context window someday? Is there is there a strategy for getting there? >> Absolutely. And I I think these papers and others when when Demisabus talks about there being only one to two major AI advances at the level of transformers left before we achieve what what he'd characterized as AGI. I I think breaking the context window ceiling is probably at least half of one of those great advances and I think we will absolutely get there pretty soon. >> Immad, how do you think about this? Yeah, I mean I think I agree with Alex and also this fits with Google's hardware architecture. So the massive kind of tooidal uh TPUs that they're doing that can handle huge amounts of memory gigabytes probably terabytes of memory in one instance by making it more efficient um like from the graphs that we see on uh Titan and Merass it's everything else kind of just slopes straight down. This goes almost continuous as you scale without the also complexity overhead because you used to need almost uh exponential amounts of compute as well as memory to handle that increase. Being able to just capture everything in one go means that you don't need to store stuff to files anymore. Like you could have an entire picture of every email the organization has ever sent just in the memory at once. So it can track everything and figure out the interconnections dynamically. And again, I think that's what helps you break through to that next level of performance. Um, and it's pretty exciting and I think a very logical approach that they've taken here with surprisal uh element there as well. Right now before transformers are a bit brute force to be honest. >> This reminds me of Ben Girtzil back around I think 2010 or so launched the open cog project which was an open- source effort at recreating a mind. So they had different modules of what constitutes a mind like [snorts] memory uh pattern recognition, sensory uh adaptation um etc. And they were trying to replicate each module in software and then improve the software typically like Ben very very early for the time scale. As we look at this and we're building like memory and we've got the processing power, it feels like uh these new this new generation will get to that point and essentially we're without realizing it actually growing a mind. >> All right. Uh, I can't wait because frankly I would love to have perfect memory and when we uh when [clears throat] we add augmented reality glasses and uh an always on version of Jarvis, having an assistant there that's able to constantly remind you of everything you've ever known and everyone you've ever met is going to be super handy. All right, let's go on to open AI uh is uh just you know we heard about in the last pod we talked about their code red uh response to Google's you know growth in dominance. Well uh some news is coming out when announced today that looks like GPT GPT 5.2 will be coming online next week and this chart we're showing which shows the benchmark and GPT 5.2 2 and Gemini 3 Pro. This is still hearsay. This was put up on X. Don't know if in fact if it's true, but just for fun, uh, you know, we're going to see once again, are we leapfrogging model on model on model? Uh, and we'll see XAI come out again with something, I'm sure, very shortly, shortly thereafter. Uh, Alex, >> yeah, the the catchphrase I heard over and over again at Nurups this week is that this is a rat race. There are so many employees at the Frontier Labs who are just grinding away competing at what they view as a rat race to achieve the the Frontier Max in this case. I I fully expect as I've [clears throat] mentioned on the pod in the past that we're just going to see leaprogging on a near weekly basis at this point. >> Absolutely. >> Yeah. >> Until we get to the finish line. And I think the big question is what does the finish line look like? It's interesting that Sam went out and made this code red announcement which got picked up by all the media everywhere, right? And it's it's kind of a interesting strategy because he's putting the organization on alert. He's letting the world know that he's put on alert. He got a lot of negative press from that, but he doesn't care. He just wants to refocus the organization. It it really is a uh an interesting management strategy. people comment that a good crisis is a terrible thing to waste. >> I love that. That is fantastic. >> Leverage that, right? You're you're really uh and I think that sends a message throughout, you know, look, Google did this exactly the same thing, right? They um Sergey Brin said, "I'm perish. You're doing back in. We're going into founder mode and we're going to solve this AI thing and they've done it and this is now the leaprogging rat race which is good for the consumer in so many ways." That's amazing. >> Yeah. [snorts] you know, we we were gonna we're going to be sharing the conversation we had last night on our next pod uh with Mustafa Sullean uh who's the CEO of Microsoft AI and just foreshadowing that one of the conversations we talked about is safety. Uh and if you're in a rat race and everyone's just trying to leapfrog everybody else, you know, it feels like safety goes to the sideline and it's just an accelerationist point of view over and over again. Um, Emod, uh, any thoughts on this code red? >> Yeah, I think the code the the code red makes sense because the competition is intensifying and there's only so much attention that consumers have as it were for these kind of models. Uh, this benchmark chart I'd be very surprised at because for example, it has video MMU and GPT5 can't understand video at the moment. So, it' probably be a brand new architecture underlying that. However, all these numbers will be hit in the next 6 months probably for a year and that's why like we're running out of benchmarks. >> Well, well, Peter asked me, you know, should we put this out there because we have no idea if this is real or not. It's just a leak, an internal leak. Uh, and we'll know next week. We could look really stupid if this is totally wrong. But I I wanted to actually make sure we put it out there in case anyone wants to trade on Poly Market because, you know, right now the end of year [laughter] the end of year, you know, you can buy uh Chat GPT or or OpenAI at uh like six cents on the dollar. So if that if that humanities last exam number is right, that's just mind-blowing. So we'll we'll find out next week, but wanted to at least give everybody a chance to to see it and make their own guess on whether this is real or not. And and like Ahmad said, we'll hit these numbers within six months no matter what. You know, some somewhere. You know, the other thing that was really interesting last night at at Microsoft is that we'll we'll start adding a column to all these charts that has Microsoft's numbers independent of OpenAI. That's the mandate. Now, I think I think Mustafa was really clear that yeah, we're going to be another column on every one of these charts and another line on Poly Market. >> Yeah. Well, uh I guess one other point just to just to note uh you know Sam has got a lot of capital to raise uh in order to implement the buildout that he's announced. And I think this kind of like I'm willing to do whatever it takes to stay out front uh is part of the strategy being able to raise capital and get ready for an opening I uh >> That's a great point. That's a great point, Peter. This is as as much for investors as it is for the general public and for the employees. >> Yeah. But I I I think the the bottom line for all of our subscribers listening is expect this on a week-by-eek basis, which is what makes our our conversations on this pod so interesting. It's it's like it it is watching I don't I don't know what the equivalent race would I mean, it is a horse race, but it's continuous uh with with billion, you know, a billion dollars per day plus going in to fuel this crazy competition. I >> I think the closest analog I can think of is this is like a world war with multiple campaigns and multiple fronts and multiple thrusts and initiatives. >> Yeah. Uh >> yeah, if you only have time to look at two numbers on this chart, look at the first and the last because the first one is the one that's most correlated with self-improvement and accelerating AI. Well, just read them for those read them for those listening here. >> Well, I mean, it's speculation, but the the high bar on humanity's last exam is without tools 37.5% which is really good, but >> which is Gemini Gemini 3 Pro >> and it's Gemini 3 Pro. Then with tools, it's higher than that. It's closer to 50%. Here the speculation is that they've leapt all the way up to 67.4%. Which would be crazy. I mean, again, we've only Alex can answer those questions as far as we can tell [laughter] on this podcast. I think EMA would do a good job as well. >> But what [laughter] is >> I mean seriously they're they're damn near impossible. >> What does with tools mean for those who don't know? >> Uh well so then the AI it doesn't just answer in one pass. It's allowed to actually use a whole variety of calculators and really any kind of a of a tool that doesn't give it the answer. It's allowed to use in its chain of thought and it can iterate many many many times. And so it's not just the standalone LLM. it's the LLM accelerated or or enhanced with other software, which is perfectly fair if you're trying to solve a world problem, cure a disease or whatever. That's why they they use that benchmark in addition to the raw the raw benchmark. >> Yeah. >> And and then the last line is the one that Alex loves for good reason. It's, you know, self-improving is one thing, but then self- financing is another. And Alex, you talk about that better than anyone. I'll hand it to you for that. Yeah, vending bench 2 and vending bench arena. I I I love to to the extent that we have any sort of economic touring test or economic benchmark for agents ability to autonomously deliver a return on on capital. That is what we have right now. And uh as uh as I've mentioned in the past, maybe just project this in into the ether. I would love far better benchmarks for measuring economic autonomy than vending bench, but vending bench is what we have right now >> because it's coming. >> Actually, there's a there's another thing that just crept in uh didn't make it into the slide deck, which is there's a trading competition uh with the AI bots, I think, um on the crypto side of things, and uh there was a mysterious model that actually made a profit reliably all the way through. And Elon Musk just announced that was Grock 4.2. >> Nice. So >> continues >> the leap frogging and so he said that's how you pay for all the GPUs just don't let five wild on the stock market. >> So you're going to compete against Elon and his million GPUs. >> Dollars are the best benchmark. >> All right. Anthropic is making news once again. Uh there's a lot of uh excitement and energy and right now it's still a bit of rumor but that they will have an IPO as early as 2026. So, Anthropic is negotiating a new funding round that could value them at $300 billion as revenue is projected to reach 26 billion next year. Uh they're aligned alongside Open AI, which is also exploring a future IPO. So, if we've got, you know, OpenAI going public and to access capital and anthropic going public, I have to imagine XAI is also going to go public sometime in in the near term. Um thoughts on this one, gentlemen? >> I'll comment. Oh, go ahead, sir. >> No, go ahead. tired. >> I I I I think if if anything XAI is is relishing not being public given it its history, but I I I think more broadly the worstc case economic scenario for super intelligence is that it maybe not the worst, but the the the next worst case is that it remains decoupled from the human economy and that an intelligence explosion happens not on the publicly traded markets and that insiders and early employees and the machines themselves sort of skyrocket in in terms of real wealth but are largely decoupled from retail investors and the rest of the human economy that that would be I think a highly suboptimal economic outcome whereas if we get enough IPOs from anthropic from open AI from SpaceX from some of the these other firms that are achieving hypers scale on land in space I I think that is probably the best case from a macroeconomic perspective for the economy and and once those happen. Assuming they happen, I I think it's far clearer to see how the economy grows past the so-called debt crisis, how we achieve hyperrowth, real hyperrowth over the next three years. >> Dave, >> well, having founded and taken a company public, this is a big big step. And and when Dario, the CEO of Anthropic, Dario Amade gets interviewed, he he says, I actually never visualize myself being a CEO at all. I'm surprised I'm in this position. Then when you become a public CEO, it's a whole another level. So I'm I'm a guessing he'll grow into the role, but it's a big deal. And so why do it? And why would why would Elon be relishing not doing it? Well, once you're in the public limelight, all your dirty laundry and your code reds become, you know, crystal clear in your stock price every day. It's it's very hard to do what Sam does right now, you know, roam the world selling the story when your dirty laundry is right there on every stock ticker. Uh so it's another level but they have to do it because you can raise 1020 billion dollars privately but you have to tap into the public markets. Yeah. You you got to be talking about much bigger numbers and the only way to do that is through the public markets >> and it gives you currency for acquisitions which is uh uh which is important. I I think it also increases trust in the company if it's a public company versus being a private company. >> Yeah. >> Yeah. Sam Sam was at Davos last year and I was, you know, following him around on on the streets of Davos and >> I mean just the backing [laughter] >> he actually had this you couldn't miss him. He had an entourage as big as as a president of a nation. Um [laughter] it was but he's just doing meeting after meeting after meeting saying give me another billion dollars. Give me another billion dollars. And you know, you can see how it there's no way that can scale to what's happening next in >> I mean and part of what's coming out in the news right now is a lot of the deals that uh Sam and Open have announced are options and not actual deals which is fascinating. >> Yeah, I think you're at this fascinating time now though whereby the dollar benchmarks are starting to accelerate. The revenues ramped up like Anthropics at 10 billion of revenue just a few years in. It's amazing. And they're actually catching up to OpenAI. But then the competition is going to get intense. Like Opus 4.5 is $25 per million tokens. Grock 4.1 is 50. Will you see substitution occurring? Or will you see these models actually just being used to literally make money? Like I said, like I could easily see Elon in particular just say Grock 5 is going to pay for itself and all the GPUs by being the best hedge fund in the world and just let it loose on the stock market and Mac hard is going to replace all the SAS. >> Yeah. >> So yeah, >> it's an interesting >> you know the other thing that happened this week concurrent with this it's not in the deck but uh the cost of HBM memory the memory that drives AI skyrocketed. it went way way up and and uh OpenAI in the news said we've we've reserved 40% of the world's supply of memory for our own data center work you know in in Abalene Texas at at Stargate which is which is crazy you know normally memory comes down at a rate of almost half a year in cost and so to see it go the other direction is the first bell weather that hey there's going to be a huge shortage of compute and if you don't go public and raise the capital and lock up the supply you're going to be left comput starved Yeah, I mean the same thing is going on >> in fundamentals, right? I I didn't put it in the deck, but there's a copper crisis right now. The price of copper is going through the roof because of wiring these data centers. Um, all right, let's move on to our our next story here. Uh, >> wait, quick point. >> Yeah, please. >> If if their next year revenue projections are 26 and the valuation is 30 bill 300 billion, that's only 10 times revenues. Palunteer is trading at 111 times revenues. So that's cheap in that sense. It's a good point. It's a good point. >> No, it is reasonable. It's crazy big numbers, but it's perfectly reasonable. >> I think Slim is saying it's overly reasonable. It should be at a higher valuation and it and it will be. It'll probably uh you know spike [snorts] after an IPO. All right, here's our story. OpenAI finds confessions can keep language models honest. So, you confessions method trains models to openly admit when they're hallucinating or when they've broken. The method encourages models to self-report mistakes instead of hiding them. So, I am completely curious here. Um, it's like, okay, so you use this methodology. Uh, do you actually get two reports? Here's my answer and here's my confessions. Uh, Emod, what's going on here? Yeah, I mean this whole thing with next token prediction, right, is that the models kind of go along and then they can't have the self-reflection and more things like that. I think that what you find is when you've actually got the right prompts, the right planning and then the right loops, you get uh very interesting things occurring. Um particularly as the hallucination rates are dropping now as well because the models used to jump a lot and skip these behaviors because they didn't have the self-reflection. they didn't have some of these other things. So, I'm not very surprised by this. Um, and again, I think what we'll eventually see is what we saw with the Deepseek uh V 3.2 math paper, a concept called a metaverifier where the models learn from their mistakes. So, rather than just checking against a very small baseline, are you being honest? Where have you made mistakes? Having that as a verification loop is very similar to how humans learn and that's what causes big leaps in some of these uh more frontier areas of thought as well. You know what I found shocking? I asked uh one of the models you know how often are you hallucinating or providing wrong answers on average and I found a couple of studies and one of them was that 25% wrong answers on everyday user questions. Um, another one said GPT40 and Claude 3.7 sonnet hallucinate on an average of 15 to 16% of the time. And I never expect that when I'm when I'm asking my questions. I'm assuming and I I think the majority of all of everyone perhaps not you and and Alex. I'm assuming that they're correct. If it's really you know 10 to 25% hallucination that's scary. >> [snorts] >> It's basically the same as a human doctor, right? And the interesting thing though is that it's dropped. So GPT5 dropped it from 18% down to 3%. >> Mhm. >> So the last generation of models. >> Yeah. >> Yes. Go ahead. >> Can I give you a dramatic example of this? I think the it's worse than a human doctor u because it's they're actually trying to please you the models. So therefore they're saying whatever. I had a TV that where the power went bad and Chache PT said, "Oh, if it's this model, here's and it's making a buzzing sound." >> Yeah. You mentioned that in our last podcast. >> Yeah. So, so I asked it then, "Okay, how do I who do you know that can fix this?" And it gave me names of three local TV repair shops that were completely hallucinated [laughter] with with phone numbers with phone numbers, websites, names, addresses. And I started calling them. They were all all the phone numbers didn't work. And then I went and looked up none of them existed. So this this is a big problem. If [laughter] but if I lift up a level for this confession thing, I think it goes back to the earlier point that there's a it's great to have a feedback loop. It gave me somewhat chills cuz I went to Catholic high school and the idea of confessions is somewhat chilling. Who's the priest? Uh is my question. When you do this type of model, but I think the feedback loop is very powerful to have. >> Wow. Wow. I I I think it's also worth mentioning the 50-year-old notion from economics of Goodart's law, which is that when a measure becomes a target, it ceases to be a good measure. And the way that these models are trained certainly and superficially rewards various sorts of behaviors that might be construed as dishonesty. and being able to avoid Goodart's law. Clever ways to to avoid Goodart I I think are are admirable on the part of OpenAI. And maybe the the final solution looks a little bit less like naively optimizing just next token prediction objectives or reward maxing on RL objectives to solve math problems or programming problems. looks a little bit more like some sort of multi-objective optimization problem where maybe there's some blend of a a good heart avoiding honesty reward and an accuracy award and and an ethics a reward and that maybe almost start to look a little bit like separation of powers in in what we see in in government systems. There's an executive in in some systems a legislative judiciary etc. I'm gonna have to bookmark that comment, Alex, because you lost me at multiobjective optimization [laughter] problem. >> On that on that note, I'm going to move us forward here. >> But you have a good heart, See. [laughter] >> All right. So, again, it's like the next release Google releases Gemini 3 deep think uh which uses parallel reasoning testing multiple solution paths at once. That makes sense to me, right? an upgrade from 2.5 deep think uh and it's excelled once again humanities last exam and uh GPQA diamond arc AGI2 going to our benchmark expert Alex this is a template for how revenue is going to scale to justify the trillions of dollars of capex it won't just be faster models or better models or stronger models it's going to be lots of agents fleets of agents millions of agents many millions billions of agents all running in parallel to solve problems. That is in my mind and and certainly based on the architecture of Gemini 3 deep think which isn't just a faster better singular model but it's also scaffolding to have fleets of agents fleets of Gemini 3 agents that are all running in parallel to solve a given problem. And that's that's the deep think part of Gemini. >> Sounds like quantum computing to me. You know, it it's like I'm going to run I'm No, I I know that. But there's the concept I'm going to run this uh this problem in multiple parallel universes and bring back the answer. I'm going to run this problem in, you know, a billion or a trillion agents and bring back the best answer. >> Parallel. Yes. But quantum computing wishes that it had the economic utility of Gemini 3 deep [laughter] think. >> I'm with Peter on this one. >> Go ahead. Go ahead, Salem. >> I'm with Peter. I'm with Peter on this one. It feels like that kind of parallelism. But I think the broader point you're making, Alex, is that when you have millions of agents each specialized, if you take something like the Manhattan project, you have thousands of people each with a deep specialty connecting together and the hive mind then solve the problem. And we're going to see the same with agents. Is that the is that a metaphor that works? >> Yeah. Like when Daario speaks of countries of geniuses in a data center, this is what it looks like. We're going to have billions of agents that are all going to be independently probably pretty expensive even though the cost of intelligence is going to zero. But collectively, yes, this is going to generate trillions of of revenue if we have so many agents and this is how we pay for all those data centers. >> Yeah, I think that's a really important point, Alex, is you know, everybody talks about the cost of intelligence going to zero, but it's not actually going to zero. It's going down to a low number, but concurrently the fleets of agents are getting so much bigger so quickly. And and you know we saw earlier in this pod too the the process of iterative expand the context window to entire you know hundreds of millions of tokens uh and run many many iterations to get rid of the hallucinations. Those forces are going in the other direction and it's working far better than anyone thought it would. And so it's very unlikely that the cost of intelligence is going to go to anywhere near zero. Everybody's going to want more intelligence and more intelligence and more. So, there's going to be an acute shortage. And I only mentioned that because many business leaders are out there saying, "Let me just wait and see what happens." And you're going to be starved of access. And you can see this already when the new models come out of Gemini and they add, you know, another level of deep thinking. It works incredibly well. But you wait 3, four, 5 minutes to get your answer. And very often it says, "We're experiencing unexpected loads right now. Sorry, we're offline. Like, how's that possible if if the cost of intelligence is going to zero? Well, it's not. The it's the cost per token is going way way down, but the use cases are expanding on at least three different dimensions on this ridiculous curve the other direction, >> and everybody's going to want it because it works so well. So what does what does this actually mean other than we have yet another faster model able to hit the benchmarks a little bit better and next week we'll be announcing the next better model. Uh Immod [snorts] I think the models are getting to the point now where again ensembles of these models doing different things are just genuinely useful for real world advanced complicated tasks. I'm really looking forward to using Gemini 3 Deep Think 2.5 Deep Think was pretty good, but right now I think the only one usable for Real Frontier stuff is GPT 5.1 Pro, which again does something similar. >> Ultimately, what you want is you don't want a task that's really complicated to be done in seconds [snorts] nor minutes. You want to be iterating on a task for a period of time, giving it input and feedback, and the model just not making mistakes. like Gemini 3 Pro still makes mistakes in math when I'm using it, you know, and so Gemini 5 GT 5.1 Pro doesn't. >> The [clears throat] model usage again, I think the Deepseek math paper is fascinating for this. It's the first open- source model that gets a gold on the IMO and to each of the problems, they use two billion tokens. So about two billion words >> and that gives you an idea of how many more tokens you can use. >> Yes. And it works. It works. >> And it works. it got. >> I mean, if you want to experience this firsthand, just go to G to uh, you know, GPD 5.1, soon to be 5.2, ask it to do something complicated for you that it can't quite do, and they just keep asking it to try harder about a thousand times back to back, and it will eventually get it right. You're like, why does that work? >> What's an example of a hard thing to do? >> Oh, I do this like all day long. In fact, right after this pod, I'm back. I I have a fleet of uh Kimmy K2 agents scouring the the world right now working on hard problems. But I'm, you know, if I ask it to translate legacy C code into Python and then it's, you know, it comes back slow, make it faster, improve the algorithm, um, or or, you know, more more down to earth. Do you do that with your student shooter? >> Do you do that with your students, too? Work harder, try it [laughter] again. >> Well, that's the that's the difference. That's where everybody's analogy breaks because there are a limited number of humans and students, but there are an unlimited number of AI agents. And so deploying a billion in parallel to work on something is out of your normal range of intuition, but it just flat out works. You need to expand your intuition to this new world we're moving into. >> I think that's one of the most important things that we can we can say coming out of this, which is we're about to enter a new world where there is a near infinite amount of intelligence to be thrown at things. Um, >> yeah, anyone. >> Yeah. Go ahead. >> Interesting things. Sorry, please. Sorry. >> Go ahead, Emma. Yeah, I think one of the super interesting things on the context when just realizing it is again the stuff that we get wrong when we're trying to solve problems usually the only stuff that survives is the stuff that we get right like at Nurips it's papers full of all the stuff people got right >> being able to actually have scientific method strategy and things like that where the context window includes everything you got wrong for all the different models >> fascinating >> we know that will do better because often it's what we got wrong that actually guides >> learn from your mistakes Yeah, sure. >> Yeah. I mean, if you had asked everybody in the community 3 years ago, is that going to work? 90% of people probably would have said, "Yeah, I really doubt it." But it does. Now, everybody agrees. Everybody at Nurups, I'm sure it just flat out works. But that means you need massive massive numbers of of parallel agents and and even, you know, even any given agent needs many iterations. It's just a huge amount of compute, but it it just solves problems. It's incredible. All right, our next story here is the reasoning AI became so efficient. So AI got more efficient by mostly uh mostly for huge LLMs with training becoming 22,000 times more efficient while smaller LLMs only improved by 10x to 100x. So what's the story here, Alex? Yeah, this is sort of a finger in the eye to to those armchair theorists who say that the small guys the the small labs are going to benefit from algorithmic advances. it. So this is a a study that found that 91% this is a study out of MIT 91% of algorithmic efficiency gains between 2012 and 2023 were the result of only two things. one, the switch from LSTMs to transformers, and two, the switch from Kaplan scaling, named after my my former office mate in the Harvard physics department, Jared Kaplan, at anthropic. >> Uh, and the switch from Kaplan scaling to chinchilla scaling th those two things. So, LSTMs to transform LSTMs were recurrent transformers, not >> what are LSTMs? >> Uh, long shortterm memory. Uh so the LSTMs were uh prior to to the transformer revolution, LSTMs were the favored language model. I remember the the old days prior to transformer, prior to to GPT when Andre Karpathy had his char RNN language model that stunned people by being able to generate code. There was a there was a life prior to to GPT. But those just those two algorithmic transitions LSTMs to transformers and Kaplan scaling to chinchilla scaling those two were 91% of the efficiency gains. And what that says is is that this story that oh well we're just stacking small wins on top of each other and that eventually somehow algorithmic efficiency gains are going to enable smaller labs to have some sort of advantage relative to larger labs. This suggests that's just not true and that most of the algorithmic efficiency gains are actually acrewing to the large labs that are able to scale out the most. There >> there's one other thing in this paper that's noteworthy. Uh and please don't read it. Alex summarized it perfectly. That's everything you need to know. [laughter] It's way longer than it needs to be. Classic MIT work, but it's it's a very very good summary at the beginning of the document of why this work is so important. uh because we're putting a immense amount of of societal energy into scaling the hardware and and you know Elon Musk talks about you know Tennessee all the time and Stargate and huge amount of thought and research and discussion on our podcast about these massive data centers because they're so visual and they're so expensive but the software side of it is very underresarched and very under analyzed so they're taking a first shot at trying to give us better insight into the future rate of improvement of the software side of it because that's where it's not as expensive, but the lift could be enormous. And so I think this is a really, really good focus area, and I'm really glad MIT is on top of it. Um, but you know, Alex's summary is all you need to know about the work so far. >> Amazing. So the inner loop the inner loop here then is is energy going to GPU to agents going to intelligence and therefore all of that scales and there's the demand is so infinite in terms of adding intelligence to everything that it'll be a long time before we run out of that. That's the That's why we're traveling the world with data centers. >> We're we're t So So I I I I think there's some YouTube viewers somewhere with a a drinking game or a bingo game for how many times we can say tile the earth with compute or disassemble [laughter] the moon or whatever it is. So So drink your whatever or cross off your bingo game to this one. >> Silly robot. Robots are part of the loop. >> We're robots in the loop. >> Here we go. This this next article here I find uh really important. This is about visual uh chain of thought. Uh and it's the notion that uh chain of visual thought methods uh are now able to give us a better understanding of uh of images. Uh and this visual uh thought delivers 3 to 6% gains in continuous reasoning performance. Uh the image here on this on this is asking uh question is the wall behind the bed empty or is there a painting hanging on the wall and what you see then is the analysis the ability for an AI to understand what it's seeing right uh at the same time that we're bringing about augmented reality glasses uh and we have humanoid robots coming in coming online uh is is going to be fundamental uh I want my AI to understand what I'm seeing. I wanted to be able to remember during the course of the day where I left the keys or who I ran into or recognize a face and give me their name. Um, how fast is this accelerating? >> I I think this is if if I may even more profound than than just garden variety acceleration. If I ask all of you or I I request don't think about pink elephants. What's the first thing that happens? You start thinking about pink elephants, not in terms of text tokens in your mind. You're not probably thinking in terms of language. You're you're using your visual cortex probably to create a mental image of pink elephants. And the ability to visually reason is something we've talked about on the pod in the past. We're finally a few weeks later, few weeks after this was predicted to happen, we're starting to see major gains in reasoning performance by models that can include visual tokens in their train of thought, not just text tokens. And we're going to see a lot more of this. >> You How excited about you or this are you? >> Yeah, I'm not surprised at all by this. It's very exciting. I think it's actually something fundamental to reality. Models are the things with the best math that approximates reality. And we've seen some interesting things before like originally we built stable diffusion and then from stable diffusion we extended it to 3D using the same knowledge. We found out actually Harvard did a study that a image model understood 3D. Then we extended that out to video the same thing. It somehow actually had a concept of physics in there. And in fact, if you look at the latest image model that's top of the charts now, Flux by the Black Forest Lab team, my former colleagues, it started with a language model that then got a video model that then became the best image model in the world. And you see now um for example, Luma recently raised 900 million uh from Humane and others to build world models where you input all this data, image, video, text, etc. Because text is low dimensionality. If you actually want to understand and reason, you need to have all the different types of data. But the latest spaces are actually very very similar to them all in terms of your understanding of the universe. So you can go from a text model to a video model actually just by adding the right types of data, but the underlying structure doesn't change which I think has big implications for again the actual nature of reality itself because each of those is modeling a different part of reality. Can you go can you imagine going back to Alex Nut when when they were putting this together and showing them this capability uh when all of it it you know we're trying to recognize the number seven that was a conversation we had yesterday [clears throat] uh I mean truly extraordinary >> it is and to experience it firsthand you know uh take a screenshot of something you're doing on your computer dump it right into Gemini and say help what's going on here >> you know it's it's incredible that that works it would shocked anyone 10 years ago, nobody would have believed you at all. >> And go ahead. Go ahead, Iman. >> Well, the crazy thing I think it's always worth coming back to this is that if you told someone 10, 20 years ago, they would have thought it'd be like this massive logic tree, right? >> We have to remember this or is it that, right? >> They're just ones and zeros. They're literally like a movie file and you push words in or images in one side and it squeezes out the stuff on the other side. the reasoning isn't actually reasoning at all in the way that we think about it. And again, I think that says something profound about the way our brains work in the universe works. This static group of ones and zeros can do that. I think what's what's important to realize here is where we're going. Uh all of us are going to have a AI with visual capability always on helping you, supporting you, right? And I think that's a vision of the future. People say, well, I I don't want to lose my privacy. and so forth, but it's going to be watching what you eat. If you want to turn on health mode, it'll tell you, you know, eat more of that, don't eat that, or there's a staircase over there. Go take the stairs instead of taking the elevator. I mean, the ability for an AI to be your always on, you know, visual Jarvis assistant uh is going to be profound uh throughout our lives, increasing our efficiency of what we do and what our objectives are. Yeah. Uh Sem, do you want to add on that? Just to build on that point, Peter, I'm expecting in a year or 18 months, some sensor that's in your stomach saying, "Hey, you're about to eat that donut. Wait 10 minutes because I'm still metabolizing the coffee." Right. Okay. >> And and creating radical efficiency in all these very little things that we never thought about much is going to be one of those areas that we're going to add a ton of compute against. So, I took a screenshot of our podcast as we're speaking and gave it to Gemini just to prove the point. And I said, "Hey, are these guys having fun, and it completely interprets the scene. It knows exactly what we're talking about." And it says, "Yeah, it looks like it's fun if you're a tech enthusiast, you like futurism, or you enjoy brain food. It's probably not fun if you dislike technical jargon or you want casual entertainment." [laughter] >> Okay, that's that's probably true. >> Point is, it completely knows what we're doing from just that screenshot. And I and you know this is going two different directions too. It's making the AI more in touch with humans and the way we live. But the data is not specific to that. It can also go the other direction where you feed in genetics data, you feed in satellite image data and it can then get intuition in those domains where nobody that you know has intuition. So it's going in both directions at the same time. So if you if you kind of study what's going on with vision on this slide, you can develop some intuition about what it's very soon going to be capable of with medical imaging, with satellite imaging, with other types of sensors that we're not familiar with. >> I'm still reeling over last week's comment from Alex that we're taking uh brain scans and running them through AI. I mean, that's going to just generate some unreal insights. >> Well, Immad has thrown some cycles at that previously. Yeah, I know. We were uh I was catching up with some of your former colleagues from the the Medark days at at Europe. fMRI wants to be its own modality. >> It does indeed. I think all the modalities again, we need to tell the world for some reason, right? >> All right. We're going we're going back to one of the stories we opened up with, which is uh the response China is having or the leadership it's providing. So, China is accelerating its push to become independent of Nvidia with uh Cambercon planning to triple output to a half a million accelerators in 2026. So, this is a response to US policy. It's always that way. As soon as we restrict a country from buying a product or service that we're providing, especially if it's if it's fundamental to their lifeblood, they will develop competition. uh and without question I think the competition will you know there's a huge amount of intelligence resident in China don't forget uh uh the the Chinese sort of educational system excels at math and compute so I would not expect that um uh they would deliver anything sub Nvidia uh Iman you want to kick us off here >> yeah I think necessity is the mother of invention right uh we we also saw more threads uh IPO this week in China. They raised just over a billion dollars. They're again another competitor GPU. It was 4,000 times over subscribed. >> So $4 trillion of demand. >> Uh now obviously that's a bit much, but again you're going to see more and more of this stuff ramping uh particularly for the specific Chinese models because having an open-source model that you can test as you're developing it really closes the feedback loop a lot more aggressively here. So you don't need just to build for one vendor, you can build for everyone. And most of the Chinese models are optimizing around this very sparse type structure with deepseek and similar arches with muon kind of acceleration. So you're getting towards one architecture that they can just engineer and output industrially. And who's the best at industrial manufacturer? Y it's >> China has been you know we it's important to remember Nvidia used to supply 95% of China's advanced AI chips >> uh and when that when that supply got cut uh you know there was a red alert going on in China and I'm sure the government orchestrates and supports and says okay we need to we need our own Nvidia or multiple Nvidia companies in China. Alex your thoughts. Yeah, I we don't have a slide for this, but I I would definitely encourage the audience to read the national security strategy that was just released in the past 48 hours. It is it's most certainly eye opening and I I think spells out a pathway for tech decoupling between the US AI tech stack and the Chinese tech stack. I'm reminded during the the cold war the Soviet Union had what for for for those years would have amounted to an independent tech stack and was experimenting with all sorts of crazy architectures like turnary computing and and other to to westernize unconventional choices. I I think we're going to see a Cambrian explosion, no pun intended, of architectures coming out of China now that China has been effectively decoupled from the US tech stack. And maybe many of those innovations will end up one way or another benefiting the overall world, benefiting the US tech stack. I think we'll see a lot more experimentation coming out of China post decoupling. >> So what's the implication of this? I'd like to spend an extra couple minutes on this because China is going to be going as rapidly as possible developing its uh its models, its uh it's developed fully its energy ecosystem, you know, 10x further than the US has. Uh we're going to talk a little bit about China's desire to put data centers in space. Um I mean, any thoughts on the long-term implications of this complete parallel development between the US and China? I I think we we see an intelligence race and that will lead to diversity. We're going to see so many different architectures that are all competing in in the US in the west. We have a whole handful at this point of Frontier Labs that are all vertically integrating with their own chip architectures, many of them in partnership with Broadcom or or other uh lower level infra providers. Now we're starting to see the same happen in China. I I think in the end this heterogeneity that we're seeing in terms of text tax is only going to to further accelerate the race that we're already in to the finish line. And I again I I would pose the question what is the finish line that we're racing toward because we're going to go much more quickly with this level of integration. >> So stepping up a level is this good for humanity or not? I >> I think all other things being equal more experimentation can can probably be better for humanity query whether it's good for the US or not. about query whether it's good for interoperability or or not but all other things being equal more experimentation is probably better >> Immod uh and sem I'd love to hear your thoughts here >> I think the good news is that more technology development is generally better for the world if I think about the the counterposition between the US and China I think a lot of the future will depend on where you end up with trust right um and the challenge with China is people don't trust it Now people are losing trust in the US on a week-by-week basis. So there's there's that to be considered. But I think over time uh the concept of do you trust Google or do you trust ChachiPT in terms of what the future of AI is going to be? A lot of is going to come down to where where do we place our trust? If you're African n if you're an African nation over time, >> uh where will you put your trust? Right >> really important. I saw I saw a tweet today, you know, to entrepreneurs saying if you're building something that increases trust, double down. If you're not, then stop doing it. I think trust as a uh as a scarce asset uh is a really important uh thing to >> and I got a shout out to Jerry Mcowsky here who made that phenomenal comment that scarcity equals abundance minus trust. >> It's just like amazing. >> Yeah. [snorts] >> Yeah. I I think that you'll see just like China flooded Africa with smartphones with TCL and others, you know, these chips will be very aggressively priced. So, let's to put Cambercon in context, they raised about $2 billion. Their market cap is hundred billion right now and the 5090 is equivalent to an Nvidia A100. The 6090 about a H100, but it's about half the cost >> and [clears throat] it's much more power efficient as Does this does this hit Nvidia's bottom line? >> It not for a while. For a while, they'll all be used locally, but as they ramp from 500,000 accelerators to 5 million to more, and again, China has the full end to end supply chain as well, then you'll see it flooding in a few years time. Like again, this is in the acceleration phase here. To put the 500,000 in context, I think there were about 4 million hoppers sold and about 10 million black wells coming. So, [clears throat] in a few years, you can expect even just Camcon, someone that no one's really heard about, they're already at 80% of a generation back Nvidia chips, >> in a few years, you can probably expect them just like Tesla and BYD to actually be fully competitive. >> And now you're seeing [clears throat] BYD displacing Tesla >> and over again. Yeah. >> It also comes down to the engineering versus legalistic thing, right? The US is lawyers managing immigrant and engineers. Um, and China is all engineers uh with kind of an authoritarian state. And where will this play out? >> This episode is brought to you by Blitzy, autonomous software development with infinite code context. [music] Blitzy uses thousands of specialized AI agents that think for hours to understand enterprisecale code bases with millions of lines of code. Engineers start every development sprint with the Blitzy platform, bringing [music] in their development requirements. The Blitzy platform provides a plan, then generates and pre-ompiles code for each task. Blitzy delivers 80% or more of the development work autonomously while providing a guide for the final 20% of human development work required to complete the sprint. Enterprises are achieving a 5x engineering velocity increase [music] when incorporating Blitzy as their preIDE development tool, pairing it with their coding co-pilot of choice to bring an AI native SDLC [music] into their org. Ready to 5x your engineering velocity? Visit blitzy.com to schedule a demo and start building with Blitzy today. [music] Iman, you're kind of in Europe or you're in a previous European nation. And we've had this conversation on this pod over and over again about Europe has been in an sort of an AI uh uh winter or ice age as the case might be. So here we see EU to open bidding for an AI gigafactory in early 2026. Europe is finally making a serious move uh to close its compute gap with the US and China by greenlighting an AI gigafactory uh bidding in early 2026. Uh Iman, what does this mean? >> I mean, every nation needs sovereign compute because their intelligence of their nation will be dependent on the number of GPUs, right? Uh the EU with their regulatory acts has kind of held AI behind. But I mean recently we saw Yanlukun's now hiring for teams in Paris. you know, we see teams in Germany, we have disabled diffusion teams. There's a lot of talent there. It's just they got to cut the red tape. And we're seeing, I think, a change in that and now the UK, Europe, and others are like, well, this is the future. We have to cut the red tape. But the US is still far far ahead. >> Can they move fast enough? I I saw, you know, they're going to relax GDPR to give access to data finally. I mean, GDPR was just a chokeold on entrepreneurs. Uh I mean how are you feeling in the UK right now? >> So I think again you've seen a step change just in the last few months and as the agents hit next year proper agents not these stoastic parity agents everyone has to change. No no no country has an option but to change and to go all in on this because if you don't then you're going to be left behind. You'll be out competed by your peers. Well, I'll tell you just just observing without judging. >> There's a square mile in PaloAlto, a square mile in San Francisco, and a square mile in Cambridge. And the gap between those three places Cambridge Cambridge, Mass. Yeah. >> Yeah. >> Uh yeah. Not the other C, not the original Cambridge. [laughter] The gap the gap between those three square miles and the rest of the world is getting wider and wider at an incredible rate. And I have always the same observations that Ahmad has. amazing talent all over Europe and all over the world and shouldn't this proliferate out to all that talent but when I observe you know that Peter that meeting we had with Richard Socher I heard you go holy like 12 times during that meeting >> and there's nothing on the planet and we we'll talk about that soon >> not that we can say anything about it but hey [laughter] >> we can we can't right now but but the gap between what's going on in those three square miles of the earth and the rest of the world is mind-blowingly big and accelerating very very quickly So I think you know building data centers around Europe is is way too little way too late >> unless it's done with some other in combination with with some other force that I don't know about yet but just observing it that that gap is accelerating very quickly. >> The Europe Europe is best at public private partnerships. The problem is that in this world speed is the ultimate higher bit and speed is not the strength there. I mean you and I have had these so many meetings uh throughout many of the European nations and uh the energy isn't there right the the drive the the absolute you know my favorite uh Joseph Campbell quote is like a man whose hair is on fire seeks water right I mean that's what we're seeing right now in the hyperscalers here it's like you know this code red it's like you know everybody jumping in it's 24/7 It's not it's it's not uh what was it? Uh it's not 996. It's it's uh it's I don't know what it is. It's 6127. That really is that way. [laughter] >> Yeah. Not just that, though. You know, I tried to make a point of this with Mustafa, you know, yesterday and that'll be on our our next podcast. You'll see it. But, you know, he he just name dropped. Well, you know, when I was talking to Sam the other day, and then I you know, I saw Demis, you know, last night and then, you know, Sam and I were thinking about Daario. It's all first names, you know, all of these are just first names to him. And so it's not, you know, it's not [snorts] corporate, it's not, you know, data center investments made by the government. It's this very small group of people that are on a firstname basis that have now, you know, no joke, uh, $50 billion budgets to build this out. So that's what's really happening. >> We saw the same thing in the space industry, right? In the United States, uh, we gave birth to Blue Origin and SpaceX and Virgin Galactic and a whole bunch of entrepreneurial space companies. And in Europe, it's the industrial military complex creating Aron 5 and a few other smaller rockets. But um, they can't compete with the with the current uh, you know, entrepreneurial space industry. The only way to compete is because a government buys local and that simply makes the entire space-based services that are launched out of Europe more expensive. It just can't be supported. >> Well, and it's changing so quickly. You know, it has to be on a firstname informal basis at the rate of change. You know, in Massachusetts, this will drive Alex crazy, but in Massachusetts, you know, we we have a very good relationship with our amazing governor, and she said, "You know what I need to do? Put together an AI task force." [laughter] And so the timeline on that kind of action is is like three orders of magnitude slower than the evolution of AI. >> So in Europe in Europe they would say sometime in Q3 of 2026 we'll start the discussion to create that task force. [laughter] >> Actually there's a very interesting thing. There's an initiative called next frontier.ai to build Frontier AI labs. And again it's well intentioned. It's like they'll give 12 teams 2 million >> over the next few years to see if they can accelerate up and get there. >> 25 million euros per second. [laughter] >> Can I just >> Yeah. >> Can I double down on this just for a second? >> Um, we are working with one of the biggest companies. >> And I listen, I have to I have to apologize to our European listeners. I don't we don't want to make fun of the situation there. It's it's serious. And >> just just spend two years in the middle of it and then go back home. And that's that's the way to solve the problem. >> Look, I spent all the '9s living all across Europe, right? In like five different countries. So, I've got some kind of personal thing here. In terms of the the ability to live and have a great life, Europe is amazing. But in terms of technolog technological progress, it's not really the place to be. You have to move to the west coast and others. We are working with one of the biggest uh uh European companies. It's one of the biggest global companies on transforming their metabolism and we finished one of our major sprints with them and they said well we need to start another one right right away and this was back in February and they said let's have the first meeting about it in October. >> Yeah. >> And this is the problem the the people aren't seeing that the metabolism of everything that is happening needs to accelerate by a hundred times across Europe for them to jump to get there. >> It's culturally blocked. You know there's a old adage in Europe you work to live. In the US you live to work. >> Yeah. >> Yeah. Which may not be the very best thing. >> Now we're going to live to Now we're going to live to compute. >> Yes. All right. Let's jump into jobs and economy. A few interesting articles this week. Uh the first one is Michael Dell's $6.25 billion investment in America's kids. Uh, so it's called Invest America and it will give every child born after January uh 1st of 2025 an investment account of $1,000 and it'll be deposited to build financial security. Let's take a listen to Michael and Susan Dell describe what they're doing. >> We're making a $6.25 billion investment in America's kids through our charitable funds. >> Next year, every American child will be able to get an investment account powered by Invest America. We've seen what happens when a child gets even a small financial head start. Their world expands. >> The real power of these accounts is that anyone can contribute. Parents, relatives, friends, everyone can help shape a child's future. >> To philanthropists, companies, community leaders, if you want to be part of something truly meaningful for our kids, for our communities, for our country, join us. So I you know celebrate them for that effort. Um there's been a number of players who have talked about similar situation. Of course being able to invest uh versus just save is a part of what's America made America great. Now the question becomes is this too little too late right? Um >> or we're just flatout irrelevant given that all education is moving to AI. You know this better than anyone Peter. the I mean one of the questions became uh you know maybe what's going to happen is every single kid will have an AI agent that is out there generating revenue for them right this was a where was the conversation we had about this um no it was it was the conversation that uh Ilia had in his recent pod saying you know one of the problems is if you've got an AI agent that's doing all this work for you generating revenue supporting you representing you the question is does the human uh fall out of the loop uh and becomes irrelevant and is it important instead then to ultimately merge with AI? But that's a different conversation. I >> that's a different conversation. But I think I think I'm 100% sure of this topic. You know, teaching at MIT, Harvard, and a little bit at Stanford. Uh there was a huge push to move all educational materials online when the internet exploded and it it kind of worked and kind of didn't work. You know, it made all the material available. >> I mean, yeah. ing. I am 100% sure that now that there's an AI face and voice that matches your personality on top of that that it's going to absolutely take off. >> Sure. >> And and traditional education will be completely irrelevant imminently because because it can match your it matches your accent, your favorite voice, your favorite star, your >> Well, I think this is more than just for this is more than just for education, right? I think this is more about how do you provide a financial stability? We've talked about this in the pod before that, you know, this was back a few episodes ago on the data from FI9 that the majority of the world is absolutely concerned about not being able to be employed uh and the cost of living and if you have a, you know, a seed kernel of capital when you're born that is growing by the time you're 18, does that give you some additional stability? Sem, you were going to say >> I have two thoughts about this. One is I really really love the fact that it has every child born and it's kind of essentially universal. It's creating a wealth floor for every kid which means every kid from day one will be thinking about huh investment and how do I think about it etc. I didn't come across the concept of investment until I was like 16 or 17 right? If I had had that way earlier I'd be a way richer person today than anything else and I think that by adding the employer add-ons and encouraging people to contribute you're creating a community effort here. So I think that it may be late to be doing this but at least it's being done and I got to applaud them completely for doing it. >> Well I think also [clears throat] it's just money so it'll be pivoted over to access to compute and say look education oh it doesn't have to be tuition you can also get you know your GPUs that you otherwise >> ultimately that's the that's the currency that matters ultimately it's just hard for for folks to to acknowledge that and understand it. Emod >> I mean >> well yeah I mean it used to be that capital is what compounded right? You give people money earlier that $1,000 become $20,000. Now it's comput and cognition that compounds >> as [clears throat] you move to self-arning systems like your capital almost becomes irrelevant as the compute can get capital quicker than anyone. It's all about again how do you build that whole cognition architecture around you. So I think this is great. And then the other thing is we got to give people access to frontier compute as young as possible as well >> in a way that makes them able to compound the benefits from that. >> I would just add this to my eye looks like the beginning of universal basic equity. We we've spoken on the pod about UBI, UB, UBS. This looks like universal basic equity where every person in the economy will have an equity stake in the economy. And I if we do see hyperrowth, macro hyperrowth over the next few years, then $1,000 in a a 530A account, which is again what this Invest America, thank you Brad Gersner for for helping to conceive this idea. what $1,000 in an account now in a 530A account few years from now if we experience hyper hyperrowth could be quite material to a person's living circumstances. >> Yeah. And Brad's brilliant and he's agreed to come on the pod and talk about his moonshot. So we'll make that happen uh probably in early 2026. Along these lines, our next story here, college students flock to a new major, AI. Okay, not very new for us, but AI majors are exploding with popularity with schools like MIT and UC San Diego and launching AI branded degrees. So Dave, I'm going to go to you first. Everything is AI at MIT these days, right? >> It sure is. Yeah. So this is at MIT lingo. This is course 64, which was only added just a minute ago basically. Uh and it's already almost caught up to 63, which is core computer science in terms of people who are majoring in it. And I'll tell you, when you talk to the students, they say the curriculum sucks. There there are two or three great classes. Well, because you're trying to build an entire major and there's only two or three classes so far. You know, it takes takes the school too long to build, you know, the material because they're used to this much slower time scale. So, I'm sure it'll fill in because the demand is is so high. But, as of right now, there's just a couple of classes and then a whole bunch of garbage. Um, which is frustrating the heck out of the students, by the way. Everybody wants to move to this and for good reason. It's the, you know, no matter what you're trying to achieve in life, whether it's biotechnology or space travel or whatever, the way to achieve it is via AI. So, if you get a good grounding in AI, you're actually then empowered to do virtually anything. So, it's it's the perfect thing to study anyway, especially when you're young and you have time on your hands and you can really grind through these complexities. So, I I'm really glad this is happening. I just want the curriculum to move much faster to, >> you know, catch up. The interesting note here to add is that AI related job postings in the US uh was up 50% year-over-year from 2024. So continue that that's going to continue. Any other thoughts on this one? I mean it feels kind of obvious and I think the biggest challenge I've got is it shouldn't just be in college. I mean we should be seeing this in high school as well. >> We're going to see a lot of people that are going to skip college. I think uh that's a debate that we've had. So, um, if we can get you started in high school to think about AI, think about the world you're going to be inhabiting and inheriting and how do you use this technology to create your vision and your your passion? Immod. >> Well, I'll tell you if there's one actionable thing to talking to every school administrator, every high school principal, every college administrator, approve the applications. When the students say, "I I want to study this on my own. I don't want to study that." >> Yeah. >> Just say yes. Just approve it. Let them let them carry themselves forward. Don't hold them back. And >> intrinsic motivation. Intrinsic motivation. >> Unleash them. Unleash them. >> My favorite Joseph Campbell quote is follow your bliss. Let them follow their bliss. >> Yeah, that's a good one, too. >> Yeah. >> Yeah. I think I think it's fascinating because the fundamentals of AI are not actually that hard. Like it's not easy math, but it's not like that hard mathematics. My take is like if you have a semivocational course where you do fast.ai which is a fantastic intro into the math and the basics for programmers. Andre Karpathy's video series on YouTube and then you just vibe code and build and the entire class like implements some latest research every month. That will put you way ahead of everyone. I think that CVS and qualifications move to show me what you have built and done with AI. >> Like, >> yeah. So, if you're if you're listening to what Ahmad just said and you're a student, uh, take exactly what he said. Take the Carpathy material. Carpathy is the one guy from that OpenAI original crew who is not a self-made billionaire because he's building education for the world right now. He's given up. He could be a billionaire tomorrow if he just signed some documents. He probably is anyway actually from his own banana stock. But putting that aside, he's he's building out the best educational platform you could ever imagine. Just go find him online. Then tell your high school teacher or your college professor, I want to study this instead. >> Can you allow me to do that in replacement for this class I would have taken? Brilliant. >> That that's the solution. >> But what you just said is antithetical to the concept of a university structure, which is >> or a high school or a high school uh program. >> Yeah. [laughter] Just um >> I think just just quickly I think that if you implement the stuff together and discuss it >> and again that fits with it. It's way better than doing it by yourself. >> Mhm. >> Uh for for sure. But I'm just saying I'm just saying you have to literally hijack a high school curriculum or university curriculum to do that because it's not offered today. to Dave's point earlier, um, Peter Lily, my wife, has been pressured by all the local parents to have a day of just AI mind shift for all the teenagers. So, we're going to do that and pilot that out and see how >> I heard I heard that you've stolen Max Song, my my strike force member to join. >> Yeah, [laughter] >> I should also point out, Peter, I mean, just want to look at this for a minute from the perspective of economics. Right now AI engineers are complimentary good or complimentary service to AI comput the the cost of intelligence is going to zero and so right now pursuing careers and majors in AI highly complimentary but but but but recursive self-improvement is also potentially imminent and to the extent that recursive self-improvement gives us soon AI engineers we might start to see AI itself become a substitute for AI engineering labor in which case Maybe this rush to to major in AI at MIT and UCSD maybe [clears throat] reverse itself, unwind itself and everyone goes back to majoring in the humanities like they used to. >> And we h yeah and we had the conversation in the past about you know co should you learn to code and there comes vibe coding. Uh one of the conversations we had yesterday up in uh Redmond, we'll we'll hear about it later this week. Uh was the importance of of studying philosophy. All right, let's talk about the next uh the next job boom uh which are in data centers where the gold rush is for construction workers. So AI data center construction boom is making welders, electricians and supervisors earn between 100k and $225,000. Uh and these AI companies need that kind of labor. There's a national shortage of 450,000 skilled trade workers. Uh and it's uh it's significant. Um, you know, this is a alternate career path where you don't come out with hundreds of thousand dollars in debt, you come out with the ability to earn immediately. Uh, how long will this this uh opportunity last before Optimus 4 or five or figure six comes in and does this work for us? I don't know. Maybe it's uh 5 years, 10 years, something in that in that realm. Thoughts? I agreed. I I think that that is the the multi- trillion dollar elephant in the room. As with college majors flocking to to AI in in this case right now, if uh if you can pursue a career in the the so-called skilled trades to facilitate tiling the earth with compute, drink your whatever. Again, I I I think that that's potentially very promising local strategy. But of course, 5 to 10 years out, and I agree, Peter, with your your timelines, we're going to see humanoid robot substitution effects. >> All right, let's jump in. >> Yeah, go ahead. >> The economics and dynamics of AI data centers are really similar to fracking actually when you think about it, >> even the financial structures and these booms in these industrial kind of areas. So, I think it'll last longer, but let's see. I find this next article. So Amazon I is expanding its network after talks with USPS stall. So you may not know this but uh the US post office is one of Amazon's main delivery carriers. So the US post office is delivering Amazon packages last miles in rural areas. Uh it's been a significant about a $6 billion per year contract between the two and uh that contract is breaking down. Um my prediction is the US post office will be put out of its own misery and Amazon will get a contract from the government. Today the US post office has about an 80 billion per year operating budget and it's losing 7 to10 billion per year annually. Um thoughts, comments, Jens, >> what happens when we have last mile robotic delivery services? I I think we have to prepare for that imminent future here and that that is probably best done by the private sector. >> Drones, you know, we saw an article probably about a month ago that Amazon is giving its drivers now uh augmented reality glasses, right? And it's saying to the drivers, "Okay, wear these glasses. will warn you about if there's a dog in that in that apartment building or that house, it will show you where to drop the package and so forth. And I think what's really going on here is that Amazon is collecting all of the last mile or the last 100 meter data uh and and being able to train its future robots, right? Autonomous trucks, autonomous robots doing that last uh 100 I keep want to say 100 feet. I hate the fact that we use feet uh and pounds in the United States. It really drives me up the wall. And it drives me up the wall that science fiction writers are using that as well. Damn it. We [laughter] need to Did we switch over to metric back in the 60s? Pain in the ass. Anyway, uh yeah, this is going to be uh an interesting battle. How what's your under over on how long the post office lasts? Anybody? >> Well, the p this is an interesting bellweather because it should have been privatized probably 30 40 years ago. Everybody knows that. But it's written in the constitution and you know nobody wants to mess with the constitution but it's so obvious like like space travel is getting or space launches are getting privatized. Uh it's not in the constitution because space didn't exist when the constitution was written. So it can just move over to SpaceX and Blue Origin. >> By the way, look at the FedEx line, right? I mean FedEx had such an amazing lead. Fred Smith was such an extraordinary entrepreneur and it's been just slowly on a decline. All right. Um I I'm my my guess is US Post Office has at max five years left. >> I don't if anybody wants >> That's how it would have about the same. >> Yeah. Yeah. >> It'll take an act of Congress. >> Yeah. And two3 ratification of the states. It's it's a structural like this is a good case study. It's not that big a deal, but it's a great chance to learn like what are we going to do that's blatantly stupid because of legacy structure and and how is that going to get fixed? So >> yeah. [clears throat] All right. Uh let's move on to space. Uh a fun subject. Uh there are four space stations under development in the US today. Uh VAST uh which is going to which is being launched by SpaceX. Axiom Space Star Lab and Blue Origin orbital Leaf. Just throwing this out because it shows finally we're going from government to truly commercial inhabitation. Uh Alex, do you want to add anything here? Yeah, it's not a coincidence that there are four separate private space stations that are about to launch. These are actually all causally related to a NASA program. When we speak of privatizing the government, NASA in 2021 started the commercial LEO uh low Earth orbit destinations program with ultimately $1.5 billion in funding. And the the SpaceX surge to to space that we saw was in in part the result of another analogous NASA program to to try to commercialize >> commercial crew program. Yeah, >> that's correct. >> Yeah. In in fact, the commercial crew program uh was what saved SpaceX, right? SpaceX had three launch failures of their Falcon 1. They got the fourth one finally to orbit after Elon literally borrowed money to be able to put that together. And in Christmas, was it 2008? He won a billion dollar plus contract from NASA to go forward with Falcon 9, which is today the most successful launch vehicle on the planet by like an order of magnitude. Yeah, >> that that's right. So, the commercial LEO destinations program was spun up in part because the International Space Station is going to need to be de-orbited sometime soon and there was a desire for a private US space presence to succeed the ISS. I I I'm very optimistic about all of these and other private space stations. I think we're we're going to see an exponential rise of humans in lower Earth orbit sometime. >> You know what I'm excited about as well, Alex? Jared Isaacman. I I cannot wait. So Jared Isaacman is back on the docket to be our NASA administrator. Um I'm not sure when the congressional hearings finalized. Do you know? >> Uh several days ago. >> Oh, is he is he in finally? Well, there has to be a vote, but the hearing was several days ago. >> Okay. So, uh I've been texting with Jared and he's agreed to come on the pod as soon as uh the confirmation is done. So excited about that. He is he is brilliant. Um absolutely brilliant. I've known him for a long time. I took him to Russia to watch the uh souse flights from some of our commercial launches there. All right, continuing on. Uh >> wait, I have a quick comment. Yeah, this this uh space station thing reminds me of a date put out by I remember one of our NASA astronauts telling us the most interesting date in the world for him was October 31st, 2000. And it was on that date that the first human being lifted off of the International Space Station. And since that date, we've always had some h at least one human being off planet. >> Mhm. >> And so the first molecules are kind of drifting off this thing. So, this next article is a bit of a surprise uh that SpaceX is considering a 2026 IPO. I mean, I've had this conversation with Elon. He was always resistant to take SpaceX public for a number of reasons. When you're a public company, you have to disclose all the details. Doesn't want to disclose all of his details and how he operates uh to his competition. But the other thing in particular was, you know, if you're a public company and you're spending a whole bunch of money to build Mars vehicles to go and colonize the Martian surface, uh, is that something which your shareholders are going to support? Um, so, uh, listen, I'm a SpaceX investor. I've held it from the very beginning. I I would love to see it public. I always thought that what Elon was going to do was spin out Starlink and take that public and keep the launch capability. >> That was the conventional wisdom. >> Yeah. I >> I think Oh go ahead. Sorry. >> Yeah. >> No, I mean like Elon's a smart guy and he's got a million GPUs and so they'll have more AI lawyers than anyone to attack the stupid people that come after [laughter] them. Uh, but I mean serious this is like >> SpaceX, XAI, Tesla all will basically have full AI teams top to bottom. Like you can criticize their strategy. They all will just clap back at you. You can sue them for the silly stuff and the AI will just clap back. It's a big difference in the way that you can actually run public companies. >> Yeah. You take SpaceX public and you take X public and Elon, you know, leaps over the trillion dollar mark in terms of personal net worth. Okay. >> I'm also maybe just to comment quickly. I'm also not sure [clears throat] the historic story that Starlink would spin out and do its own IPO. I I think with the rise of orbital data centers, I I think that muddies the water somewhat in terms of Starlink as pure communication service versus Starlink as a predecessor to orbital data centers and putting compute up there and and not just comms comm's capabilities. So in that sense, I think I could imagine a scenario where orbital data centers are actually pulling all of SpaceX to go public, not just spin-off Starink. >> Yeah. And that's a relatively new part of the conversation. >> That's right. It's very recent. >> Uh I love this competition. You know, it's it's fun. My mission has always been open up space, and I, you know, built so many companies on on the space theme, and it does the 9-year-old in me so so proud. and and gives me such contentment that two of the wealthiest humans on the planet are battling it out to open the space frontier. So, Blue Origin plans to start flying cargo to the moon in early 2026 using its Glenn Heavy Lift rocket, which by the way uh recently did a launch and full recovery of its first stage. And it's backed by a multi-billion dollar NASA contract uh for targeted human landings in 2028. You know the government has always wanted dual suppliers. So for most of human for most of the American space flight industry for the 70s 80s 90s it was you know Boeing and Loheed Martin um competing uh for for this here comes SpaceX which becomes the dominant player and now you know the government wants the number two and it looks like it's going to be Blue Origin which is uh which is super exciting. Alex, thoughts on this. >> This was basically the plot of season 3 of the television show For All Mankind. >> I love that show. Yeah, >> it's a wonderful, wonderful show. The three-way race. In in the case of season 3, it was a three-way race to Mars. In this case, it's a three-way race between SpaceX, Blue Origin, and China to land humans again on the surface of Mars by 2028 or earlier. And I I think this resumption of a space race which was dormant for 50 plus years and maybe also had collateral downsides for the rest of the economy in terms of overall innovation. It it's coming back to life. We're we're back in the space race again and uh one might hope we'll see a lot of growth and innovation come out of it. >> So the nine-year-old in me is so happy. Just to put some numbers and size against this. So NASA's 2025 Artemis budget, Artemis is their lunar program, uh their human lunar lunar program is $7.8 8 billion. Let's look at that compared to the Apollo program. So in 1966, NASA's budget uh was about about uh well actually the Apollo budget was about 3 billion of NASA's 5.9 budget. So Apollo was half of uh NASA's budget. And if you adjusted the Apollo budget to today's dollars, it would be about 35 to40 billion. So, uh, compare that to the 7.8 billion that we're spending in Artemis. Uh, the we were spending about a half a percent of the US GDP on the Apollo program back in the '60s. Pretty impressive. And and the reason we don't have to do that anymore, of course, is commercialization and technology. We brought the price down, you know, orders of magnitude. I find this article hilarious. Sam Alman enters rocket business to compete with Elon and SpaceX. Uh, you know what's fascinating is, uh, Elon goes for BCI and Sam goes for BCI. Elon goes for space and Sam goes for space. There's probably a few other areas. Any particular thoughts on this one, gentlemen? Well, I'm really curious to see how the code red interacts with, you know, Sam has cut a deal in every single dimension related to to AI, including, you know, Johnny Iive with the wearable device and Stargate with the data center and and Broadcom with the chips, you know, the TBU. So, he's he's cast it out in every direction. >> That's Sam personally versus Open AI, right? >> Uh, it's a mix. It's a mix. the bigger deals are open AI and then there's about three 400 personal deals, you know, that are all the use cases and components. But it's it's a massive metric in this Samoverse, a massive network of of connected parts. But now you've got this code red where hey, wait, the thing that matters at the middle of it is is these a these AI benchmarks and we're now off the chart on poly market. [laughter] >> Code red, code red. So, I'd be very curious to see what that means because, you know, there he has a lot of talent, but there's still a limited supply. It's not infinite. And so, that all gets drawn back into the middle that that's going to cut some of the things on the edges. >> To give some more detail here, the company he's in discussions with is a company called Stoke Space, and it's founded by two former Blue Origin uh propulsion engineers. It's uh as with every, you know, launch company, needs to be fully reusable. It's a two-stage fully reusable uh rocket. It's never flown, right? They're using something called a ring-shaped aerospike engine, which also has never flown. So, it's a little bit of a risky bet. Um, but if Sam wants to enter the orbital data uh data capabilities, I think having space launch capability, and of course, let's not forget uh Eric Schmidt uh is also in the rocket business. Yeah, I think this vertical integration by hyperscalers into space is is probably an inevitability at this point. We're we're certainly not going to get our Dyson swarms drink >> without that. But I I I I also think, you know, imagine near-term future. Are we going to get a meta space station? Are we going to get an anthropic space station? Maybe maybe clusters in space for >> fascinating. Just like we're getting uh just like we're getting uh hyperscaler fusion plants. Uh, >> that's right. >> Yeah, >> Facebook space station. [laughter] >> No, I'm not going there. >> You got to be full stack to control the like cone of humanity. >> Uh, >> exactly. Love that. >> It's a better place to put a name than a than a sports stadium. >> Maybe Instagram space station. I'm not sure. >> Oh god, you guys can makeers here. >> All right. Orbital compute energy will be cheaper than on Earth by 2030. So again, I still find this um kind of challenging just because we have so much solar flux on the Earth and don't have to worry about launch. But if we can really get the cost of launch down to $100 per kilogram, uh which is the projection with Starship versus $500 to $1,000 per kilogram perhaps. Who wants to jump in on this one? I >> I'll just comment. It could also be even cheaper than this once we get compact fusion online. A lot of these uh orbital compute projections are assuming that solar is the primary power source for orbital compute. Doesn't have to be. Once compact fusion is cheap enough, and there's no reason to expect it won't be, we can tile low Earth orbit at minimum with compute as well. And it won't require all of these expensive solar panels. >> So, we're going to throw fusion reactors into orbit. >> Yes. >> Wait. So, the theory there is launching a fusion reactor is cheaper than just a solar panel. You know, the solar panel in space is about 10 times more effective than it is here on Earth, but it's still cheaper to launch it reactor. >> It's maintenance. >> I I think that >> I just won the bingo game. We said launching a fusion space [laughter] wins. >> No, so I mean solar in space is still fusion based. It's just using the fusion reactor at the center of our solar system. So I think that the question is where do we want fusion power to be located for space-based compute and as fusion reactors and there have been a number of uh deep space probes that NASA and other other organizations have launched that are using fision for example uh ion based propulsion. It's it's not like nuclear energy is is that foreign for for space fision thermal has been used by deep space probes for for decades. It's not like we don't know how to to do it. is what's what's going to be new is compact fusion in particular. We've put fisionbased energy in space for decades. >> You know, Alex, I'm looking at the numbers here and it says current terrestrial average is $12 per watt and we're talking about $6 to $9 per watt in space. That's not enough of a difference for the level of complexity. Uh >> yeah, you're going to need at least a 10x drop in that. >> Yeah. So maybe it is compact fusion. Uh, I think if we're actually mining the moon, lest I say disassembling the moon to build uh, you know, the beginnings of >> already won the drinking game. >> Yeah. Well, hey, uh, maybe uh, that occurs. But, you know, I love the fact that it's now orbital orbital data centers that are driving humanity's expansion into space. That's amazing. It would have never have to be it was going to have to be something. I mean, if you look at all the sci-fi plots, it was either going to be the the discovery again for all mankind. It was without spoiling too much. It was either going to be ice on the moon or the discovery of microbial life on Mars or something like that that had to motivate space exploration and development. Who who knew that it was going to be data centers? Well, it had to be something. >> It had to be. I remember when I was in I was at MIT and I was running SDS and I put together this brochure on why open the space frontier and I used to have to rationalize like better materials there and I mean there's like always this like very soft rationalization uh but this is real industry real base people were trying to like what can we manufacture in space that has value here on earth >> this is the moment you've been waiting for in undergrad. I mean, you should be like a kid in a candy store. But it it totally makes sense and it always drove me nuts when, >> you know, like Roman Septa when he graduated, our our buddy uh he went to Ford and he was working on wire harnesses and rearview mirror motors for for Ford. And I'm like, why do we need like a another electric component in a Ford? Why don't you work on space or something foundational that changes humanity? It's like, well, because you know, it's kind of like your iPhone now. new feature for this massive installed base is economically incredibly valuable even though it's marginal for society. So, it sucks up way too much great talent. And something really important like space data centers doesn't get worked on. But you need an economic crack that starts the whole process. And this is this is it. We finally have it, you know, after and it's so much better of a storyline than than for all mankind, you know. Actually, it's it's a lot later. I still I'm still betting I'm still betting on asteroid mining. I mean, everything we hold of value on Earth, metals, minerals, energy, real estates, and infinite quantities in space. So, you know, those those nickel iron asteroids that are worth trillions of dollars in platinum group metal or those carbonious condrites we're going to mine for oxygen and hydrogen for fuel. Um, >> can I burst your bubble there, Peter? >> Oh, don't do it. >> I think AI transformation of material science will ride around all the scarcities around that. Uh, I don't know. >> Or maybe it'll accelerate it. I don't know. When Peter, when you were founding SS, did did you I'm guessing not foresee the plot twist that the killer app would for space would actually be like getting enough compute available to to do generative cat videos doing funny things [laughter] >> that I was not able to project that far ahead uh to be honest. >> Yeah. So, so who who knows what the asteroid belt will actually end up being used for. Uh so you know lest we >> we'll assemble it for compute obviously >> uh lest lest we leave the Chinese out of this uh China a company called Cosmosace is planning to build and add AI data centers in space uh they're putting up a supercomputing cluster with three modules one's got 100 megawatt level energy the other is 10 uh terabs per second comms and the third is uh 10 x operations per second. 10 exoflops, 10 to the 18th level compute module. Uh, Alex, what do you think about this? >> I I think we're seeing a race to build Dyson swarms. It's as simple as that. It's not just a race to the moon. It's not just a race to tile the Earth. It is a race to put as much AI accelerated compute into low Earth orbit as possible. And KOMO Space emerged from nowhere. I had never heard from them several months or heard of them several months ago. And I I don't think an an obscure or otherwise obscure Chinese provider is going to be the last story we hear for Chinese orbital AI compute. We're going to see probably a dozen different vendors from China. We'll see as just discussed dozen hyperscalers in the west and the concern maybe becomes like overpopulation on Mars making sure that all of these Dyson swarms remain interoperable. Uh, can we just point out to all of our listeners, if you've been if you've been following us on Moonshots, this conversation of orbital data centers did not exist 4 months ago uh in any way, shape, or form. It was there. I'm sure people were speaking about it, but it's now become a weekly conversation over the last 3 months. It literally came onto the scene with a vengeance. It's extraordinary. >> Well, that technology clearly works. It's proven technology now. So it's just a question of launch costs. That's that's the only missing link, you know, and and it looks promising. >> Even fig they fig out dissipation side of things. I think that was still outstanding. >> Yeah. No, no, they got I mean there is still there is still an issue of how you can get efficient energy dissipation on the back end. Um in fact that was a subject it was proposed as an ex-priseze this year at visionering. So >> they'll get efficient. >> It'll make more sense. But the the thing that always gets me with this is it's horribly insecure. >> Like you had the proposal by Eric and others like how things go on race go against data centers. Space data centers saying they'll go up and it'll just start disappearing honestly. >> Yeah. I'll give you the counter argument and I totally agree by the way so I don't want to I don't but just to give you the counter argument the hardware depreciates in 3 years anyway. So you only need it to be secure for 3 years. So I think the counterargument is that the US Space Force will will basically guarantee enough safety that you can get three years of hard work out of it before something bad happens and that's all you need to to pay off. >> So what about what about solar flares? One of our one of our subscribers asked that question. What happens when you have solar flares hitting these and what happens when there's an EMP that hits them as well? Right? All of this gets knocked out. >> Uh actually I've got a very interesting thing. So we were trading on thousands of A100s a few years back and we kept getting errors exactly at the time of solar activity because uh it was basically messing with the EMCC memory. >> Wow. >> Yeah. >> So [laughter] we'll find out how these things sustain in the back. >> Yeah, you know this better than anyone but you know a little inside scoop on the million compute clusters that are being built now. they have errors, you know, here on Earth, too. And you have to solve that problem in order to have coherent training anyway. So, the error rate goes up a lot in space, but you have to have a process for backing off. And you can't, you know, right now everybody does checkpoints and roll backs, but you can't, you know, invest, you know, an hour of a million GPUs at millions and millions of dollars and say, "Oh, wait. We have an error. We're going to roll back all of those GPUs for an hour." So, you have to do it, you know, unit by unit. And so, that work is well underway. So presumably that'll work fine in space too and you can you can tolerate the error rate. >> All right. >> The other comment of course is those models just want to learn. So for AI compute workloads to the extent we're doing training or inference they they can be structured to be fault tolerant. >> Yeah Microsoft was actually the leader in that and now Google's the leader in that. It's just seamless the way that it flips. It'll be interesting once we get out of space. >> Our last topic here we're going to dive into robotics just for a few stories. Uh here we are. After an AI push, the Trump administration is now looking to robots. So robotic uh are the focus for a 2026 executive order to accelerate US robotic development. Uh we're seeing this in China, right? China is crowning its winners. It's got huge investments into the robotic industry. In fact, in our last pod, we talked about the fact that there is a at least uh what the Chinese are calling a a robot um uh what do you call it? Um a a robotic uh bubble going on today with over 150 Chinese robot companies. Uh I find this one uh fascinating. Uh after the acceleration, so major national robot strategies are coming online. Robotic firms are likely to have tax credits, subsidies, protection against trade measures, something along the chips act. Once again, uh thoughts, gentlemen? I'll comment that the zeitgeist at Nurips this year was that humanoid robotics is the next big thing for AI after agents. I I think this is how re-industrialization of the US and the West happens. I think this is probably the best path for radically increasing economic growth and automating the twothirds of the services sector that relies on physical intervention that this is instrumentally convergent for the future that we want. >> Yeah. Uh just to remind folks from our last pod we talked about the fact that China installed 54% of the world's total robots last year. So, uh, again, massive, massive push. Uh, I want to show a couple of quick videos here just for fun, uh, to close us out. Uh, we saw in the last week, uh, a little bit of Optimus versus figure competition. Uh, Elon posted this image of Optimus walking. Let's take a look. Here it comes. Running along, jogging. And then we had Brett posting this one of a figure running across. I have to say they look pretty natural compared to where they were six uh you know 6 months ago. Which one did you like better? Let me play this again. Here comes Optimus. Optimus coming along. I don't know. It kind of looks like Figure is doing a better job running to me. What do you guys think? >> I I I think they're both incredible. And I I'd also throw out maybe a request to to the audience for the show. If you're if you're interested in supporting robot athletics in the United States, either as a a host or as a a vendor or in some other capacity, please reach out to me. I I'd like to do what I can to to ensure US dominance uh and Western dominance in general with humanoid robots via robot athletics. >> Yeah. Well, let's take a look at Chinese dominance with this video, then we can talk about it. So, we saw last week the T800 humanoid robot robot from Engine AI in China. This is 5'8 in tall. Uh, incredible capabilities. They put out a new video that I wanted us to take a look at here. Uh, cuz it's a little bit shocking. All right. This is >> Are we 100% sure this is real? By the way, >> yeah, this is this is they claim it's real and this is a follow on. Um [clears throat] uh but uh so here we are with this uh T800 robot basically kickboxing. But check this out when it goes up against a human opponent opponent. [laughter] Uh like wow kind of scary. I'll go back to my standard comment that having a robot doing kickboxing is not a great marketing message. [laughter] >> Yeah, I think calling it a T800 is also not a great marketing message. [laughter] >> What about all the skulls that they put in there on their >> Can I do a little headline? >> Yeah, we love your rant. Go for it. >> Look, a human being has evolved for 4 billion years, which is an optimized strategy. 200 200,000 years as a human being >> whatever for survival we we we have the human structure for to survive and being able to quickly pick fruits off trees so we have opposable thumbs and whatever I mean a wheel is so much more energyefficient than walking it's ridiculous I think for God's sakes at least put those little wheels in the bottom of the robot like the kids with the wheels in their sneakers so they can be more efficient as battery power seems to be huge limiting factor in this so why don't we have a wheel along with the leg so they can do both when it's needed. This this just just this this having robots copy human beings seems to be the stupidest thing in the world. It feels to me like when we first had TV with radio announcers and television reading the same scripts podcast we're going to be doing a podcast from Figures headquarters uh in Palo Alto in January. You're not invited. [laughter] >> Yeah. I don't know. I think this is really interesting. box the robot. [laughter] >> Yeah, >> this is really interesting. So, the entire chest cavity of the robot's actually a battery here. Um, but this is really interesting cuz the 450 max joint torque, that's the really interesting part. Basically, this thing can punch harder than a gorilla [snorts] uh like four times Mike Tyson. Do you really want those to be walking around in the streets? Like, are they going to have to regulations on the max joint talk? Also, if you actually look at the full video, which is real, they even show a behind thescenes one, and you look at the previous video. So, there's something called sim to real, which can basically model human actions in a robot. So, we have full [clears throat] almost real steel, the move with Hugh Jackman, telly operation capabilities now in robots, and soon it'll be policy learning. >> Like, this robot can do freaking kung fu >> with UFC. Punch through. >> UFC is coming. We're going to see Tesla bot, you know, basically Optimus versus T800. I mean, it's going to be Olympic level sports. It's going to be amazing. >> Olympics versus UFC. I think that'll be exciting. But we have to actually ask, do we actually want to have regulations around the max joint talk of humanoids in the street? Cuz I'm fine with these being in the fighting arena. I think it's fantastic. Or an industry, but I I don't really feel comfortable them walking around. >> Yeah. The ch the challenge comes >> No, no, the kitchen. You're going to be in the kitchen. that the challenge comes when they enter warfare, right? I mean, this is Terminator uh in sort of the pure sense of robots on the battlefield. Uh and it's a scary direction for us to take humanity. >> Yeah, I think it's all of the above. It it'll be warfare. It'll be in the kitchen. It'll be on the street. And you you'll see I think govern governance and governments at different levels whether it's municipal or national or international regulations for the parameters of of what the rules of engagement are making an omelette versus fighting a war. >> All right. Um I want to just do a a you know a thanks to CJ Truhart who gave us our first song on the moonshot mates. Uh this is an outro piece called the exponential. Uh but before I play our outro piece, uh gentlemen, uh it's been a blast to spend time with you guys again. I love this. Immad, it was wonderful to have you as a fifth um here today. Grateful for you. Uh what's your week ahead look like, Eman? >> Um lots of policy work and more agent stuff. We got lots of releases coming. Exciting times. >> And how was Japan? you were there for FI Japan. >> Fantastic. Huge amounts of corporate and government interest in using AI to help accelerate the way forward. And so again, hopefully some announcements about that soon. >> Yeah. And uh and Dave and and AWG, you're about to hop your flights back to Boston, I gather. >> I think collectively we covered 12 countries in the last week and a half in this group. >> So it'll be nice to be home for at least a week. >> Nice. And uh and same for you Salem. Chance to stay home. >> Yes, I'm here for a bit. I just got back. So I'm going to be I'm preparing for the big uh online meeting of life session where if people are interested come armed with any question you have about life and let's frame any question. >> Yeah. When when is it Salem? >> It's December 17th 11:00 a.m. Eastern. We'll go for several hours on metaphysics philosophy and the >> and when when Sem says go for several hours like six to eight hours. >> Well, it's a big topic. You know, there's lots to cover it. It is uh for sure. >> This is an example. We start off on a conversation of what is truth and have it broken down to a 2 by two framework that that this is sensemaking. It allows us to have a decent conversation. What do we mean? Do we mean by that? >> Well, on Monday, I'm heading up to the Buck uh in the Bay Area to talk about longevity and AI. Uh my favorite one-two punch. And with that, let's listen to the music of CJ Truheart as uh as we wrap this episode. And gentlemen, see you on the next episode of Moonshots. Thank you to all our subscribers. If you haven't subscribed yet, please do. We're now putting out uh more than one episode a week uh just because the speed is moving so rapidly. So, if you want to know when the episodes drop, a quick hit subscribe and uh and let's listen to CJ. >> [music] [music] >> Linear thinking held us down, crawling centuries slow, [music] but something shifted in the code. Now watch the numbers grow. [music] One becomes, two becomes four. The double and never ends. Deceptively flat at [music] first, then vertically ascends. Can you feel it building the pressure in your chest? This is the MOMENT WHERE THE FUTURE MANIFESTS. We're rising exponential [music] straight up to the sky. [music] Every second accelerating this the time to be alive [music] is democratize the dream. Nothing's ever been [music] fast. We're breaking through the sea on the curve of infinite rocket boost. And now the inflection point is here and we're never [music] coming down. >> All right. If you're a music producer uh using AI and you want to give us an outro, just go ahead and uh let us know. Uh and please next when you're watching this and you have questions, please post them in the comments. We are going to do more AMA in the next couple of sessions. Gentlemen, uh, moonshot mates Dave AWG, Mr. Exo, Emod. Thank you guys. Having a fantastic week. Every week, my team and I study the top 10 technology meta trends that will transform industries over the decade ahead. I cover trends ranging from humanoid robotics, AGI, and quantum computing to transport, energy, longevity, and more. There's no fluff, only the most important stuff that matters, that impacts our lives, our companies, and our careers. If you want me to share these meta trends with you, I write a newsletter twice a week, sending it out as a short two-minute read via email. And if you want to discover the most important meta trends 10 years before anyone else, this report's for you. Readers include founders and CEOs from the world's most disruptive companies and entrepreneurs building the world's most disruptive tech. It's not for you if you don't want to be informed about what's coming, why it matters, and how you can benefit from it. To subscribe for free, go to dmandis.com/metatrends to gain access to the trends 10 years before anyone else. All right, now back to this episode. [music]