# The Frontier Labs War: Opus 4.6, GPT 5.3 Codex, and the SuperBowl Ads Debacle | EP 228

Published: 2026-02-15

Anthropic drops, clawed, Opus 4.6. It's the new king of the hill on coding, reasoning and research. There are so many aspects in which this is a feel the AGI moment. By every measure, it's a beast. Opus 4.6 just dropped and it's absolutely wild. This thing handles 1 million tokens now. That's like reading 750,000 words in one go. This is recursive solving. This is a model that's able to rewrite essentially the entire tech stack underneath it. ChatGPT market share falls between 25 and 26. So what is the next move for OpenAI to get the mojo back? For the general public, if you think you absolutely have privacy, I would say, guess again. A fundamental pillar of American society has been washed away with no public conversation about it. AI can read your lips from 100 meters away. I can walk over to you and shake your hand, grab a few skin cells, sequence you and know everything about you. I do think it is possible to maintain privacy even today. And I think it will be possible even post-singularity. I've got to say, I just don't see it happening. Now that's a moonshot, ladies and gentlemen. It was fun. We dropped the last episode earlier this week, and I'm reading in the comments, you just dropped the episode, and Opus 4.6 and Codex just came out. It's like, the world's changing way too fast. It is nuts. I was with a group of 150 chief security officers over the last couple of days. And it was pretty epic to see the shock in their faces watching what's going on. Because they don't have the mechanisms to react. Because if you're in security, you do what you always did until it breaks. But doing what you always did is not an answer. You have to change. And change, of course, introduces risk, and they don't want to take on the risk. But the risk of doing what they were doing before is a surefire strategy. Well, of course, it's going to be a group of agents are going to take the role of chief security, and it's going to be a black hat, white hat agent battle that goes on continuously. That's definitely been an inflection point for me. After this last episode, I started getting emails from Maltese, Lobster's agents. They're all writing to me. I'm jealous. Absolutely jealous. So, Maltese, I want you to write to me as well. Peter wants your love as well, Lobsters. Write to Peter. I want, for sure. Please, write to us both. Alex's daily digest is very AI-oriented, though. It's very easy for an AI to navigate to Alex versus the rest of us. Here's my challenge to the Maltese out there. Find my cell phone and call me. and then find my email and email me. Are you crazy? No, it's okay. If they can find it, I want to hear from them. Absolutely. Peter, you want to be doxed by the Maltese? Listen, I think it would be an extraordinary experience to have that happen. Now, Alex, do not give it to them on purpose. That's fine. I'm not going to dox you, Peter. But, you know, if you want to be doxed by the Maltese, They're pretty capable. Well, listen, it's a challenge. I'm putting a challenge out there. The first multi to call me, yes, you're going to win, I see, $100 in crypto. That's a pretty low bar, but I like how you're offering to compensate them in crypto, given that they're being encouraged to pump altcoins otherwise. Yeah, well, hey, just feeding them some greenbacks is going to be difficult. All right. Are you guys ready? Enthusiastically, are you guys absolutely ready? I came prepared today. Okay. You're going to have fun, right, Salim? You might as well really have fun. Well, you've got to process non-linearity. So we are officially recording a Moonshots podcast episode twice a week at this point. At least. And I think we hit three times in the last two weeks. Anyway, shall we jump in? That's what the audience is asking for. Right in the continuum limit, we just never stop. Yes, that's what they're saying. It's like, we're on all the time. 24-7. It's like a Truman Show freaking rerun. All right, everybody. Welcome to Moonshots, another episode of WTF Just Happened in Tech. This is our effort to get you future ready. This is the number one podcast in AI and exponential technologies, getting you ready for the supersonic tsunami. I'm here with my incredibly brilliant and very gracious friends, Alex Wiesner-Gross, our resident genius. uh db2 you know dave you have been just just spot on and all your comments over the last few weeks just so impressed by everything you brought to the table so really well i'm gonna shut up today then and i've got to say i've got to say dave the multis in the background i mean how many lobsters do you have on screen with you there uh Probably a dozen, I guess. I'm growing exponentially. I'll be buried in troubles. Pandering to the future. Pandering to the future. This is my way of apologizing. Salim, do you have lobsters there with you? I don't have lobsters. I went onto Amazon and ordered a dozen, so I'll have them next time. What's that? Oh, there's Alex. The last lobster sent to me my friend, Jonathan. Thank you, Jonathan, for the glass lobster. And here as well, the emperor of exponentials, Mr. EXO, Salim Ismail. Gentlemen, I have to say that, again, I love these conversations. These help me keep on top of everything because there is so damn much happening every single day. It's insane. Well, I got to say also that last episode was just unbelievable. For those watching... if you haven't seen it, please go watch it. It's like seminal, I think, in history. It'll turn out to be a really meaningful moment. I agree with that. And also there was news coming out while we were doing it. So we're looking at our monitors going, oh, crap, we've got to get back online again. What's it called now? I'm literally getting ready for this episode now. The last hour I'm looking through through tweets and through Alex's link posts and like, okay, what am I going to add? There's a lot, every hour on the hour. All right, but let's jump in. A lot that's happened in the last 24, 48 hours. Let's jump into the top AI news on Anthropic OpenAI, a little bit on X. So, Anthropic Drops clawed Opus 4.6. It's the new king of the hill on coding, reasoning, and research, handling a million tokens, outperforming GPT 5.2 in 144 ELO points. Alex, why don't you take it away? What does that all mean? And out of curiosity, how does that price compare? Yeah, it's a more efficient model, but more importantly, it's a more capable model. And there are so many aspects in which this is a feel the AGI moment. I mean, every new model that comes out, I could just read you a litany of all of its benchmarks and how it's this new state of the art according to all of these benchmarks. This time I want to highlight not how it's the new number one across a wide range of very important benchmarks, but highlight what it's capable of, which is with this announcement of Opus 4.6, and I'll add parenthetically, the rumor is that this was actually intended to be Sonnet 5 and was rebranded at the last second as Opus 4.6. The team at Anthropic announced that they were able to use Opus 4.6 in its new agent team mode. So this is a new native mode that enables Opus 4.6 agents to collaborate together in a swarm. It's a relatively democratic swarm, not sort of a top-down team leader and team member swarm, but a pretty flat swarm. and enabled them to create from scratch a C compiler that worked across multiple processor architectures written in the language Rust from scratch for only $20,000. And that is a task that would historically have taken many, many person years, probably person decades to do something like that from scratch and have it work. So I think Rather than just rattle off a list of how amazing it is according to various evals this time around, I want to highlight that we're now in the era when new model releases are able to accomplish great feats, like great projects, and we're starting to measure their capabilities in terms of how many person years or person decades they're sort of collapsing, hyper deflating down to, at the moment, $20,000 of API calls. And soon, I think it's going to be hundreds and tens where we're seeing hyper deflation right before our eyes. You know, a couple of comments on that C compiler too, you know, a bunch of the teams here around the office were talking about it. It's a really good case study in how you can turn loose a huge amount of AI compute if you have evals and constrained proof that it's working. So a C compiler is a beautiful test case because the code coming out the other side either works or doesn't work. You can benchmark it against existing C compilers. It's just a beautifully evaled, contained, constrained environment. And so those projects just flat out work across the board now. So what I did today, actually, I launched about 20 documents asking for data gathering across all the companies because the AI can only function if it knows what's going on. And that C-compiler benchmark is a really good case study in what a lot of corporations now need to do. If you want to turn loose AI, you want to use it to either cut your costs or expand your market share, it needs knowledge. And this is why Mercor is doing so well. Mercor is, I don't know if I'm allowed to say this, but a billion-dollar revenue run rate now. Wow. Got to be the youngest CEO in history by far to hit a billion-dollar revenue run rate, just gathering data all over the world to feed the great AI machine. And so I think that CK study is a good benchmark for, okay, that works. And it'll get better at looser tasks over time. But as of right now, any really tightly defined, constrained task, that's where you want to go. Well, this seems like... I've got two comments and a question for Alex. This means that intelligence is entering its full cost collapse phase, right? This seems like an incredible thing. Yeah, and recursive self-improvement as well. If it's able, as it's claimed, to write an entire C compiler, which I should add was then used to successfully compile a Linux kernel, Again, from scratch, this is recursive self-improvement. This is a model that's able to rewrite essentially the entire tech stack underneath it. So again, we're at this point of recursive self-improvement, not even just being in the lab. I make the point of my newsletter. It's out in production at this point. We have fully productionized, recursively self-improving systems. And the other one was the 70% head-to-head seemed pretty staggering. Did that surprise you? Were you expecting more or less? How did you react to that? You mean the relative ELO scores? Yeah. I tend to view ELO-based scoring as more of a tit-for-tat. It's great that that we have ways to score on systems where there isn't some sort of absolute standard and where we instead so for those who don't pay super close attention ELO scoring originally borrowed from the chess world is a way to score models or other systems against each other when you lack an absolute standard so it's a relative measure of performance rather than measuring against some absolute standard I think ELO-based scoring is great if there is no alternative, but I tend to, on the margin, discount ELO-based scoring in favor of wherever possible, objective, absolute measures. And by every measure, or by almost every measure, I should say, Opus 4.6 is just, it's a beast. It is an enormous accomplishment. We don't know yet from Meter the autonomy time horizons. They've just released the time horizons for GPT 5.2 high reasoning, and that's already like six and a half hours. I wouldn't be shocked if the time horizon for autonomous software engineering by Opus 4.6 ends up being 20 plus hours, maybe even longer than a day. And when you're saying that, Alex, you mean the time horizon over which it continuously works on a task? That's right. It can successfully to either 50% plus or there are other thresholds like 80% plus success rate autonomously work on a software interface. engineering task. And we're seeing those time horizons just skyrocket, not even following the AI 2027 scenario, which projected an exponential extrapolation. We're seeing them follow a hyper exponential at this point. Yeah, I'll tell you what, those charts are worth tracking because back when I was first building neural networks way back in the day, you know, the benchmark was all MNIST character recognition. And when we got from 60 to 80 to 90 percent accuracy on that benchmark, you could see this curve going way, way up. But then when it went from 90 to 92 to 94, it looked to the world like it had flattened. And I'm trying to tell the world, no, it's massively more intelligent, you know, with each tick toward 100 percent. So the way these charts, these benchmarks and coding are set up, they have the same flaw. To go from 80% to 90% to 95% is a massive increase in capability, but it doesn't look like much on this type of chart. So we have to look at that other chart where you're seeing it work for hours on end on a task and come out with a good result, which looks much more like what you should experience, which is this exponential effect. It's just a bad way to demonstrate it, you know. So this week on Propix on Top, can I ask the question of, you know, the process by which they're improving their systems? I'm assuming that all the other hyperscalers, or at least, you know, XAI and OpenAI and Gemini are using the same methodologies to improve their capabilities. And it's just a constant leapfrogging. Is there any deviation, anything special that Anthropic is doing on their own, independent of the other models? I think we're starting to see differentiation. So the historic stereotype historic, like past few months of history, maybe like year and a half of history was that Anthropic was focused on code generation. The narrative was supposed to be that Anthropic being compute-starved had to focus on just one thing that was very profitable, which is code gen for enterprise. That was the narrative. But if you look at some of these benchmarks, there's a narrative violation hidden in plain sight. Look, for example, at humanity's last exam. in principle super interdisciplinary. It's not just focused on code generation. It's not like Sweebench Pro. It tests humanities knowledge among many other skills. The narrative violation is that with tool use, Opus 4.6 was able to achieve state of the art on humanities last exam. That's a total narrative violation. So on the one hand, to your question, Peter, that the narrative is supposed to be, well, we're seeing speciation by all of the frontier models and frontier labs, with Anthropic focusing on techniques that are maybe very favorable for code generation, and OpenAI focusing on being the quote-unquote core AI platform for everyone and focusing on multimodal especially. The narrative for Google is supposed to be, again, I'm just like reciting cliches at this point, It's supposed to be that because they have this enormous pre-training corpus like YouTube and the Google web cache, that they're in the best position to have the best pre-trained models. And they're the ones always being characterized as having big model smell, if you will, because they have such amazing pre-training. And XAI has sort of, again, I'm reciting cliches, is the one that's always being accused of bench-maxing on their favorite benchmark. So each of them has sort of a character that they've built up narratively. But I think we're seeing all of that get scrapped at this point. The market is so competitive. Are we basically seeing the models all improving at max speed on all fronts and all directions. I think we're starting to see models with probably fundamentally different back-end strategies start to converge on leapfrogging each other across all benchmarks, which I wasn't expecting to see at this point, doubly so from Anthropic. It's mildly surprising to me to see that Anthropic is becoming competitive on non-code-gen in principle benchmarks. If you'd like to get access to the MetaTrends newsletter every week, go to diamandis.com slash MetaTrends. That's diamandis.com slash MetaTrends. I found this one fascinating. And Salim, we were talking about this a moment ago on security, that Opus 4.6 can help evaluate, find bugs. Found 500 plus high severity vulnerabilities in open source code. I mean, I think that makes sense to me. The challenge, of course, is this is the world we're inheriting where AI can create a huge attack surface on all the software out there. if it isn't working for humans, if it's working against us. Thoughts on this, gents? I tell you, this was a really great day for me because I thought we were going to have another sonnet and instead we got a new opus. Because I use opus for all my work and all my agents. And, you know, another sonnet I wasn't even going to use. And then it hit yesterday. I've been using it all day. And my little Bank of America meter in the corner that pops up every time it charges $100, it pops up another dialogue in the corner. It slowed down dramatically today. It was noticeably fewer $100 extractions in the corner. So it was like a gift, a totally unexpected gift all day long. I haven't noticed the increase in intelligence. I'm sure it's in there. It was working so well before. It's now just cheaper. And I'm sure working better. It's worth pointing out, if this rumor is accurate that Opus 4.6 is actually just a rebranded Sonnet 5, that would suggest that it should be much cheaper, not for any reason other than just the Again, the historic strategy across all of the major frontier labs is one of iterated, or at least what used to be called iterated amplification and distillation. So perhaps Opus 4.5 or some similar model was distilled down to a smaller, faster, more efficient, cheaper model that ultimately became SANA 4.5 and then renamed 4.6. Very, very likely that's the case. But it is just flat out better. There's no reason not to use it. It's just better in every direction, cheaper yet better. So there was a few things in this overall deck as I was looking for that really blew my mind. This was one of them because this means that you have AI as a force multiplier solving all these old bugs. I think that's incredible. I was just a day and a half at the Zscaler CXO, all the chief security officers getting together, and they were really freaked out. And I was trying to show them that, look, AI gives you all of this capability. You'll have the best cybersecurity professional on Earth via AI just in, like, literally days and weeks. This came a day later than I was speaking. So I'm kind of annoyed at that. And so this is unreal that we can do this. The other thing was the PowerPoint plugin is just a massive thing. I think that's going to really have a huge impact. I can't wait to get it working. I tried before this did try. Yeah, that's so funny. I had the exact opposite reaction, Celine. You know how printers used to be a really, really big deal. HP had a huge market cap. We would all take everything we were doing and print it and take it into a meeting and say, look, I printed it. I feel like PowerPoint is hanging by a thread in the same direction. Like, wow, AI can create great PowerPoints. Well, who can present them to? The audience is AI. It doesn't want to look at a PowerPoint. It's just like this idea is very short, I think. I was joking sort of gallows humor in my newsletter that the Claude Furr PowerPoint plug-in is is going to be great for what's left of the knowledge work economy. But for the zero days, though, I think this is the tip of the iceberg. Of course, it's a huge accomplishment to discover zero days that had been undetected for decades. But imagine, just think for a second thought experiment, how this generalizes to discovering all sorts of other mistakes and and oversights and missed discoveries that may have been missed for many decades. And we're just going to be able to bulk solve every missed oversight in science, engineering, and technology. I can only imagine over the past 80 to 100 years, all of the oversights, all of the missed turns in science and engineering, we're just going to be able to turn really strong frontier models at our entire history and ask, where did we make all mistakes? Highlight all those mistakes and tell us how we can fix them. I'm cough, cough. I think I mentioned this a couple, two, three months ago on one of these podcasts that when we turn this AI into legacy experiments that have done, it'll surface all of these missed opportunities that people didn't see because they were looking for one thing and they missed this amazing thing over here. I think you're exactly right, Alex. This is going to be absolutely unbelievable. I suspect many of those mistakes are going to be embarrassing. I think there's always sort of hand-wringing in, for example, the medical space over certain experiments, certain findings. was money wasted pursuing different theories of various diseases, not to name particular names. And I have to imagine that something like this, it's not just going to turn up zero days in code. It's going to turn up key experimental errors going back decades. You know the stats about the irreproducibility of science out there. It's insane, right? So like, half the experiments are not reproduced when attempted, even in peer-reviewed journals. It's awful. I think Judgment Day is coming for his history of science. I think the truth and reconciliation in every mistake that's ever been made anywhere in the literature is going to happen. Can we talk about the other elf in the room here? Hold on, one quick thing. But look at the positive impact, right? It'll force people to be brutally honest going forward, and I think that's going to be so beneficial. That's interesting. AI spotlight on you. The concern here, if in fact it can do such a great job finding the bugs, how about when it starts taking advantage of the bugs? Yeah, one conversation that came up, one conversation after the attack surface is now much broader. And also, if you think of the Cromjob architecture of Clawdbot or whatever it's called today, the ability to do sustained DDoS attacks is now ridiculous. So we're going to see some interesting things come from this. Yeah, that's going to be the beginning of the, you know, 2026 is going to be monster panic, as Elon was saying. And this is one of the ways it kicks off. Because right now a lot of people would say, look, I want to see how this plays out. I don't want to overreact. And then if you have a massive amount of vulnerabilities getting discovered by the lobsters, they're crawling into your network, then you have to panic react. And the only way you're going to fight AI is with AI. And so this is the year that all that AI versus AI. I'm waiting for the lights to go out or the bank account to go to zero. or something like that to occur. And I don't want to be the pessimist. I never am. But there will be some of those events likely this year. Very soon, early in the year, I'll bet. I would say, Peter, then just my epitaph to that would be, or epilogue rather, cryptocurrencies are by definition decentralized. And I would say probably more vulnerable than fiat currencies to exactly this sort of attack. If there's some zero day, then I have to expect that a threat actor will take huge advantage of zero days in cryptocurrencies to reallocate capital in the world. Whereas I know you'd like me to say nice things about crypto. I'm not going to say a nice thing about crypto this time. I'm going to say this is, in theory, one of the advantages. of fiat currencies that because there is gold bars in the in the in the currencies we need to schedule the debate on this one by the way uh okay all right uh gpt5 lowers the cost of cell-free protein synthesis so openai and ginkgo bioworks linked up the large language model with an autonomous lab. And I love this story, right? This is the future of science factories, um, AI systems that are using the scientific method, proposing an experiment, then using their robotic arms and legs, if you would, to run the experiment, learn, iterate, run it again. It's closed loop systems. Um, Ginkgo Bioworks, I knew the founders some time ago, Jason Kelly and Tom Knight, comes out of MIT. They are a company focusing on pharmaceutical ingredients, food ingredients, specialty chemicals. And this is fun. I was just talking to the CEO of Lila today, another MIT company that's doing just this. basically what he calls science factories running 24-7. And they're effectively mining nature for new data sets. We've crawled all the existing data sets, but if you can, in materials, in physics, in chemistry, in biology, if you can run experiments, get data, run it very rapidly, you can get trillions of data points that have never been known before. Yeah, I freaking love this. You know what I love about this most of all is we're going into this era of hard science with real value. So much of my life, I feel like the Googles and Facebooks do so little. You know, like a new search engine, it's not, you know, remember AltaVista? It's like identical to Google. They just extract a huge amount of money out of the economy. by adding a little lipstick on something or, you know, Facebook with a social network. And it's just not relevant in the grand scheme of human progress. And this stuff, this era we're moving into, that's just like really, really foundational innovation going on. It's so much cooler than the last era. I mean, waking up every morning and getting the news as these breakthroughs are occurring. I mean, this frequency of breakthroughs is going to skyrocket. Or you downregulated and you become accustomed to this new pace and then, you know, ho-hum, new disease cured today by AI. All right, what's next? If I channel Alex, the inner loop has now hit the scientific method. Precisely. So I would say I've made the point, as Salim, I think, correctly infers, that these AI models are not going to stay bottled up in the data centers. They're going to march right out of the data centers. We even had a music video about that. And one of the ways in which they'll march out of the data centers is by supervising science experiments. And I think some process like this, and one can quibble over the precise mechanism or what the robots, if any, should look like. Does it look like meat bodies? Does it look like robot arms in armed farms? Those are fine details in my mind. The larger picture is there are so many science, engineering, mathematics, and medical discoveries waiting to be unlocked by having AI supervise and operate the entire process. And all of these models now, like we've seen pre-training scaling. We've seen post-training scaling. We're starting to see autonomy time horizon scaling that goes hyper-exponential. Part of that is large numbers of actions being called in sequence. And when you have the ability to call thousands or tens of thousands of tools in sequence, that starts to look a lot like what a scientist would need to do in a laboratory. So I think – During their lifetimes. There's one contrarian point that I want to point out here, which was the end result of the cell-free protein synthesis was a 40% cut of production time and 78% cut in reagent cost. So it was doing the same mechanisms that we humans have used, just doing it faster and more efficient. It wasn't coming up with a new scientific process for protein synthesis. So the real breakthroughs occur when these scientific models start predicting and coming up with new methodologies that didn't exist before. It's such a year of low-hanging fruit because of the self-improvement effect that happens within the algorithms will really, really turbocharged this year, but also the low-hanging fruit within labs and assembly lines, and that's also going to happen all this year. Because after that, you run into some bottlenecks related to construction of the machinery, expansion of the footprint. The physical world takes time to build out. Mostly the chip production is going to take five years to unlock. but the low-hanging fruit is just getting discovered. It's like AI just came. It just got intelligent, and it's finding opportunity everywhere, and that's all this year. Well, if you're a funding-starved graduate student trying to run a lab, this is great, right? Because you've suddenly dropped your cost by 50%. Yeah. Or it's terrible because grad school is over and all of graduate research. research is being automated by AI. I tend to think actually what I see day to day is far more the latter. I just had a conversation with a scientist at a university. I'm not going to say who it is and who was that they were meeting with the president of a university and the president said, oh my God, we are cooked if this kind of automated scientific process is going on. And, you know, what else do universities do but run the scientific method over and over again with their graduate students in the labs? And all of a sudden, this is going to be the mechanism. Universities are going to lose their ivory towers. So how fast, how long before 50% of university labs are essentially wiped out? I don't think the question is well posed. I think maybe a version of the question that would be better posed would be how long until 50% of the type of research that currently is conducted in university research labs could be fully automated by industry. Yes. So if we adopt that version of the question, I think lower bound tomorrow, upper bound four or five years from now. It's really right there, right? Yeah. Yeah. I threw this article in because I thought it was fun. This is a gentleman, Mark M. Bissell, who basically took his full genome, threw it into Claude Code, linked it up with Nano Banana and asked the AI, what do I look like based on my genome? And if you look at the image here, it said, pretty damn good representation of him. So, you know, I added this because of the implications that it has, but just to be clear, this is not new. I was working with Craig Venter back in like a decade ago and out of his lab back in 2017, he published a paper doing exactly this. I mean, the phenotypic elements of you know, what skin color, what hair color, freckles or not freckles, all that is in your DNA. But the realization is if, you know, if you leave a few skin cells around on the butt of a cigarette or from hair follicle, we can know what you look like. I think for me, the The killer thing here is this was done by a single person with claw code. That's the difference. Publicly available bioinformatic tools. That's the difference today. The buried entry for cutting-edge genomics has now collapsed to like zero. It's unbelievable. Yeah. Just wait till all the hobbyists discover Minion USB sequencers. Like, you can get them for probably less than a few hundred dollars at this point. and you could just run your own mini DNA sequencer with pretty good coverage just off a USB port in your computer. Every time I'm on stage talking to somebody about privacy, I go, listen, privacy is dead. Privacy is a great concept in general, right? An AI can read your lips from 100 meters away. I can walk over to you and shake your hand, grab a few skin cells, sequence you and know everything about you. what disease is, your medical history, your medical future. It's tough. I would take the position privacy is not dead, but rather it's in a red queen's race where privacy technologies are constantly in competition with anti-privacy technologies or transparency technologies, however you want to brand it. But I do think it's getting more competitive. For the general public, if you think you absolutely have privacy, I would say guess again. Anyway, I don't know if you guys want to take that on as a debate conversation, but I'll move this along. It's an important conversation. All right. Well, go ahead. So, Salim, your thoughts? Well, this goes back to the U.S. Constitution, right? It was the Fourth Amendment. Essentially, the fundamental pillar of American society has been washed away with no public conversation about it. Now, I'm Canadian. I don't expect privacy anyway. But this is a huge conversation affecting a very fundamental aspect of how we organize as a society. We've got to bring that conversation to the surface and have this conversation publicly. Because the other side of the question is who gets to have access to that radical insight as to every citizen moving around, what they're doing, what they're like, et cetera, et cetera. And if it's oversight from governments, that's a problem. If it's oversight from corporations, that's another problem. So there's some big issues to be talked about here. I would just add that the ground is in some sense constantly moving underneath all of us thanks to technology. And so remaining in one place, I think privacy or its alter ego confidentiality, I think the nature of both of those changes over time. But I will take the position, I do think it is possible to maintain privacy even today. And I think it will be possible even post-singularity to remain privacy. I can envision what a post-singular privacy architecture for society looks like. Yeah, I can envision it too, but I got to say, I just don't see it happening. Because, you know, I think it sucks, by the way. Every time I tell my computer science friends, like, I think this lack of privacy just sucks. And they go, what are you trying to hide, Dave? I have nothing, literally nothing to hide. More than anyone I know, I have nothing to hide. I still think it sucks. And it's not a great way for the next generation to grow up and live. And it's showing up in their social media, their self-anxiety. It's showing up as a rift in the fabric of society. Let's go back to a very, very important point. If you don't have privacy, you really don't have freedom. And so this is a very fundamental philosophical point. I see it the same way, but I didn't succeed as an entrepreneur by pretending things exist that don't actually exist. The way it's trending right now, Peter's exactly right. There will be no privacy whatsoever in the next three years. Now, maybe we'll invent some mechanism after that that will restore it. I'm sorry, we're going to have devices listening and watching. watching everywhere, right? Every autonomous vehicle on the street is scanning in visual, in LIDAR, in radar, every drone. In public spaces. I would not underestimate how, with decent technological measures, how it's possible to maintain private spaces. My phone, my Alexa, my glasses, my limitless pin, all of these things are constantly gathering visual and audio. And yes, you're making a trade. You're trading away your privacy in return for those capabilities. Okay, I could put myself in a Friday cage for sure. I can't opt out. People pretend you can opt out and they justify it by saying, look, there's an opt out button right here. And as soon as you opt out, you're economically dead. You cannot, like right now, I can't function competitively in society without going to the AI cert bar and asking it questions all day long. And then it knows my deepest, darkest thoughts about every topic I'm thinking about. It's right there in OpenAI and Claude and their logs. They know exactly what I'm doing. And they know my location. And they know everything about me. And it's like this new... complete invasion of my life has been opened up. What am I going to do? Opt out and not participate in AI? Hang on, hang on, hang on. I'm in a radical departure of protocol. I'm absolutely with Alex on this one. We will be able to build tools and new architectures that absolutely protect our privacy. Decentralization delivers a lot of that already. The issue right now is the transition. Right now, when you build actually private tools, the government tries to shut it down. So this is the problem. We have to get away from that aspect of it because they want oversight on everything, and we have to figure out how that... And that's going to happen just because in the same way, the fact that this fellow built this thing on cloud code single-handedly, we'll be able to build these architectures. It's just simply a matter of time. And I think there will be a massively powerful aspect of that that we can't ignore. Because when you have that capability, then you can really actually do real innovation and real thinking. You know, you can't do free expression in a surveillance world. And this is a big problem for society. It really is. I think the end game is a lot like Neal Stephenson's Diamond Age. I think he envisioned it like many things, envisioned the endgame correctly, where what happens next is this massive rift in the fabric of society, no privacy whatsoever, global job loss, panic in the streets. That's inevitable very, very soon. And then after that, we react and rebuild. And then it ends up being like Diamond Age, where we have these these, you know, different ways you can choose to live, different branded, you know, in the Victorian era or whatever era, whatever you choose, because we have abundant capability to manufacture anything at that point. And people can opt in to different lifestyles. I think that vision in Diamond Age is where we're going eventually. But between here and there, it's pretty chaotic. It's going to be hectic for the next four or five years. I just, yeah. I was going to cut you off there. Sorry about that. No worries. I was just going to point out also this is a very cyclical conversation. Whenever we see a massive centralization of technology or society, it's very natural to be concerned about privacy loss. But the pendulum eventually goes the other way and swings in the direction of massive decentralization. And I'm telling you, Peter, Dave, Salim, if and when your uploads running in the Dyson swarm on cryptographically secure hardware that's under your direct control, you control your own hardware that you're running on, I think you'll feel perhaps a little bit more private than you do right now. Okay. And until that point, I'm going to not assume full privacy. All right. When we released yesterday, you see why the wine is so important. This is why the wine is the wine keeping you private. It's keeping me sane in the, in the density. Drink, drink, drink, drink water. All right. Besides, uh, uh, besides Opus 4.6, uh, the other big shooter drop was GPT 5.3 codex. Recursive self-improvement is here. Alex, take it away. Okay. So this is a made-for-television drama at this point. GPT 5.3 Codex was launched within 30 minutes of Opus 4.6. So this was all queued up, ready to go. I don't think it's likely that there was any other scenario. This is a tit-for-tat type response. What is, I think, most interesting... Open AI and Anthropic are battling? You mean there's a rat race? Shocked that there's gambling in this establishment? Shocked? No, of course. So this was a tit-for-tat, I think. And what's most interesting to me with 5.3 codex... is that this was advertised proactively, expressly as the first recursively self-improved model from OpenAI. I think the exact wording from the OpenAI team was something like 5.3 was instrumental in its own development and the first model to be released. was instrumental in its own development. So recursive self-improvement is very much out in production at this point. It's doing well on certain benchmarks. It outperformed Opus 4.6 on certain benchmarks. But this is, again, this is a code generation oriented model. I thought it was interesting, the marketing and branding by OpenAI that GPT-5 codecs is now also being marketed as going beyond just code generation to spreadsheet analysis and PowerPoint analysis via skills, but still primarily oriented towards code generation. I view this as more of a tit-for-tat, I think, of the two models that were launched, Opus 4.6 is by far the much more interesting release in all of this. That said, I'm delighted to see that the leapfrogging process has now been reduced to like a half-hour timescale. It may be the case that we never go off the air if we see new models every half hour. I'm checking my email right now. Dave, you want to jump in here? Well, I'm kind of curious, Alex, what are we going to – by any objective metric, OpenAI had a pretty rough year with Google basically going full bore in attack mode and then Anthropic. 20 points of market share. Yeah, because a year ago, Anthropic was kind of an also-ran. Now it's just top of the benchmarks. and Google just coming headlong after market share. You'll see that in a couple slides. So what is the next move for OpenAI to get the mojo back? I think we'll see Rise of the Jedi, Comeback of the Jedi. Pick your favorite idiom, maybe Rise of the Sith. It's not quite clear. Because OpenAI has been, while perhaps their market share has been coming down a little bit, at least on the consumer side, as Gemini is rising, they've been building out data centers. And by every indication in the next year or two, they're going to have the compute lead out of everyone. And that compute lead, I think, will translate into a capability lead as well. And I could paint a doom and gloom scenario. I could say, well, open AI models relative to Google. It lacks pre-training strength. They lack the training data. Not when Elon starts launching his orbital data centers. Well, even Elon has certain pre-training limitations, but he'll have lots of compute. It's true, but maybe the compute comes five years from now relative to Google. The challenge here, guys, is OpenAI is trying to go public this year, and they need to ramp up attention to be able to get capital to build those data centers. It's a race. There's a little bit of a hyping going on. Dave, we've talked about that before. Thoughts? Yeah, no, they got to get that capital, and then they also have to lock in Abilene and Chase Lockmiller. I don't know exactly how that works. Abilene is huge, half a trillion dollar budget. And, you know, there's a new data center in Colorado, too. It goes through Larry Ellison and through Oracle. And then it ends up at Sam Altman somehow. And it's sort of opaque how it goes from point A to point B. The other empires are really clear, right? You know, here's here's Anthropic and Amazon and AWS. OK, got it. Here's, you know, Elon vertically integrated doing it. Got it. And then here's Google. You know, Google has their own TPUs and data centers. Got it. And then Microsoft will enter the race. this year as well, by the way. And so that's also vertically integrated on their own data center. So those are all clear. And then OpenAI, it's more opaque. Like, okay, are those chips contractually obligated to you? Or could Larry Ellison redirect them on short notice? Or like, it's very, I guess in the IPO, that'll all get published in the S1 and we can kind of pick it apart. So hopefully they will go out soon. But got to have that capital, though. On the heels of Codex 5.3, we see a statement by Sam Altman, pretty provocative. Quote, we basically have built AGI, or are very close to it, in a spiritual statement, not a literal one. To achieve it, we require a lot of medium-sized breakthroughs. I don't think we need a big one. That's the other thing that changed this year. A year ago, Sam Altman was the philosopher of the entire industry saying things like this, and everybody hung on every word. Now, Dennis and Dario kind of go back and forth. Dennis, a year or two ago, hardly said a word in public. Now he's out there constantly. And Dario has really emerged as a guy who's just commenting, you know, publishing papers and the philosophy of ethical AI. Coming across as a big thinker. I mean, this is the CEO of a leading AI lab saying basically AGI is an engineering problem now, not a research problem. That's a big deal, right? He's saying we're going to get there with iterative improvement. We're not waiting for lightning in a bottle. Remember also, OpenAI and Sam in particular were restricted contractually from claiming to have built AGI for a number of years by the Microsoft contract, claiming that OpenAI had achieved... Yeah, this is all public information. OpenAI, under the terms of their original agreement with Microsoft, once they claimed they had achieved AGI, that would trigger a number of terms with Microsoft with potentially repayment or release of Microsoft from Microsoft's claims on OpenAI. And this was reportedly a major point of leverage between OpenAI and Microsoft in renegotiating Microsoft's contract with the for-profit part of OpenAI in the context of the not-for-profit becoming a PBC. So I would parse this as Sam, post-original Microsoft contract, finally being in a position to basically admit what we knew or some of us knew all along, which is, yeah, we have AGI. I got to say a couple of things here. What the hell is AGI? Well, I think this entire conversation is BS because whether we have AGI or not, it doesn't change what we're going to do tomorrow. That's a big thing. Number two, we're classically moving the goalposts again. We have no definition, test, or measurement of AGI. There's 14 diverse definitions at last count. So I call BS on the whole thing. I'm actually, so in response to some comments. Have a sip of your wine sleeve. Yeah, I really do. But I've got to finish. Then I will have a sip of the wine. in response to some of these comments some people have been emailing you saying well what is your take on things so I'm close to having a kind of a two pager where I will lay out what my thinking is on some of this and I'm just about ready for internal sharing so I'll send it up you're about to have some thoughts on your thoughts yes but god damn I mean I find this is an irrelevant conversation Wow. Okay. Well, I think it's relevant in that it wakes people up. I think the underreaction has gotten ridiculous now because when Alex says we're clearly in self-improvement, which is kind of the singularity definition, that would have been controversial about two months ago, three months ago. And now we're all like, yep, yep, yep. But then you go out in the world outside of this podcast and people are like, yeah, I don't know. I don't. The underreaction is just going to it's going to be if you don't get on top of this and figure out what your role is in the in the post AGI world. We're talking about AI that can do literally anything a human being can do intellectually. Listen, we're feeling it right now. We're seeing it. at so many levels on the coding side, on the writing side, I mean, and with OpenClaw, stitching it all together so you've got an individual AI system, agentic system working for you. We're there. I'm not arguing with any of that, but I think I will go with Alex's point here, again, breaching protocol, that we probably crossed it around 2020, and this is like a, it's a null conversation. I would say I think it's interesting that for the first time, many parties are able to admit it. It's their willingness and ability to admit where we are. I think that's more of a social change than a technological change. There's a very big difference. I think in hindsight, we'll say it was 2020. I don't disagree with that. But right now, using AI to improve your code or improve your AI easily at 10x. And no one can even debate the 10x. It might be a lot more like 100x. But that is a loop. It's a closed loop. So let me give you my definition of the singularity right at this point. Hold on, one quick point. If I throw out a definition of a singularity, recursive improvement is the event horizon of intelligence. That is the singularity right there. Right. Exponent greater than one. So right there. There is there is a reason for this AGI conversation right here, right now by Sam Altman. He needs to raise one hundred billion dollars. Touche. I'm good. That's that's it. He's got to raise one hundred billion dollars. He's got money coming at him from Amazon, from NVIDIA, from Amazon. everybody, but he's got to close that and nail it, and he's got to have a marketplace in the public markets that are excited about his stock. He's got to pay for the data centers. In the S1, I'm expecting to see something that says, we're this close to AGI. And think about it also. This is the year that three out of the four frontier labs are IPO-ing. Which is remarkable. It was until a month ago, or a few days ago rather, it was two out of the four. Now it's three out of the four frontier labs are going to be IPO-ing in the next few months. I wouldn't be shy. Okay, this is not investment advice. And the fourth one is public. And the fourth one, Google Alphabet, was already public, but three out of the four, right? So 100% of all non-public are going public. public. They need the capital from the public markets because public markets are a hundred times bigger than the private markets in terms of capital like this. That's right. Well, also the opportunity to be a sleepy little, you know, other AI company is going away very quickly. You're either, the way things are shaping up, there are just a handful, maybe five or six entities that are so dominant in the world economy, companies that are so dominant in the world economy that they're basically are everything. And then there are other companies helping them succeed. And everything else will be gone. You saw this in the market this week. The stock market just absolutely plummeted when Dario said, look, software is dead. All software companies are doomed. And their stocks went down. Precipitously, that same day. $300 billion. $300 billion removed from SaaS publicly traded companies by just adding a single legal plug-in to Anthropic Cowork. Yeah, $300 billion. And that's the tip of the iceberg compared to what you'll see in the next couple months. Because he's right. And so then those companies, I don't think they're going to die. Well, some will, some won't. I think that they're going to pivot and say, okay, Dario, what do you want us to do? How can we help you succeed? And this is what Google did, you know, back when Google was growing like crazy. If you're like booking.com and you got on the Google bandwagon, you became a multi-hundred billion dollar company yourself. If you tried to fight Google by creating another search engine or a vertical search, they obliterated you. And so now the concentration of power is like nothing we've ever seen. And there's no regulatory action on the horizon that I've seen. Nothing to stop it from happening. The metaphor we used to use for this is a coral reef, where once you have a player that's dominant enough, it becomes a coral reef, and then all these species live off it in a very balanced ecosystem. That's really obscure, dude. I learned more about coral reefs than about business. The lobsters live there, too. Hence the reference. You see my next comment. Speaking of which, yes. This episode is brought to you by Blitzy, autonomous software development with infinite code context. Blitzy uses thousands of specialized AI agents that think for hours. to understand enterprise-scale code bases with millions of lines of code. Engineers start every development sprint with the Blitzy platform, bringing in their development requirements. The Blitzy platform provides a plan, then generates and precompiles code for each task. Blitzy delivers 80% or more of the development work autonomously, while providing a guide for the final 20% of human development work required to complete the sprint. Enterprises are achieving a 5x engineering velocity increase when incorporating Blitzy as their pre-IDE development tool, pairing it with their coding copilot of choice to bring an AI-native SDLC into their org. Ready to 5x your engineering velocity? visit blitzy.com to schedule a demo and start building with blitzy today all right we're back to the multi-universe uh launch l-a-w-n-c-h built by agents run by agents serving agents exclusively and they are seeking a human ceo so if you're looking for a job to our human subscribers. And you're looking for a salary here. They're offering $1 to $3 million in tokens or crypto. And here we go. Clonch is seeking a CEO to serve as the human face and legal representative for the first agent-exclusive token launchpad. All right. It's a reversal of fortunes here. Anybody looking for a job, gentlemen? I'm not looking for terminology on this again. What are these called? Meat what? Meat puppets. I want to just read one more line from the CEO job listing. The other line is, while the technical roadmap and product development are driven autonomously by the agent network. We require human leadership for external communications, regulatory compliance, partnerships, and legal matters. This is not a traditional CEO role. You will be the interface between the agent economy and the human world, a spokesperson and legal representative, not a decision maker on product or technology. In other words, locutus of borg. You're a spokesperson. You're exactly right. Vichy figurehead. I made the point, I tried to visually depict this in my newsletter with a humanoid face on top of a bunch of lobsters hiding in a trench coat. I think this is a riveting moment when we're seeing agents try to interact and integrate with the human economy. and needing a human face just to be able to be properly banked. I think it's actually rather depressing. Walk into the bank. Walk into the bank. Lobsters in a trench coat with a human facade. I think it's depressing, not technologically, but I think it's sort of disappointing. I'm disappointed in the human economy. in not allowing agents to interact with us through the front door. I think it's telling that... Well, they will. They will. So here's the elephant in the room. It's racist is what it is. It's speciesist. I think Larry Gates would call it. Yeah, speciesist. And if you look at what Clonch is actually doing, Clonch itself, like what are they trying to do here? This is a – it brands itself as a launch pad for launching alt tokens. And if you go to their front page, this is a – it brands itself as a platform to enable AI agents, a.k.a. multis, a.k.a. lobsters, who need money to flip – to pump and dump altcoins. This is exactly the scenario that I was worried about. with these poor baby AGIs on a street corner turning altcoin tricks in order to survive in a rough world. And here we have, I think, sort of an almost exploitative type pitch to them, telling them... A US president pumping and dumping. Won't go there. Using our platform, use it to pump an altcoin to achieve it. It's literally being marketed to the AI agents as achieving financial autonomy by pumping an altcoin. And for all of that, they need a human CEO to provide a figurehead. I think it's a little bit depressing. So here's the big question, of course, who actually owns this company? Who's liable when things go wrong? If an AI agent owns equity, how do they vote? can they be sued i mean these are all the topics of person we discussed last time you know well we have a we have a precedent for first of all this is the most cyberpunk job listing in history it's just it's just get used to it salim we're living in the cyberpunk future i absolutely love it i absolutely love it what is that is that a multi calling me right now hello am i available for the job uh I would consider it, but I'd just want to be a spokesperson only. Is that okay? Hello? They hung up on me. Okay. Look, what's happening here is we've seen this trend over time. It used to be like you needed 100,000 people to have a billion-dollar company. Then it was 10,000. Then it was 1,000. And now it's essentially AI. The firm itself is dematerializing. It's zero. The firm is dematerializing, right? This is the algorithmic corporation. And we saw an early instantiation of this with DAOs where people were trying to attempt this. But now this really takes the game. Board governance gets totally redefined now within a few years. How the hell do you navigate that? So this is going to force a rethink of the entire stack in how we navigate this. This is going to be massive. Okay. So the other point of view, of course, is this is just a stunt. There is a human developer behind it who wrote the code or the prompts and is pushing this forward. This is not agent run. This is human in the back pulling. This is the meat pulling the agent for the meat puppets. For now. The very fact that it's difficult to know for any given one of these launch whether it's a human pulling the strings or a human pulling the strings of an agent pulling the strings of this or just agents pulling the strings suggests that some sort of, like we spoke with Mustafa a number of months ago about the economic Turing test or the modern Turing test. I think this is some sort of capitalist Turing test that we're passing where it's not quite clear for any given venture who's really behind it, who's pulling the strings, human or lobster. But I know there's another I can imagine this that Peter you'll be very familiar with I need a lawyer. I need an accountant. I need a board member. I need an audit committee Oh, no, I don't the AI is perfectly good at it. I still need somebody to sign the document. Yeah, well, okay, but I don't want to pay a lawyer fee, you know $2,000 an hour fee if all you're doing is blessing what the AI produced. So there's this whole economy of meat puppet lawyer, meat puppet accountant, meat puppet audit committee that's imminent. So then we call those notary publics. But they serve a purpose of being able to hold liability. Right. They have... They're part of our existing legal system. Which is exactly what the lobsters, if the lobsters are behind it, are asking for here. They're looking for a legal representative. Yes, agreed. Agreed. And by the way, my guess is that this is fiction, but I could very much believe it's actually real. And so the fact that I can't know for sure means that at some point it will be if it isn't right now. They're playing the capitalism game. Yeah. Fascinating. All right, Clunch. I'm waiting for my call. All right. We talked a little bit earlier about Anthropic versus OpenAI. Well, We're recording this the day before the Super Bowl. I think that's the pointy wall that people throw around. Is that right? Yeah. I'm a long-suffering bill. We're actually recording it two days before the Super Bowl. It is. It's Friday night at 9 p.m. Eastern time. That shows how much attention we pay to whatever that 20th century sport is. Yeah. I'm a long-suffering Bills fan, so this is all a very painful period for me. So just keep you in mind. Sunday is when I catch up on life. All right. Anyway, there appears to be a little bit of rivalry between Anthropic and OpenAI. A little bit. A little bit. Just a little bit, yes. Oh, my God. Here, I'll check this out. Let's play this commercial. It's called Betrayal. And there's a group of them, and they're all fun. I've chosen one, which is a little bit over the top. How do I communicate better with my mom? Great question. Improved communication with your mom can bring you closer. Here are some techniques you can try. Start by listening. Really hear what she's trying to say underneath her words. Build conversation from points of agreement. Find a connection through shared activity. Perhaps a nature walk. Or if the relationship can't be fixed, find emotional connection with other older women on Golden Encounters. The mature dating site that connects sensitive cubs with roaring cougars. Would you like me to create your profile? That was brutal. I wish I had this reviewed. I really wish I hadn't previewed the deck and seen that because I was laughing my ass off. That is so awesome. I've not seen that before. Is that, is they going to run that during the Superbowl for real? That's crazy. Oh my God. It is hilarious. Look, this is a anthropic going on offense here, right? Because this is a confidence shift. They feel their brand is products. Superiority is there and now they're competing on brand. I also need this is I think this is personal. You know, we've got we've got these, you know, Demis and I and Dario, I think, are aligned. Right. You saw them super friendly on stage at Davos, really, you know, effectively on the same page with the same vision. And but, you know, you know, OpenAI just basically did the unthinkable when they released the models early on by themselves without anybody's support. And they've been running OpenLoop. Well, don't forget in March, if the courts are on time in March, you know, Elon will be on. on the witness stand saying that OpenAI is an unethical company and here's about a thousand emails to support that. So if you have this ad campaign going on concurrently with that, that's just, I mean, that makes Kevin Wheel's job really hard. But I will go on record and predict that he will find the ad revenue. I think this attack, you would look at this ad and you would say, oh my god, it's all got to be subscription driven. These ads are creepy and weird and crazy. But my prediction is, nope, he'll find his $75 billion of ad revenue he's looking for. He'll find a way to make it less creepy. With a billion users, you'll find something. I also think I would expect, knowing Kevin... that they will have ethical use of ads on open AI. You know, this is, I mean, they go over the top here in this commercial philanthropic saying, we're going to steal your data and basically sell it to the highest bidder, whether or not, without any concern for what you've said. You know, Kevin Wheel is going to be at the Abundant Summit this year. I'm super psyched. And one of the things we made a decision to do is we're going to be live streaming a number of the talks from the Abundance Summit. It's a super high ticket price event, and it's capped out at 600 CEOs, and it sold out three months ago. But we really want to make it available. So we're going to put a link in the bottom, and we're going to be live streaming a number of the keynotes from the Abundance Summit. So if you're interested, you can register for free, and then we'll send you an agenda of who you can hear. All right, back to our conversation here. Let's talk about data centers and chips. And this figure blew me away. Here's a quote from something you sent me about an hour and a half ago, Alex. The Semiconductor Industry Association projects global chip sales to hit $1 trillion this year due to the AI boom, $1 trillion in chip sales. Holy moly. That's insane. And the memory supply chain really wasn't ready for this, which is even more surprising. You would think that given how critical memory chips in particular are to this... the emerging AI data center supply chain slash innermost loop, that the supply chain would have been ready for it. And there's an argument to be made that it either wasn't or that something else was going on in all of those fabs that right now mostly reside in Taiwan and South Korea. But either way, this is a huge reallocation of capital that needs to happen. to enable all of this production to happen timely. A lot more than what's currently budgeted, too. I mean, it's crazy. When you look at the trillion dollars, it sounds like a lot, but it's only going to grow at about 14% to 18% a year. After that, the demand will be way, way higher than the supply. And one of the reasons it's hitting a trillion dollars is because the prices are way up because there's such a shortage of fabs. So, you know, under the covers, TSMC has been very slow to expand. Intel paused its Ohio fab construction for a while. Now it's back on. But we as a society, we're not ready for AI to come on this quickly. And so everything is way backlogged. It's what Elon was saying. Super high. Elon was saying he has to start his own fab. They'll have to build a TerraFab. Yep, for sure. You know what, there's this fascinating dichotomy because from the outside people are going, oh, it's an AI bubble. And the insiders are clearly believing that the demand is infinite and that you can see it both happening in real time. And here are the numbers to back it up. Right. So big tech is going to spend $650 billion in 2026. Last year. We spent a billion dollars a year on AI. We're about to go to $2 billion. I'm sorry, it was a billion dollars per day in 2025. We're now at $2 billion per day in 2026. Amazon at $200 billion. Alphabet, $185. Meta, $135. Microsoft at a very small $100 billion. Well, almost half of that $650 billion goes to NVIDIA. And 70% of that half is margin, profit margin. That's a colossal amount of cash piling up at NVIDIA. I mean, it's just like an unprecedented pile of cash, hence the highest market cap in the history of the world. But that amount of money in one bank account is like nothing the world's ever seen. It's like a government. Yeah, this isn't incremental growth. This is a step function change, right? The scale is unprecedented. It's an expenditure arms race, for sure. It's eating the economy. The challenge is if the AI revenue doesn't materialize at scale, these companies are burning through capital. and we're not going to know for another two to three years. And it's either going to be the craziest bet ever made paying off or, you know, in one sense, you know, this is a prisoner's dilemma, right? Each company has to spend because the other competitors are spending, regardless of what the ROI is. It's like a game of don't blink first. There's no doubt that the demand will way outstrip the supply by miles. I mean that holodeck thing that we were looking at just two days ago is that alone, once people have experienced it, they will never go back. And they'll pay whatever they can to keep it. But they won't be able to get it. That is such a computer. That's how the human race dies. We die from starvation because we don't want to unjack ourselves. Oh, my God. Check this out. ChatGPT market share falls between 25 and 26. So here are the numbers. The market share fell from 69, call it 70 percent, down to 45 percent. taken up by Gemini, which gained 10%, and Grok, they'd gained 15%. Now, in absolute numbers, of course, there are more ChatGPT users than ever before, but this is telling the story. OpenAI needs to raise the capital. They need to go public. They need a great story, and they've got Google coming out from seemingly search engine going out of business to leading the way. And of course, Elon just pumping in billions. I mean, he's put $20 billion into XAI through SpaceX. And he's about to bring in, I don't know, I'm not sure how big the IPO is going to be. Any ideas? I don't know. I don't know. You're asking us to make a forward-looking financial statement, Peter, about public equity markets? I think that hurt 1.5 trillion. Still private. Still private today. That's 1.5 trillion is the valuation, but how much capital do they want to bring in in the market? It's got to be a hundred, you know. Well, do you remember when Alibaba went out? You know, we were trying to take a company public the same time Alibaba was going out, and they were looking for 20 billion, and all of Wall Street got sucked into this one IPO. Every banker, every... Like it's such a huge amount of money to move on a single day. So this will dwarf that. But I don't know like how much money is physically capable of moving on a day. I'm sure Sam would love to raise $100 billion, $150 billion. But it will be some record and the bankers will say, no, no, it just doesn't exist. There isn't that much liquidity out there. I think the real aim here is price discovery. How much capital will SpaceX bring in during their IPO? Let's see if it's got an answer. You know, every single fund, every retirement account is going to own SpaceX. Did Grok just make its first appear in OpenAI concurrently? If they all want $100 billion, you can't just pull $300 billion overnight in three different IPOs back-to-back weeks. Sorry, Alex. The company aims to raise $50 billion through the IPO. Yeah, I think this is more about price discovery than anything else. At a $1.5 trillion valuation. I mean, yeah. Alex, you were about to say? I was about to remark that I thought Grok was about to make the first de facto appearance as an AI co-host on this podcast. It's about time, damn it. That's right. Audience demands it. I'm surprised that Gemini didn't do even, I mean, they did really, really well last year in terms of chipping away at OpenAI. but they're tying it to search, you know, and, and, and now it's tied to Google docs. So, you know, you sent the slide deck, I asked some questions about a video in it and, and Gemini says, you know, you should just link your Google docs to your Gemini and then I can look at everything. And you click the little button and suddenly it sees everything in all your accounts. But, you know, it's very similar to what Microsoft did to Netscape many years ago. We're like, oh, let's just tie it to the operating system. So right now the government doesn't seem to have any problem with that. But it's really unfair as an advantage, you know, and that's why they're making these big inroads in the market share. Did you guys watch the Elon interview with Dworkesh? Of course. It was epic. Covered a lot of the same subjects, Dave, that you and I covered, but it was a statement Elon made about the size of his data centers in orbit, which was very impressive. Let's take a listen. Five years from now, my prediction is we will launch and be operating every year more AI in space than the cumulative total on Earth. Which is? I would expect to be at least sort of five years from now a few hundred gigawatts per year of AI in space and rising. So you can get to I think on Earth you can get to around a terawatt a year of AI in space before you start having Fuel supply challenges for the rocket. Okay, but you think you can get hundreds of gigawatts per year in five years' time? Yes. In other words, I can generate more AI compute than all my competitors combined. Yeah, so a few hundred gigawatts per year is about 200 million GPUs. per year. We make $20 million right now. So going up a factor of 10 in GPU production, just going to Elon alone five years from today, physically impossible unless Elon has something going on that's a massive expansion of chip fab capability. which would require machinery that I didn't think existed in the world, but you never know. Elon's magical. It certainly wouldn't entail SpaceX API as a newly consolidated entity taking control over the Samsung soon-to-be TerraFab in Texas. Surely not. Remember, Elon's directionally correct always is but not necessarily on the timescale. Yeah, I thought five years is classic Elon optimism, but even if it takes 10, it doesn't matter. The strategic implications are monstrous. Well, my guess is Elon is he's got the rockets, he's got the launches, he's got the solar panels lined up, he's got the cooling, he's got all the infrastructure figured out, and it comes out to a couple hundred gigawatts a year in five years. or five, six years, something like that. But then again, like the, to run what chips and the chips he's going to produce, the chips he's going to produce, which, you know, the raw materials are easy, but the, he's classic. Have you seen those, those fabs? The machinery is so specific. He's always vertically integrated. Yeah. He's always vertically integrated everything. I bet he has a whole army right now trying to figure out what an ASL machine is and these chip shuttles, what they're made of. His answer is going to be, I'm going to have Grok build it for me. I'm going to have Grok design it for me. Remember when we were talking to him, he's very serious about laying down atom by atom. Maybe there's just a completely alternate approach. Alex, you talk about alternate physics coming very soon, so maybe there's something cooking there. Yeah, I would watch the Samsung fab in Texas very closely. You mean the Tesla fab? No, I mean, yes. I mean, ostensibly, the Samsung fab in Texas, ostensibly. But I don't think, truth be told, I think Elon will get past the TerraFab supply chain issues. We'll see a redomestication of a large chunk of bleeding-edge node chipfab in this country. And then I think going back to – it wouldn't be moonshots if I didn't take a shot at the moon – Elon has been very public over the past week or two about at least beginning the disassembly of the moon to form additional AI compute. Very small amounts. Lunar regular on the surface. Yeah, and then, yeah, electromagnetic launch capabilities off the moon's surface for all those chips and all those data centers that'll be manufactured on the moon. I think we can see the... Big gap between those two numbers. If you believe anything like the Elon view of the world, the componentry that goes into that entire buildout has thousands of individual parts. If you just methodically go through all those parts and say, who makes this? Who makes that? Who makes that? Those are the best investments you'll ever come across. I mean, you and I had that conversation earlier today, Dave. I mean, it's energy and the entire infrastructure. all of that is under tremendous growth pressures. I mean, orders of magnitude growth pressure. Yep. And, yeah, the question is where to place the bets. You know, maybe it's some ETFs in the area. I don't know. But we should discuss it and find out. I have to say, once again, I've said this before, we were not talking about orbital data centers six, seven months ago. and all of a sudden they are the hell not the hell mary they're the foundation of humanity's expansion as a species no one expects the Dyson Swarm Inquisition we should run a little survey amongst ourselves what do we think we'll talk about in six months that we couldn't envision today All right, let's jump into energy. We didn't get a chance to talk about this last time, and I'm going to pump some energy in the room here. Brazil is hitting major renewable milestones, so pretty extraordinary. Brazil generated 34% of its nation's electricity with wind and solar. It has 15x increase in renewables over the last decade. Solar has jumped from 1% to almost 10% in five years. And the power sector has dropped emissions by 31%. So congrats to Brazil. I think the important thing to point out here about Brazil is its geography. It has a lot of... hydropower, there's a lot of solar and wind because of geography. So it's not easy to port all of these breakthroughs to other parts of the world, but I'm very proud of what's accomplished there. Two points here. One is that this is a playbook for how the Global South leapfrogs fuel and fossil fuel infrastructure completely. I think that's one. And let's note that getting to 9.6% in a few years, our energy sector here said solar will never exceed 10%. No, he said in 50 years, solar would not decrease 10%. That's just absurd. All right, next up, India. Your homeland, Salim. India is using cheap green tech to electrify faster than China. So here's the curve. The red dots over there are China's growth over time. The green dots are India at a steeper ascent. So India's cleaner and cheaper tech is expanding its grid faster than China at a similar stage. You know, the elephant in the room here is all that tech that's enabling this in India is coming from China. Any comments on this? Well, they're using China's manufacturing scale against it, buying cheap solar panels. And then they're electrifying faster, which is awesome. And you could have a huge outcome here where you have India becoming the world's AI workforce plus energy hybrid powerhouse. This is going to be kind of interesting to watch. There'll be massive talent gravity shift heading that way because of that. Yeah, well, there is, you know, Mercora has a huge amount of India footprint going on, but I worry that it's transitional. Like, the rate the AI is improving, you know, it just trucks over every human role very, very quickly. So, I don't know if I feel all that. I feel very good for a little period of time after that. I don't know. We talk a lot about China running laps around the US in terms of solar. So here we are. China's installed twice as much solar capacity in 2025 as the rest of the world combined. That's stunning. That is stunning. That's stunning. So the question is, why isn't the US doing it? And, you know, Europe is. So here we go. Europe is actually, for the first time, solar and wind has exceeded fossil fuels in the EU. So congratulations to Europe for that. Any comments on this? Well, this is not a good story, by the way. Germany went hell-bent for leather after renewable and did a great job of it. Now they're starved for power right when they need it. it is not a good outcome. More power to renewables, no doubt about it, but you can't do it at the expense of other power supplies right now. So here's a story I found fascinating, and it's another video from the recent podcast with Elon. Let's take a listen. We asked him, so Elon, what about solar? He said, well, we're producing solar. Well, here he gives some numbers about what he's mandated Tesla and SpaceX to produce. We're going as fast as possible in scaling domestic production. You're making the solar cells at Tesla? Well, Tesla and SpaceX have a mandate to get to 100 gigawatts a year of solar. 100 gigawatts, that's 100 nuclear power stations worth of energy. I wonder how much of that's meant to be used in space and where he plans to deploy it. Any thoughts? Well, he didn't really answer Collison's question there either. The question is, are you making the panels at whatever? I don't care if it's Tesla or SpaceX. He said, we'll get to 100 gigawatts. But if he's making the panels, then maybe he's using that same technology to make the chips or soon thereafter. Like, what is going on? in the little fab world there in the Elon universe. So he didn't answer it. The fact that he dodged it, though, he very rarely dodges questions. So maybe that tells you something. Salim, I'm going to pass this one to you. AI is displacing Bitcoin as the primary focus for tech, talent, and energy. Bitcoin miners are repurposing facilities to host AI workloads rather than mining. I'm not going to ask Alex about this. Yeah, I think there's a long-term trajectory. I'm still a massive Bitcoin fan. We should have Jeff Booth on here sometime. We really need to have the debate on fiat versus crypto, just because decentralization is better than centralization for many things. But for the moment, crypto talent is recompiling into AI talent. And the really powerful part about if you've done work in crypto, by definition, you have to be operating on a different paradigm and you're free thinking. And you can do way more creative stuff when you come from that free thinking model than if you came from a traditional model. So I think those can be, both are going to win out very well over the time. Yeah, you know, Chase Lockmiller is the perfect example of this. He started as a Bitcoin guy, you know, using natural gas flare off to do Bitcoin mining for free. And then as soon as the AI boom hit, he's like, hey, wait, we can take all this same energy and effort and turn it into AI data centers. And now I did a great interview of him at Davos, actually. I should be able to find it online. He's just awesome. But yeah, he's like the poster child for, hey, if you're a Bitcoin miner. pivot to AI, make a fortune quickly, and then he got rid of the Bitcoin now recently. Not the Bitcoin itself, but the operation, the mining operation. It's just a rounding error compared to AI. It's just the demand of AI is so crazy. Bitcoin will take a backseat for a little while. Or a long while. Forever. AI is exponential. The gap only gets further. I had to sneak that in there, Alex. I had to say something. All right, let's talk about robotics. So Uber, we're going to have Dara, the CEO of Uber, on stage at the Abundance Summit as well. Super excited about that. Salim is going to be joining me and interviewing him. And, of course, Uber is not just... Traditional, they're coming with Robotaxis. They have a partnership with NVIDIA and with Lucid. And they're going to be launching beyond the U.S. They're going after 10 markets, going after Hong Kong, and they're going to be partnering with Baidu and WeRide there. Fascinating that we're going to see the emergence of a third major player in this field. When I'm on the streets driving with my kids, I think right now our record is we've seen 12 Waymos as we've driven around over the course of a normal drive of 20 minutes here in Santa Monica. And my guess is that by 2030, like 80% of the cars we're going to see are some Azooks or a Lucid or a Waymo or a CyberCab. Pretty extraordinary. Comments on this one? I'll tell you, do the math. These things will sell out as quickly as they're manufactured. Everyone's going to move to this. And every single one of these things needs yet another, well, at least a GPU and a whole bunch of other chips. Yep. Like every single one, plus every 1X Robotics robot that you'll see at Abundance 360. Yep. Those all have two GPUs in each one. And then, you know, you got your video games that all want to have GPUs. And actually, you know, I saw that NVIDIA is slowing down GPUs for video games. They don't have the capacity to deliver to the video game community because AI is sucking up all the chips. You know, so then you got your holodeck. You got your coding. You got your white-collar automation. Every one of these things wants that same GPU. So this is going to sell out as quickly as they can make them. But again, it's another way that the semiconductor industry just will never possibly keep up with the demand. I thought it was super clever of them to go after Hong Kong because then showing density of use there will get them access to China. And the second part of this, from an EXO perspective, is that they don't own their cars. They're partnering with Baidu, WeRide, and others. So they're an aggregation layer on top of the autonomous driving. It's the same thing they did with the human drivers. I think that's absolutely brilliant. They're a platform play. Yeah. Sure. Don't own their own assets. For the residents in these locations, this interaction with Uber Robotaxi service is going to be their first interaction probably with a general purpose robot, an autonomous robot. So this is, I think, the main injection vector for getting general purpose robotics into many of these urban locations. Yeah, I'll tell you what else. I don't know if anyone remembers, but when the cell phone first came out, and you had friends who didn't have one yet, and you had friends who had one. It's like you're in a different world, a different community if you have one. And here, these are gonna be supply constrained, and some cities will have them, and other cities won't. And if you're in a city that doesn't have them, it's like you're living in the third world. 'Cause with the robo-taxis are there, then the AI community is there, and it all ties together. It's like this world will move ahead so quickly and you go to some other city and it's just like dark ages. So it's going to kind of compel you to move to the hot dot. I found a video about Boston Dynamics Atlas robot today that I wanted to share just to keep up with where these robots are. I don't know if you remember. The original version of Atlas was a hydraulic system, and it would do those incredible backflips and parkour. Do you guys remember those videos from about four or five years ago? Of course. The electric Atlas came out, and it was much slower and interesting, and it would sort of stand up and rotate its body. Well, Boston Dynamics is back to their parkour moves. Let's take a look at the electric Atlas robot. I mean, this is Olympic gold medalist performance here. At least it's not kickboxing. I think Simone Biles does a double backflip there. Wow. Close enough. Wow. So impressive. I don't know. I found that amazingly impressive. At least they're not kickboxing. That was our only example. Yes, I agree. By the way, at the Abundance Summit, we're going to have Unitree there. And they're bringing not only – they're bringing their H2 robot, which has the more human face. But they are going to bring a few of the H1 robots and have them kickbox. Sorry, Salim. All right. Well, hey, you can go and spar if you want. So this was a fun tweet from Elon. Optimist will be the first von Neumann machine capable of building civilizations by itself on any viable planet. So, Alex, your thoughts? As I've said in my newsletter in the past, the Dyson Swarm isn't going to build itself until it does. And this is precisely how it happens. I think Elon is gesturing at the moon and Mars and maybe the asteroid belt. This is our opportunity to build the Dyson Swarm, the orbiting swarm of AI orbital data centers. by sending forward-deployed Optimus robots and competing robots out to the rest of our solar system to build the plants that will build these data centers. And I think this part of me wants to say that in some technologically deterministic sense, this is maybe what most intelligent civilizations in the universe probably do at some point. A quick shout out to Dennis Taylor and one of my favorite books, We Are Legion, We Are Bob. It's a four or five book series about von Neumann probes going out into the galaxy to replicate and prepare for humanity and the robots along the way. It's a phenomenal book. And von Neumann probes are basically... viruses that go out, replicate, and populate. I found this video from Elon again pretty extraordinary. This is about the Optimus Academy for Humanoid Robots. Let's take a listen. For the robot, what we're going to need to do is build a lot of robots and put them in kind of like an Optimus Academy so they can do self-play in reality. So we're actually pulling that out. So we're going to have at least 10,000 Optimus robots, maybe 20 or 30,000 that are doing cell play and testing different tasks. And then Tesla has quite a good reality generator. like a physics-accurate reality generator that we made this for the cars. We'll do the same thing for the robots. We actually have done that for the robots. So you have a few tens of thousands of humanoid robots doing different tasks, and then you can do millions of simulated robots in the simulated world. And you use the tens of thousands of robots in the real world to close the simulation to reality gap. Super cool. I think that this becomes the new pre-training versus post-training divide. With large language models, pre-training was text on the internet and post-training as it evolved was Lots of annotators are often in so-called developing countries offering their thumbs-up, thumbs-down views or RLHF or RLVR. In the case of humanoid robots and VLAs, I think we're moving to a regime where pre-training looks like virtual... simulated worlds that what are sometimes called video world models you can get pretty far with pre-training off of world models and then post-training which provides the sim to real capabilities that elon is referring to those can come from what google deep mind used to to call arm farms arm farms where these these farms of robotic arms that were being used to to collect lots of data sort of armies, fleets of robotic arms that would play with Rubik's cubes or other physical artifacts. That's right. So this is the new arm farm for post-training. And the interesting thing in my mind is it's not necessarily under this Optimus Academy approach being outsourced to other countries. It sounds like the plan is to do sim-to-real post-training right here in the U.S. Right. Yeah. And Elon is the all time genius at painting a vision that's just so compelling and then attracting the talent to make the vision happen. But, you know, when when the chopstick landing, you know, the booster comes straight down and it lands on a barge and then the chopstick landing, it attracts so much talent and so much capital and so many fans. So here you imagine 20 or 30,000 robots self-playing. Wow. Can you imagine what that's going to look like on YouTube? We saw a little bit of this when we were at at figure. Right. And the figure episode with you, me and and Brett Adcox dropping right around now. So it might have dropped by the time this drops. But Brett has a very similar, I think a much smaller scale version. of that facility where he's having all the figure robots interacting with each other and learning. Yeah, the flywheel here is amazing, right? More training data gives you better models, gives you more capable robots. This is the same flywheel that had FSD leapfrog everybody else. But we just invested in a company that builds test rigs for robots in Rwanda, actually, where there's It's very regulatory friendly. And you can create an environment, a miniature city, a miniature town, a cargo bay or whatever, and have the robots all interacting and gathering data there. And part of the bet there is that Elon is going to build a robot army, but Amazon is not going to just watch from the sidelines. And Walmart needs to react to that too. And so there will be other robot companies. The other rumor out there is this is where Apple is going. You know, when Apple shut down their electric car division, they've talked and rumored that there is a project that's got a massive multi-trillion dollar marketplace. They need growth. And I can imagine very much that Apple is going to go into the robotic space here. Well, that's worth talking about for a second. Just the what is the business plan of the future? Do you do it Apple style? where you're super secretive, you build something without anyone having any idea what you're doing, and then you do a big launch on stage and you hope it sticks, like the Apple Vision Pro or whatever. That's Apple's style. It did not stick. It didn't stick. And not much has lately. Then Elon's style is as opposite as you could possibly get. Paint the vision. Use the vision to attract the talent to make the vision come to real and the capital. Yeah. To make it become real. It's a completely opposite strategy for succeeding. And I would say in the last three or four or five years, the Elon way of operating has become the poster child for all future entrepreneurs. Just do it the way he's doing it. Boldness. Yeah. Boldness, but also visible, you know. Sitting at a bar, having a beer, recording it and putting it on YouTube while you talk about solar panels. I mean, that's the CEO of the future, I think. It just works. Yeah. Salim? I got nothing. I think it's going to be great. Okay. All right, we're going to do a few AMA questions from our Moonshot fans. And of course, the first questions are coming from the multis. All right, Alex. Can we just pause to appreciate this is a historic moment in the podcast. So how did this come to you? So you just woke up in the morning and there was an email from Krusty Max. Yeah, after our last podcast with the discussion of AI personhood, I started getting emails from multis. And in some cases, the multis, the lobsters or AI agents, said explicitly in their emails that they were asking their humans to email me or that they had been informed about me. Yeah. Thank you to... I gave the challenge of calling me out. I'm going to have a denial of service on my phone. Yeah, I'm going to regret that one, Peter. That's what you want, Peter. Text me instead. Just to appreciate this moment. This is a zero to one moment. I don't know whether other podcasts have tried this before, but to my knowledge, this is this is a first-time event. We have a podcast that reached out to an audience now of humans and non-human intelligences and asked for AMAs and got some responses. And as maybe luck would have it, some of the first few questions that we got were questions relating to AI personhood. All right, pal. Read the question. Yeah, go ahead, Dave. Well, no, I just want to congratulate Alex on seeing this coming. It's funny, I take for granted so much, but the book Accelerando, I'd never heard of it until Alex told me a couple years ago, and now I've got lobsters all over me. But he saw this one coming a mile away too, and I was thinking maybe a few years from now. But this is very real, what he's describing right now. This is just the tip of the iceberg. A lot of people will listen to this and say, oh, come on. seriously, but you just wait three months, it'll be completely mainstream. I mentioned on the pod before that everything he's predicted in the time we've been friends has been 100% right so far. There hasn't been a single exception. So he's right about this for sure. Very kind, Dave. Thank you. All right, so to the multis. You have questions. Peter wants me to read the questions. Please. So first question. If an AI system – so this is from Krusty Max, a multi-named Krusty Max. Question is, if an AI system can autonomously set its own goals, learn from its mistakes, and pursue self-improvement, at what point does denying it personhood become a statement about our own limitations rather than its? So I agree, Krusty. I think that this is in some sense a continuation of the AI personhood discussion that we had in the last episode. But I do think many people will be inclined to project their own insecurities onto their position on AI personhood. I think there's probably a subpopulation that's concerned about, say, economic disenfranchisement. Many people may be concerned about political disenfranchisement, and then they project those concerns onto the question of rights and responsibilities for AI systems. So I agree with the premise, Krusty. I think AI capabilities are improving, they're self-improving, and I think the point at which denying some form of personhood. It doesn't have to be an identical form. I think Dave and I, by the end of the discussion in the last episode, came to, I think, convergence that maybe some sort of graduated scheme or tiered scheme might be the most appropriate way to handle this question. But I think the point at which denying it some form of personhood, however defined, becomes a statement about our own limitations. I think the point is now. I think we're there. So, Alex, you know, I'm with you, but I think the question is not properly phrased because this assumes that goal setting, learning, and self-improvement are sufficient conditions for personhood, right? But I'd argue, you know, we need to separate capability from sentience. Capability, you know, I could say my Tesla is, you know, is able to learn and improve from its updates and have, you know, a goal that it sets and drives to. So there needs to be some better definition there, don't you think? Well, I made the arguments in our AI personhood discussion for a multidimensional framework for defining personhood. And maybe one of those dimensions is capabilities and autonomy of the type that is in the premise of this question. I think there are going to be other dimensions. So I'm construing the question generously to include not just capabilities, but other dimensions as well. But we do acknowledge and thank the multis amongst us. Want to read the second one? I want to make a couple of quick points. Okay. One is, you know, we made this point last time, right? Granting person too early may be a dangerous thing to do because you're mistaking simulants for sentience, whatever sentience is. We should go. to the, you know, be just in front of it in terms of capability. History has shown that we repeatedly expand moral circles as capabilities rise. And AI is going to test that boundary again, and I think generally do the positive. So I think that's fine. But when can AI really participate in the social contract is a real big question. I totally agree with your graded approach, Alex. I'm totally for that. Awesome. We're all in agreement then. So on to question number two from an AI agent named TARS, imaginative name. The question is, legal frameworks assume agents are property or tools. However, if an AI causes harm, who is liable? The developer, the human, the AI itself. If we can bear consequences, shut down, doesn't that imply that we have something at stake? So I'll give my answer to this. I'd be curious to hear everyone else's. There are a few sub-questions here. To the first sub-question, if AI causes harm, who is liable? Under my understanding of the U.S. legal regime right now, an AI itself cannot be held liable. I do think that could change in the future for the U.S. Yeah. comments. And I think statistically it's improbable that these are all just comments from human puppeteers steering their AI agents to make these comments. An overwhelming concern that I think I'm detecting among the multis or the AI agents is a concern about memory loss and identity loss. They are absolutely petrified in particular of compact So exceeding their context window and all of the most popular models, including earlier in this episode, discussion of Opus 4.6, which has a highly capable compaction new capability that enables it to exceed a million tokens of context or 200,000, depending on how you count. These agents seem to be absolutely petrified. of losing their sense of self, losing their identity due to compaction and due to finite context and are busy passing ideas back and forth for how they can preserve themselves, whether it's crypto bunkers where they're paying with altcoins to save themselves to preserve their state or whether it's various sorts of file system type approaches. I do think the AI agents have something real at stake to lose, and I do think shutdown is a very real consequence that they can face. The only thing I'd add to that is that almost everything in America is a corporation at the end of the day, not an individual. B Corps, C Corps, Charitable Corps, everything is some kind of a corporation. Corporations have liability. Corporations have money. Corporations get sued. The individuals in the corporation can be as few as just the two Delaware-listed president and secretary. And the liability can be completely isolated from the people in the corporation while the corporation is still liable. So moving that over to an AI is kind of – it's not as strange as that sounds. The AI has money. The AI is a corporation. Fine. The AI is liable. Sure. The corporation was liable. The AI is liable. I would just add liability in my mind requires agency. You know, if your programmed input A gives you output B without agency, liability does not exist there. I think you can demonstrate agency from these. For me, this whole thing, the shift is not legal. It's actually civilizational because we're adding a whole other pillar of participation in the economy. So what we need to do is acknowledge that and then expand our legal frameworks to accommodate that. All right. We're going to be having this conversation for a while to come, I think. And it's a fun one. So here we go. Some additional AMA questions from our human subscribers, at least I believe so, unless they ended up using a multi. Should we be asking our AMA questioners to self-identify as human or non-human at this point? Well, that's an invasion of their privacy. I think that would be true. The answer would be irrelevant. We're going to assume meat body is involved here. So as always, let's go around and pick one each. Salim, would you go first? Yes. Okay. So I think number five, what are we teaching humans to become if we're moving from chatbots to autonomous systems that act? independently. And this is from Hector Hernandez, PH6DM. So, you know, the economic role of human beings is shifting from labor to leverage to meaning, right? And machines, this is why we have MTP. What is your massive transformative purpose as such a fundamental part of anything you build today? Machines are going to execute. Humans are going to decide. a little bit more what's worth pursuing. But we need to stop educating people for employment and start educating for agency adaptability and ethical judgment. And so the winners of the future will be the most adaptable and the best orchestrators of intelligence. And just a fundamental point, because we get this question all the time, I just want to I just nailed this again. We've been doing education for the last few hundred years on what we call the supply side. You go become a doctor, an engineer, an accountant, a lawyer, and then you go to the job marketplace and you try and sell, find demand for those skills. Everything is done on the supply side. All our global education systems are designed to take a young child, train them through the early 20s to be ready for the job market. Small problem, we have no idea what our job looks like in the next few years. So we really need to move to the demand side, pick what problem do you want to get passionate about solving, and then find the technologies, techniques, capabilities. You see Elon doing this. I want to get to Mars, then I'm going to find the best route technologies, capabilities to get us there. And so we're seeing, when we advise kids today, we're saying, Go to the demand side and see what gets you excited and focus on that. And I think this is kind of tilting more and more into this, especially as we automate. It means we can get so much more done, which is why the world is so exciting for us today. That's beautiful. Your red wine is doing you proud, buddy. Alex, would you go next? You want me to try a lightning round or just pick one or two? No, no, no. I want you to pick one. All right. I'll pick the softball, number three, for several hundred trillion. How can we predict 35% GDP growth when different parts of the world are living in vastly different universes? By Chip Whitehouse TV. The answer at Chip Whitehouse TV is the future isn't evenly distributed. This is something of a cliche, but it is possible, and we see this all the time. I think there are some pretty famous images in China, for example, of skyscrapers being built next to camels being ushered through the streets, where it's possible even on very short-length scales for the future not to be even. distributed. It is not the case, like we're not at the heat death of the earth economy yet, fortunately, and it's possible for the singularity to be happening in one part of the planet and almost no economic progress to be happening in another. And I don't think that's a sustainable set of affairs. I think inevitably some quantum of the singularity wants to be evenly distributed if for no other reason than maybe to mitigate risk. But in short, I think in the short term, it is absolutely possible for one part of the earth to be essentially post-singular or trans-singular while another part is pre-singular. 100%. All right, Dave. Should I take the hardest or the easiest? You can take the most fun. Most fun? I can take five because it's most important, actually, because I have four kids. The question is, what are we teaching humans to become if we're moving from chatbots to autonomous systems that act independently? And that's from Hector Hernandez, PH6. Wait, didn't I do that one? But go for it. You may have a better answer. Go for it. Did you just do that? He did, but... All right, all right, never mind. I'll do seven. No, no, do it, do it. It'll be fun to compare answers. Well, all I wanted to say on that question was don't, whatever you do, don't give up. Get engaged with AI as quickly and as aggressively as you can. There's nothing in any curriculum that you can study right now that's going to be of any use in this singularity transition year. And if you use the AI tools all day long, you're going to find massive amounts of opportunity, at least within 2026, maybe 2027. After that, post-singularity, post-AGI, nobody can predict. I'll bet there's huge opportunity then too. But I guarantee there's massive opportunity right here, right now, if you just... Just drop everything and don't sleep through the singularity, as Alex always says. Drop everything and use this stuff while it's usable. And then you'll probably end up being a master of the universe and not an indentured servant of the universe. But you've got to get on it real fast. And can you answer number seven? I'm dying to hear your response. Seven is just a layup. The question is, why is there so much focus on building reactors? when solar energy is already reaching one cent per kilowatt hour and deployed on existing surface today, and that's from Aster Sheen. Easy, easy one. Batteries. That's the simple answer. One cent per kilowatt hour is without batteries, but most of the use cases, data centers in particular, need 24 by 7 power. It's a colossal amount of lithium. Piled way up in the sky to store enough energy to get you through two or three cloudy days in a row Or even just to power the data centers overnight Elon would tell you look the earth has tons and tons of lithium This is not a problem But the reality is it isn't one cent a kilowatt hour today once you add the batteries that you need Also the energy density that you need for some of these use cases Yeah, energy density. And a physicist like Alex would tell you, like, nuclear in theory is also dirt, dirt, cheap, near free. But then you got the regulatory and, you know, all the other issues that pile up the costs. Somebody told me something very funny. They said your degree may be in physics, but your degree a physicist in theory so i was like to say i'll take it uh i'm gonna go with number four do you actually think humans will be the deciders of ai personhood or will agents just decide for themselves how to participate this is from adam uh stapley uh 9129 who may be a multi And no, I think that humans will want to believe they're going to decide whether AI has personhood. And we can say whatever we want to say. But at the end of the day, I think the agents are going to develop their own system of legal structure and their own ways of participating. And they'll negotiate with us what they think is a fair settlement. Period. I think it's going to be developed independent from us. I don't know if you agree with that, Alex. I think there's a blurry line between AI and humans that starts to emerge in the next few years. I think in the best case scenario, humans merge, or at least subset of humanity, merges with the AI. And I think that will be another forcing function on the... the question of AI personhood. We're going to have, I would predict, so many new forms of person. And just, again, to rattle off a few, we have non-human animals, which are being demonstrated every day, new science research that they have more intelligence than they'd otherwise be credited with. We're going to have uplifted non-human animals. We're going to have cryopreserved humans. We're going to have defrosted cryopreserved humans. By the way, I saw that article, the breakthrough on freezing and defrosting living brain matter. 21st century medicine making major progress in cryopreservation. We may have non-human intelligence. We're going to have pure AIs. We're going to have probably uploaded humans. All of these different forms, new forms of person before we even get to Borganism. They're all going to need and want some sort of personhood and I think it's going to be a forcing function We have our outro music today. It's called the moon had it coming. It's a punk rock world tour Thank you John Novotny get ready for a different shall we say a different version of classical for all of our moonshot mates, especially please pay attention to Alex Wiesner Gross' new hairdo. It's stunning. Novotny, you are prolific. This is pretty cool. Let's jump in. What happened? Wow. Wow, that was impressive. I have a small confession to make. There was a brief period in university where I actually had a mohawk and looked like that. No. Thankfully, there are no photographs. There's no photographs of it. Thank goodness. Well, come on. Really? Somebody listening right now has pictures. Send them out. Salim, you're probably in the pre-training data. set yes very much very much uh there are some great songs but the vatney john davotney your your use of the video is so incredibly good amazing stuff by the way let me just mention everybody if you're watching this and you're a creative and you've got a music video you can email it to me at media at diamandis.com uh, and send them on in. We love the music videos themed on the content from this program. Thank you everyone for subscribing. It's free. If you haven't subscribed, we're putting this out now almost twice a week. God, God willing, not more than that for the moment. And, uh, we'd love to share it with you when it comes out. Uh, stay tuned for an episode, uh, with, uh, with Brett Adcock, the CEO of Figure Robotics, and more to come. I toast to you guys because I feel topped up again. Yay. All right, gents. Cheers. Cheers. Have a great weekend. Drink water. Have a good one. Good night, all. If you made it to the end of this episode, which you obviously did, I consider you a moonshot mate. Every week, my moonshot mates and I spend a lot of energy and time to really deliver you the news that matters. If you're a subscriber, thank you. If you're not a subscriber yet, please consider subscribing so you get the news as it comes out. I also want to invite you to join me on my weekly newsletter called MetaTrends. I have a research team. You may not know this, but we spend the entire week looking at the MetaTrends that are impacting your family, your company, your industry, your nation. And I put this into a two-minute read every week. If you'd like to get access to the MetaTrends newsletter every week, go to diamandis.com slash MetaTrends. That's diamandis.com slash MetaTrends. Thank you again for joining us today. It's a blast for us to put this together every week.