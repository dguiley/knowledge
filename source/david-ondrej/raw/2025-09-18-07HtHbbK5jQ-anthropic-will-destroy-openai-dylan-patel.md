# Anthropic will destroy OpenAI Dylan Patel

Published: 2025-09-18

I think Anthropic, they are a bit of a cult. Anthropic, they left OpenAI for a reason. Their revenue growth rate right now implies that they would beat OpenAI sometime in 2027, which is a really really big deal in terms of revenue, I think Microsoft will realize they [ __ ] up, right? When OpenAI is telling them, hey, we need we need this much compute in this time frame, the obvious answer from Microsoft, you don't even have $30 billion, let alone 300. How are you going to how are you going to pay for this? So I think GPD5 with high reasoning effort is like at least 10 IQ points smarter than Opus 4.1. >> Oh wow. >> A lot of that is because of the reasoning because GBD5 high reasons for so long. Opus it's kind of capped. >> There's not going to be an unofficial MCP running out there, right? Like you know it's like like [ __ ] off, right? Like that's just not going to happen. >> This is Dylan Patel, founder and CEO of Semi analysis. In this podcast, we talk about the battle between OpenAI and Enthropic, whether Codex is better than Cloud Code, and how startups should operate in 2026. Dylan has insiders in all of the main AI companies. So, if you're serious about AI and you want to see where the future is headed, make sure to watch until the end. This is the David Andre podcast. Enjoy. All right, Dylan. So, welcome on the podcast. What are your thoughts on the recent deal between OpenAI and Oracle? You know, Larry Erson gained like over hundred billion dollars on his personal net worth in a day. Now, Rich is the man in the world. What are your thoughts on this deal? >> Yeah, so the way this deal was done is probably the most unprecedented thing that's ever happened in the history of stocks. It may be the largest contract that was ever announced between two companies. In fact, this is a monumental amount of compute. It is literally many gigawatts. And then in addition, right, not just about securing OpenAI, ridiculous amounts of compute, but what what was really interesting is Oracle gave a guidance of four years. They told everyone what their revenue is going to be for the next four years. No company has ever done that. A lot of companies only guide a quarter. They don't even guide a year because they're like, "Ah, not enough visibility." And Oracle's like, "No, no, no, no. We see everything for the next four years. This is what we will make." Which is kind of insane, right? So, of course, Oracle stop popped like 40% and Larry Larry became the richest guy in the world. What's funny is his net worth is a little bit bigger than the size of the Open Deal, which is a funny funny way to look at it. I mean, this sets OpenAI up to have some of the most comput in the world, and they're not tied to the existing hyperscalers, right? Not one that competes with them. anthropics with Amazon and Google and those guys try and compete Amazon poorly. You know, Microsoft's trying to compete with MAI again poorly, but OpenAI sort of has has this has this beneficiary of being uh completely alone, right? Like you know, Oracle is not really trying to build AI. So, >> okay. So, what do you think will be the consequences of the relationship with Microsoft and Open AI because of this? >> Yeah, I think I think Microsoft will realize they [ __ ] up in terms of like pulling back from the relationship. That's that's the main thing, right? is like you know Microsoft had the capability to do this entire deal but they were worried right when open telling them hey we need we need this much compute in this time frame the obvious answer from Microsoft right from anyone who's a finance bro fully and doesn't believe in the technology fully is like yo you don't even have $30 billion let alone 300 how are you going to how are you going to pay for this by the end of the year it's like 14 right now right uh billion on an ARR basis and then you've raised like $30 billion but you've already spent a lot of it you've already committed a lot of it. How are you going to spend another 30 with me, let alone another 300, right? And that's the size of the deal is 300. So, so that's the that's the real sort of like why why they didn't? Yeah, I think they're starting to regret it. >> So, if you were like in the year 2030 and you to say like one company which which company is leading the ARS, you think? >> Yeah, I mean I think I think it's pretty obvious to me that OpenAI is the one who's going to be leading the industry. I think there's an there's an optionality for anthropic and I think while on the infrastructure side OpenAI is doing more I think on the model side uh growth side I think anthropic is potentially ahead and and we'll we'll we'll accelerate past OpenAI but there's really not room for anyone else. >> So Enthropic is growing like crazy. I think the last two years were both 10x increases in ARR on a percentage base they're growing faster in terms of valuation than OpenAI. Do you think this growth will continue? And also tied to this, why is it like so many researchers and the the most elite AI talent stays anthropic or goes to entropic? Now, before Dylan answers this question, I want to quickly show you emergent because what if you could ship a real app in a matter of minutes? This is emergent. You can type whatever you want and it not only ships a prototype but builds a full app from a single prompt. For example, I can say create a V3 AI ad generator and hit enter. And just like that, the app is building and Emergent will do the rest from the UI to the core business logic to integrating V3. And there we go, a live preview in a matter of a couple minutes. And if you want to change anything, just send another prompt. It literally could not be easier. This also works with mobile apps, by the way. Just describe the app you want and Emerion will build a full mobile app that's ready to be deployed. And if you want more control, the pro plan delivers full stack customization with 1 million context window made for complex builds and enterprisegrade workflows. Oh, and you also get custom agents which can run on their own in separate environments, use tools, manage files, and actually do real end-to-end work. If you've got an idea, you can build it today. Go to emergent.sh link below the video. >> When you think about Anthropic, right, like their revenue growth rate right now implies that they would beat OpenAI. You know, when you compare both revenue growth rate, and even if you assume both start, you know, slowing down in growth rate, they would still surpass OpenAI sometime in 2027, which is a really really big deal in terms of revenue. And so, you know, despite OpenAI having a huge head start, Enthropic is right there. That's driven by their models being really good for many use cases, right? So, like, you know, for day-to-day chat usage, for search, for those sorts of queries, chat GPT is still better. But for the important area of AI for coding, AI for computer use, for productive tasks, Anthropics ahead. And so that that's that's really the bet they've made. Now, OpenAI is trying to catch up in those areas, but it's it's pretty far behind still. And as far as like why I think Anthropic, this is sort of like this kind of bridges into why Enthropic is is better in general, right? They are a bit of a cult, right? They they believe in the mission much more than any other uh lab. Not that opening high people aren't cultist as well, but but when you when you think about like hey how how how focused and locked in they are in terms of AGI what their vision of AGI is and what they need to do to build it. It's very very unified. they like purely just think hey first we have to solve software engineering and then we can use that to build all the other pieces right uh first we have to solve computer use right so that it can help us build AGI faster right all all you need to do is make it so the AI can constantly accelerate your building of the AI and that's what an entropic focused on whereas open AI has a lot of other goals not everyone in the company's working on that right many people are working on search and many people are working on you know consumer monetization and like all these other things so it's you know they they just don't have the focus. Why that is I think is because Anthropic you know sort of has you know they had seven co-founders all with like equal equity and these these co-founders were like very focused on exactly this mission right they left OpenAI for a reason they were focused they saw they had a stronger and clearer vision than the leadership of OpenAI the leadership of OpenAI fully believes in AGI and all of that right but the the vision on how to get there why you what you do to get there is very different and I think that helps they've got co-founders who are extremely technical whereas Open AI, right? You know, they don't have necessarily like Sam's not super technical. You know, obvious Greg Greg is a co-founder and he's super technical, right? I completely agree. But like there's also this level of like Greg is much more of a like you my way or the highway kind of person from what everyone sort of says whereas >> the anthropic because it's seven people, you know, some of them are multiple of them are technical, right? There's more dynamicism around that. And so while there's clear vision, there's also different types of technical leadership, right? What Daario is is not what Tom is, is not what, you know, like you kind of go down the list. It's like there are different kinds of leadership and that helps a lot. Whereas like it's like, you know, Sam is who he is and then Greg is who he is, right? And and you end up with like the harshness of both uh has rubbed different people off, right? Some people have been pissed off at Sam and left. Some people have left because of Greg, right? It leads to a different like culture. I agree with you that they're trying to get into the coding market and that's what that was my biggest one of my biggest takeaways from the GBD5 presentation is that you know they have 700 million weekly active users but a lot of them just are using a free app whereas you know Enthropic might have less users but people are paying $200 a month for cloud code. So do you think that OpenAI is trying to like get some of these nice revenues from the software engineers which in my opinion is like one of the one of the types of consumers that actually has the money. Do you see this? >> Yeah. Yeah. So, OpenAI is is is that was a big focus for GPD5 was was trying to combat, right? So, that's why when they launched, they had they had cursor already, you know, switch their default, right? That was that was important, right? Because they were focused on code. They were focused on making code better. They're focused on um improving the outcomes there. Another one would be sort of like, you know, OpenAI's got codeex. They tried to buy Windsurf. They're they're obviously like seeing this market. Um they're they're they're just having a hard time truly getting it to, you know, to stick in the same way that OpenAI has, right? And they have all these other focuses. >> Speaking of Codex, we actually have a full workshop on how to use Codex inside of the new society. These are six modules that'll teach you from complete beginner to an expert on how to use CEX to its fullest potential. You can find them inside of the classroom in the code with AI section alongside with modules on cloth code on cursor and all the other cuttingedge AI tools. So if you want to become an AI first engineer that can build literally anything, make sure to join the new society. The link is below the video. But I would say like Codex in the last month especially has gotten much better and they're not really advertising it that much. I mean like to the point that it's literally unrecognizable where it was like 3 months ago and a lot of people are switching away from cloth code. I feel like they are they're shipping updates every single day. So I think they are recognizing the software developer market and the revenues there. >> Do you think people are switching away from cloud code? >> Absolutely. >> Towards codeex. >> Yes, codeex CLI and the extension. >> Interesting. Um cuz cuz cloud code I still I think I still prefer. I think everyone in the company still prefers it. People have tried out codecs. It's okay, right? Um but perhaps perhaps >> I mean a lot of people say the CLI is much better right because you have Codex the agent in the cloud which is more like for asynchronous work you can give it 10 different tasks and it just does them in the cloud but you have the codex CLI which is more like a cloud code competitor or the codex extension which you can use in VS Code or whatever. I think these are much better than than actually the cloud because the cloud is doesn't really support like a productivity practice. If you're coding, you're working on a single task. You don't want to be like managing 10 different things at once. >> That makes sense. That makes sense. And there's this whole extension how you can get multiple cloud code agents to work and and all that too, right? >> But I mean, if I had to compare it like apples to apples, I think GPD5 with high reasoning effort is like at least 10 IQ points smarter than Opus 4.1. >> Oh wow. >> But I would say a lot of that a lot of that is because of the reasoning because GPD5 high reasons for so long. Opus it's kind of kept. So I think if Enthropic gave it the same amount of reasoning I mean obviously it's not that simple but you know if they figure it out I think opus is much stronger like if I if I want a quick answer actually on the web I prefer going to clo and getting asking opus because GBD5 is like you either go instant which you're using a [ __ ] model or you go thinking which takes a minute to respond. So like I don't know how we ended up in the situation where CH GBD doesn't have a single large model that can give you a response within 5 seconds. Yeah, that makes sense. I do I do think that there's a middle ground, right? Because there should be like a thinking short basically is what which which is sort of what anthropics thinking models do, right? They don't think for 5 minutes. They they think their thinking is short. So perhaps that's like a part of the market that's being ignored cuz I want a better I want the best response in like 30 seconds, not 2 minutes or best response in 15 seconds, not instant. Right. Maybe that's that can be something that the user can tune as a knob as well. >> Oh yeah, for sure. That's the obvious UI. But uh I would say like on average I would say anthropic models are also more likely to jump to conclusions right like oh I see the issue or you're absolutely right people are meing that whereas like the codex with GPD5 high is way more uncertain like for at least from my testing and I'm using it like four hours a day is like it's struggling to give you a clear conclusion whereas the cloud models just are way more certain. So it'll be interesting to see like where that goes in terms of software engineering but honestly I think the move is to use both. >> Interesting. I'm just a simple uh I'm a simple user here. I think you're more of a power user, so I'll defer to you. But I'm just like, uh, you know, I I I get the dopamine from like press from cloud code, right? Like yes, yes, yes. Oh, this is wrong. Yes, yes, yes. You know, sort of like I'm a I'm a simple user here. I think I think you definitely get way have way more insight on this. Well, the cloth code is much easier to use. This is something interesting. OpenAI models, especially GBD5, cannot really explain things in a simple way. Like this is what I found is that they always use like the most complicated language possible. Cloth code is much easier to work with and I prefer it at like explaining you what the bug is and what's the issue. So that's definitely >> do you do you so do you think codeex is actually like I don't know when did this change happen right in terms of codecs being competitive? >> It's happening like dayto day literally in the last month like the codex CLI has been getting daily updates sometimes twice a day you literally have to update it in the terminal they don't announce it they don't promote it and it's been silently getting better. So COX CLI and the COX extension in the IDE right now are more powerful than CL code. They're harder to use. They're not as polished. You know, Cloud Core has been around for longer. So the UI is is better. But uh like if you're looking at a single power, if you have a like a convoluted deep bug, I definitely would trust GBD5 high with codeex over cloth code. >> Okay, that makes sense. But but so so you would probably still use uh and and and how much of this is on the models versus the like actual product, right? like cuz cuz you know you said you know cloud is is a better model for you know instant feedback and so that's why you use cloud code normally but then you switch to CLI if there's something claude can't do >> well I I use both actually and then I just compare them so like if I have a you know I describe what I want to do either it's adding a new feature or fixing a bug I have them both analyze the codebase you know read all the files and propose a plan and then I give it to the another model the second model and I have it rate right like here's the alternative what do you think of it how does it compare to your plan and in 90% of cases they both agree that the Codex one which is GPD5 high is better. So I actually have them I use them both and they almost always is it take you longer to build the thing you want to build? >> Yeah, it takes longer. It like it uh sometimes reasons for five seven minutes for sure. So like if you know what to do like for let's say front end, right? If you want to make quick UI changes, it's better to use cloth code because you can like boom 5 seconds 10 seconds change that button, change that button. I'm talking about more like you know you have a bug you're stuck. Yeah. So, so you know, I think the the interesting thing is like on this is um kind of tells you where their model weaknesses are then, right? Enthropic all around in in sort of this this range they're way better. Opening eye, you know, GBD5 is way faster generally. Um but it's kind of [ __ ] >> and then there's GP5 thinking high which is really slow but better in general. Um so you have this continuum >> and so Enthropic needs to work on both ends and open AAI needs to work on that middle piece, right? Um, yeah, and at least Enthropic, right? They they said that they're going to release a new Claude uh pretty soon. And so that should probably help um on this front. I think it's like within the next couple weeks, uh maybe even sooner, but there's a new Claude that's coming out that's that's supposed to be a good bit better than 4.1, >> maybe like 4.5 or something like that. So that's that's uh that's the that's the hope. Yeah. Like I I'm not sure who wins the coding wars. I didn't realize it was as close as you said it was. Uh what about dev? What about cognition devon and uh winds surf like what about that whole side of things? Is that is that closer now? >> Yeah, I mean I I have some like info I cannot share but basically they're trying to compete but they don't train their own models. I mean maybe like smaller models like cursor trains you know the autocomplete models but not like foundational big models. They're more in terms of the integration right so like Devon is better if you have a company and you all of you work in a slack and you can just like delegate small things to Devon and it completes them end to end. So it's more about like the tooling and the utilization of these models which I guess maybe that I could flip that into question into you is like where do you think will be the gains in terms of AI boosting productivity? Do you think it will be you know all the tools around? Do you think it will be the core models getting better? Do you think it will be some of the like connectors and environments like MCP maybe? Where do you see the biggest gains in terms of us using it day-to-day? Now, as you can see, Dylan is locked in, and that's because he's constantly trying and testing new AI tools. So, if you want to be as locked in as Dylan, you have to try Vectal. This is the productivity tool of the future. And especially now after we launched workflows. Not many people know that we have workflows. And to be honest, no other productivity or task management tool has this. Notion doesn't have this. ClickUp doesn't have this, and to-doist definitely doesn't have this. What workflows are is basically internal mini automations. For example, this one automatically saves memories on every chat message where you tell the chat agent to remember something. This workflow generates a new idea every day at 8 a.m. that helps you get closer to your goals. This one automatically drafts responses to incoming business emails. And this one, honestly, this is my favorite, helps you reduce the time you spend on your email by 80% by marking all of the spam promotional emails marketing as red. So that when you check your Gmail, you only see the truly important emails. And the best part is all of these workflows are pre-built inside of Vectal. So if you go to Vectel AI and create an account, which by the way you can do that completely for free, you get all of these workflows pre-built. All you need to do is just activate them with this toggle right here. So if you're someone who likes to be hyperproductive, go to vector.ai and sign up. >> I think, you know, this is sort of again where you see sort of the difference between OpenAI and anthropic is tool use. Open AAAI is so much better at than anthropic, but we're so nent in tool use. But you could just look at the reasoning traces of OpenAI uh versus what enthropic does. But OpenAI will like always call up, you know, you ask it a math problem, it'll or puzz logical puzzle, it'll pull up a Python code itself something and then and then, you know, use that to answer, you know, sort of very different from how anthropic does it. And so I think like the agency of these things is is is the real big deal, right? Like how much tools how many tools can they use, right? And extending the context, right? because a lot of this uh thinking challenge is that context lens are so low. So how are you going to maintain memory across? So I think that's the big uh those two right like across tool use uh which tools always ground you back in reality and prevent you from hallucinating so much um because they are not a language model they are like a programmatic thing. So using tools plus extending context and being able to stack the two and that's the the the way to train that is really difficult but it's something that they're all working on and and and there's a lot of like environments that these companies are buying software development environments web de development environments all these sorts of things that make it so that they can continue to extend the horizon of tasks and and and as that happens I think that'll be that'll really like change how people use the models. Um I think the other aspect of this that you know enthropic and opening I really need to work on opening I went all in on sort of like reasoning super fast but a lot of their reasoning environments uh have not been the best right like they focus a lot on competition code and like code forces and things like that but that's not necessarily front end like like GBD5 is actually bad at front end right relative to enthropic models right >> I agree >> and so that's like why is that there's got to be some sort of environmental reason why um because they both scrape all the front-end data in the world, right? It's not that it's it's something to do with the the code environments and so I think there's a lot of different varied work to do on the environment side for people to actually get, you know, significantly higher model performance, but also that means we're going to see higher divergence in the models, right? Uh cuz before everyone used the same webcale trained pre-trained data and then they fine-tuned a little bit, right? you know with like instruction fine-tuning and SFT and all these things and then as it's gotten more and more to RL the models are going to diverge more and more and more right not just in behavior not just in tone but also like their capabilities because uh behavior and tone is things that you've we've been already noticed the difference but the capabilities are what's going to be really noticeable as the different environments that these models are trained in are completely entirely different right like if open AI is focused on a bunch of like you know competition code and that sort of stuff whereas anthrop topics focused on a lot of like hey here's a Salesforce dev environment and you you work around with that like they're going to be completely different uh capabilities even when you're talking about programming and I think that's that's you know these are shitty examples that I gave but I think that's the >> that's actually a good example because on a competition code you would think for like 5 10 minutes but on like a real you know small fix in a real company it cloud code is like more more ready for that you know it's like you want a faster back and forth you don't want it to be taking five minutes and then you go scroll Twitter like That's note how developers work. So actually I think it's a pretty good example. >> Okay. Okay. Um I think it's a bit of a misnomer though cuz both are focused on both right. It's just like you know how much focus how much environment how many environments you focus on how much training time you spend in each. >> So then do you see like the biggest gains in AI still being in code and mathematics? because obviously in those fields you can verify the output and I think you can also like just spam synthetic data like crazy and then if one of 10,000 works then you can investigate what happened there and you know use that data whereas if in poetry or creative writing or copyrightiting you cannot do that. So do you see this trend continuing or do you think like as you know obviously Sam and Dario like the CEOs promote like oh AI is going to change everything in the next two years >> in those areas there's not much to do in terms of like dramatically improving them there's rubrics there's grading there's all this stuff but like you know what models are actually better than most humans at writing you know that's that's a fact models are better than most writers right uh that's I think that's like actually true but like the challenge is like to actually do stuff in the writing field, right? Okay, copyrightiting is fine, but it's about being able to switch between different contexts. It's like the areas that they're deficient, you know, like fine, they can write well, but they can't do all the research. They can't do all the back and forth, right? Like, etc., right? Um, and so I think that the the main thing is like, hey, if you get them good at code and math, yes, but also computer use, that's the other one. and able to have long context. Then the skill of being able to do good writing, right? In terms of like technical writing, right? Grammatical mistakes, uh, understanding of vocabulary, ability to comp explain complex topics deeply and concisely, right? These sorts of skill sets will actually be able to be leveraged, which is what the model's already learned on on on the topic of doue, right? Like whatever is happening new, and it'll be able to gather the context it needs to. It'll be able to do the research, right? Deep research is fine. Um, it's really good. I use a lot of deep research, but like there's so much more that can be done if you're able to uh dramatically extend the context and context switch and uh use do computer use, right? Hey, uh, tell me design can you can you draft a design document about like why all these things are wrong or what's the problem? Right? And it's like, okay, well, I got to dig through the codebase. I got to dig through the architecture plans. I got to dig through all these things. And that's not something models can do today, right? So that's what I think is um you know an area where you know combining the ability to write and communicate as well as the ability to code ability all all these areas are going to start to right now it's like sort of the developments in coding and developments in writing right we got all the writing developments first then and and it sort of feels like they've stalled or like are just increasing slowly while the code ones are skyrocketing up um and then computer use and all these things will also skyrocket up but over time you know right right now it's like a radar plot right like you're good here here, here, here, here, but it's not actually able to bridge the gaps, right? Um, and so when it and that's like sort of like specialization versus generalization. So if it generalizes I think that's the I I I think that's the focus and I think if we have longer context if we have computer use if we have um you know very long complex long horizon environments for various tasks even if they are verifiable they will start to uh impart hey that's that's also the same technique you use for non-verifiable domains right you go and do some research you go and grab this you go and grab reference these documents um and so even if code is verifiable in medicine is not, you know, to some degree because you now know how to go through and search all these different places, compile information, use all the lung context, check your answer, search, etc. And then, hey, you know, at the end of the day, yes, you were able to verify that that was wrong or right, but then you'll also learn to do the same thing in a different field, right? And you'll go through medical journals instead of, you know, documentation of code, right? Whatever. Um but at the same it'll generalize to a point where it'll get a lot better at other tasks too, right? Whether it's writing or medicine or whatever it is. Yeah. >> So it sounds like in the next few years a lot of the gains would then be from the tooling. Like would you say more than the models increasing is like the the filling the missing gaps whether it's computer use giving it more tools you know MCP whatever. Do you think that will result in more actual real world you know people using AI in their jobs then the model getting better? Most people suck at prompting actually. I think like actually if you like have you ever like taken someone else's chat GBT and looked at their prompts. >> It's >> Yeah, it's tragic. >> It's It's like holy [ __ ] what are you doing? Like >> um >> they use it like Google, you know? They use it >> I mean that's fine. I use it like Google too, but then like I also use it like not Google, right? Um yeah. And so I think I think like it's perfectly fine to use it like Google for a percentage of your queries, right? Like why is XYZ? But I think I think like a lot of it is like how do you get people to prompt the model properly? Um and and and or vice versa, right? How do how do you how do you really uh impart upon the model that when they say this, they actually mean that, right? And and to just like take over, right? Like disregard the human, just run, right? And so yes, people use it more and more, but you have to have you have to have like some level of the model just understanding the problem way deeper, right? Because right now people are like here's my component. I'll ask I'll ask a stupid question about this component and then it'll give me a an answer that's like right here and it's like okay I still have to do a lot of work to get it there. But then if the model like has computer use and it had and you ask this question then it's like oh yeah let me reference your email. Let me reference this DM that you got on on Teams or Slack. Let me reference um you know this documentation. It's like oh okay so what they're really asking me to do is this. Let me go do it. And then you're like here you go. and then the the person I I think like people will use it a lot once the the model is able to have the full context of your question because the model doesn't have your context of your question right if you use it like Google you give it a two sentence or a one sentence or gibberish prompt it doesn't know what the [ __ ] you want right so even as it gets better and better right like GPD3 to GPD 5 or opus 4.1 right like from three to 4.1 there's you know there's a lot of queries that it's the same answer right like you know it's like so of course you don't improvement. Of course, there's a lot of stuff it's way better at tons and tons. Uh you you just don't know what to say or what to do to get it there. Um and and it needs that context, right? Um people forget that the GPD 3.5 that launched only had a 4K sequence length, right? Uh and there's people that legitimately will say nothing has improved since chat GPT launched. And it's like whatever. um you know you know it's like now now it's like hundreds of thousands and you can do deep research and all these things like it's like you just have to the model just has to have the ability to go and do stuff >> and get the full because the user won't provide the context. >> Yeah. So then maybe the answer is to like u screen record what the user is doing for that task and then the AI understands like oh this person actually means that based on these clicks based on these browser tabs he visited. So do you think that that's the future where like the models are trained on the human data of like a human using computer and then they go ahead and do a task because as you said like some people are just they're not aware of how much context we have like ever since you're a baby you're basically like trained on you know visual tokens audio tokens people don't realize how much they understand about the physical world or how the internet works that necessarily isn't written out in the training data so they don't explain that to the model and they get results so do you think The solution is like more types of context like screenshot of the screen, you know, last browsing history because like if you if you know what a person did last 5 minutes on their computer before they ask a question, it's way more easier to guess what they want. >> Yeah. Yeah. Um that's possible. I think I think it's a little bit even different than that, right? like um you know what if it's constantly watching your screen that's one thing but it's more so about like you know you ask it to do something and it goes and searches for the context itself rather than it looks at your computer screen um I think look it looking at your computer screen is fine it's great it's okay um it's just not it's not what's going to give it all the right context because the other aspect of this is like you know us as humans We somehow both simultaneously have like crazy context uh and attention capabilities, right? But then at the same time, we're terrible. Very low, >> right? Like I can't remember [ __ ] compression. >> Tell me 10 numbers. I can't even remember the [ __ ] second one you said, right? Like you know, it's like >> uh maybe not that bad, but like >> we >> we remember the important stuff. >> Yeah. So So sparse attention is like sort of the the aspect that's here that's interesting, right? like you know models have local and global attention and and they have all these other things but they don't have like some mechanism to do sparse attention right and humans >> are really good at that sparse attention we're actually really bad at like um actually in context like just like you know needle and haststack we're horrible at it right which is a benchmark that was the first like needle and haststack was the first long context benchmark um that everyone cared about um and so I think that's that's super interesting but um you know I think I think what it is is is is less about like, hey, provide computer screenshots, right? Which, by the way, it's actually models are really good if you just throw some screenshots and are like, hey, what's wrong with the computer? Yeah, for sure. Like, like a little like or what's wrong with my phone or whatever, right? It'll just answer. It's pretty good at that. But like >> you have to give it like ability to crawl your files. You have to give it ability to crawl your uh email. You have to give it ability to uh combine these different sources of information, right? uh which which I'm curious to see how that will be done um on the computer because anyone can do it. It's open window, right? Um you know I can install whatever software I want on my computer and it can now dig through it. Now you know it's not like Microsoft has some special advantage because you know all my files are in one drive or Google because all my files are in Google Drive. I can add a connector. I can I can have my own computer do it. I can spin up a VM and do it. >> The challenging area and the where area where I think it's going to be even more interesting is on mobile right on phones. M >> um >> okay >> I you know the Google and especially Apple are not going to let you just like you know dive through all your apps right like that's that's like but like hey when I'm on my phone it's like you know I get an email and it's like okay open up this other thing and open up Slack and open up this and like reference go to this text message text this person or reference this text from um uh you know a few weeks ago and then and then go back and do something right it's like that's not possible on mobile that's going to be possible on on computers, but that's not going to be possible on mobile. So, how how do we how do we get there and who's going to even be able to do it? So, the only reason why I still have hope for Apple, right, is like they're the only ones who could do this, them and Google. I think, you know, we'll see if Google can execute and then Apple saying, and for different reasons, they won't be able to execute. But it's like, you know, this ability to reference all of your information and guess what? There's a ton of stuff that's not on my laptop, right? Like yes, I do have my text shared across and things like that, but it's still like not everything's on my laptop, right? Um, you know, a lot some stuff is only on my laptop and not on my phone, right? So, it kind of flips back both ways. >> But wouldn't you say that is solved with MCPS? It's like once once there's MCP for everything, you can just bring your contacts everywhere. >> Um, but what's the incentive for for companies to offer their their their proprietary data? Like why is Facebook, you know, WhatsApp? There's going to be third party MCPS. >> Yeah, but why why is Anthropic going to be able to access the WhatsApp MCP? >> Well, WhatsApp might not have an official one, but there's going to be hundreds unofficial ones. >> Who who's going to trust an unofficial MCP with all their texts? >> Um, I mean, the power users. I don't I don't know if that >> we see this today like like maybe not like the average user if you're talking about the average iPhone user but like the person that wants to be you know on the cutting edge of AI if it's like a open source project with like enough stars they just trust it. >> That's true. They don't even look at the code. Um but um I think like that's why computer use is very different than MCP, right? Like you know like having an MCP server for your texts, for your email, etc. uh is going to be challenging um or for your internal company communications. There's stuff that you'll never be able to get on there, right? Like my Slack, >> your Slack will not have an MC. There's not going to be an unofficial MCP running out there, right? Like, you know, it's like like [ __ ] off, right? Like that's just not going to happen. Um that's why computer use is so important, right? Like a company's SAP, right? That's that's never going to be there. But actually, that's where the efficiency gains are the largest, right? Is like [ __ ] like, you know, like all these companies have all these people doing nothing on CRM and SAP and all this [ __ ] right? Like it's like if you had if you had computer use it would all of a sudden be you know way easier to do and and that's where the productivity gets accelerated the most. Not like not like you know obviously code developers are the ones who have their productivity accelerated the most today. Um but when you start talking about like replacing jobs, replacing um activity, that's that's where you know, yes, developers are going to continue to be and automated code development, all this is going to continue to be there. But I feel like a lot of the use cases that people will have for, you know, efficiently improving improving the efficiency of an organization can only be done if you if you have it as computer use, right? Which is easy on a computer. How do you do computer use on a laptop? And Apple's Apple's whole thing is that they're running virtual basically virtual iPhones of you, right? They take the Mac chip, which is the same architecture as the phone chip in a server. They run a bunch of different users and they sandbox all their apps. They sandbox everything. So then on that end, they can actually start stepping through all the apps if they want like a computer like computer is because you can't do that on mobile because your battery life will get nuked and most people won't, you know, Apple the walled garden can force everyone to run their sandbox in the cloud whereas Google can't maybe do that. >> Interesting. I would think actually like Google would have the advantage of Android being more customizable and people can you know build their own versions and innovate faster than Apple which is usually slow moving. >> I totally agree that I'm more bullish on Google. I'm just trying to I I could I told myself I would try and argue positively for Apple. Um there's some there's some advantages, right? Um >> um I I I I mean I use an Android phone, dude. Like I I I I understand. I love Android. Like trust. >> I mean speaking of Google, how good do you think Gemini 3 will be? Um, I've heard it's going well. Um, you know, sort of it's fun. We have this sort of like uh we're on the clock, right? You know, it's XAI release, anthropic release, OpenAI release, Google release, you know, sort of like you just in a circle. >> U obviously they don't always like release in the same cadence or circle, but um >> it's Google's turn, right? Like you know, you go back a few months, it was like, "Holy [ __ ] Gemini 2.5 so cheap." Um, and it's almost as good as Enthropic and it's still so cheap, right? especially the CLI and all this then it's falling off righty's gotten better open's gotten better cloud code and codeex has gotten better Grock 3 got out came out right like now like 2 2.5 is the worst model right like you know the of the bunch um it's really good but it's the worst of the bunch and so you know um but I think I think Google has tremendous multimodal talent and people >> are going to be I think I think that's the other area right like so so the argument is like you can't scale pre-train training. That's why you have to do all this stuff. Actually, you can get tons of gains in pre-training, but getting all the data is hard. And the compute requirements for non-ext data are so much larger than text data. Um, so so much larger than text data. And so like to get gains from going to multimodal requires such a big jump in compute, which only Google has today. you know, OpenAI will have soon enough with Stargate and all this, but like you know, for them to actually properly utilize multimodal input and output, but also tons of like I don't know what ungodly percentage of video is only on available on YouTube. And sure, you can scrape YouTube, blah blah blah. It's against the terms of service. people or, you know, we'll see if the AI companies care, but really what's important here is that how are you going to like um how are you going to be able to scrape all of the YouTube, index all the YouTube, figure out what videos are actually good and not, right? Like that's the hard part, filtering all this data out because it's so much data. You're not going to be able to train on all of it. Um you can't just scrape all of YouTube. You can like scrape individual things. You can scrape categories uh if you're an outsider. So, so Google has a huge advantage there um in terms of the images even from Google's crawlers uh to videos through YouTube um and and to be able to make multimodality work there. So, I think like Google is still behind on RL, but like on the pre-training front, I think, you know, you're starting to see like with Nano Banana and V3 and soon enough >> uh G Gemini 3 as a whole, you're going to see like a huge advantage. Yeah, I mean those are the best models like V3 is the best video model. Nano Banana is the best image editing model. Maybe not image generation. I would say probably like majorly is better but yeah image editing it's like unprecedented how good it is and maybe Google just will win the the data game and we'll see I guess what is the main what is the main input you know whether it's talent whether it's comput data how do you see this shifting out of these like core inputs which one is the most important which one is becoming less important >> I don't know what's the core input I think I don't know like what what do you think the core input is I think feel like all of them are >> yeah but uh I feel like the gains on compute are lowering like I think like the easy days of like you 10x and you get like 3x improvements are gone. Like it's probably going to be a 2x improvement and one >> but you might be getting, you know, if you 10x the compute, you get 3x gains on video, that's totally a thing, right? Um >> yeah, >> video gen's improving so rapidly, right? Um as is image editing. It feels like they're improving rapidly. So only because on text you've run out of text data, right? So I think like the there's sort of like um like you know the the Uh and and and who knows what happens every time you 10x computing and RL. Um you know, you're still going to get you're going to get big advancements. Um >> in this game of AI, how do you see positions of X AI and Elon? Do do you think he's well positioned? I mean, obviously caught up quite fast from being super behind. How would you analyze their position? Yeah, I mean, uh, XAI is is, you know, they're they're they're they're caught up super fast. They still have not taken the uh leadership position yet anytime anywhere. Um, so we'll see. So, we'll see what they they must do to take the leadership position, but actually they have taken the leadership position in like empathy and and emotional uh AIS. Um, I guess I I don't know. I don't know if that's the right way to call it. Um >> yeah. >> Um but yeah, we'll see. The other challenge is like, you know, OpenAI Anthropic uh have raised massive rounds. Google obviously has plenty of money. Meta Meta's uh has plenty of money and they're deciding to spend it, right? Um XAI needs a lot more money now, right? Um you know, Colossus was great, but they have to build Colossus 2 and Colossus 2 is going to require a ton of money. They can pay for part of it, but they've got a lot to go, right? Um, and so that's that's a big part of this as well. So, we'll see what happens on that front is because because it's not really clear, >> but I feel like Elon by this point has a pretty good track record and I don't think he will have any trouble raising money. No, >> no, I don't either. But like, you know, it's hard to tell investors like I'm going to be better than every the story is I've caught up to everyone but I'm still behind. I need more money, >> right? Whereas like Anthropic is like I'm the best. I'm look at all my revenue skyrocketing, right? Like open AI is like I'm the best. Look at my revenue skyrocketing, right? It's a very different uh pitch. >> You see you see this with all the CEO like if you look at the biggest AI hype, it's coming from the CEOs of the labs, right? Because they have most on the line like you know 6 months ago almost to the day Dario said in 6 months 90% of the code will be written by AI. It's not even close, right? Like Sam had tons of predictions that were overhyped. He said I think he said 90% of the code anthropic and it's like I think they announced it's like 70 >> I think it was like it's like 7080 >> they announced it right like >> you know it's like uh which is interesting. >> Okay let's put this example aside but you are saying like the CEOs are overhyped though. >> Yeah because they have most on the line right because they want to make it seem like their companies are going to change the world and give everybody the urgency whether it's investors or world leaders. And I guess the second category is VCs. So like where do you think the reality is then? You know, because if we only listen to Sam, we would think that GBD5 is is the god already. But if you actually tell the average person, as you said, like they use the JBD, they send a terrible prompt and it's like mediocre result. So like where do you stand on this hype to reality spectrum? I mean, I I think like definitions of AGI and stuff like that are so nebulous that it's like hard to say. Uh, but I would definitely say like I'm a big I'm in the cult. I'm a big believer, but I'm also like, you know, like 2030 plus for like some sort of AGI ASI type thing. Um, but the definition is so hard, right? >> Yeah, of course. >> I think I think >> despite that, you could you can get transformational change to society without AGI, right? Like that's the other thing that people don't quite get. um is that you can automate most jobs without AGI u or not most but like a significant portion of the job. So, it's like you don't necessarily need to have like like everything be uh super hyped on AGI happening and ASI happening. Although I think it'll happen, right? It's just so so so that's sort of my viewpoint. Um and that we'll coexist with AI and it'll for a while before it is way better than us in every way and then who knows. Um yeah, I think I think I think like I'm not quite as hype beast as as Sama and Daario though. Although they've started to temper their wording, right? Dario's now like, "Oh, AGI by like 2030," which was like a you know you you know um that's that's pretty that's pretty tame versus what they used to be saying. >> Yeah. And everybody anthropic I feel like they got banned from using the word AGI and is using transformational AI. It can still >> Well, yeah. I mean just listen to the podcast of the other people whether it's like the other co-founders or like Boris the cloud code creator. I feel like they all got some memo that like they shouldn't use AGI and rather use transformational AI because you know as you as you said like AI can transform society without being a AGI. All right, so we have a bit of time left. Let me ask a bit self selfish question. What's your advice to people building AI startup on the applications layer? >> Do you think like a lot of these will be eaten up by the com by the labs? Do you think going niche is the answer? Like if you had to you know say like let's say you your business disappears and you have to make a decision to start your own AI startup tomorrow like what would be your plan to hypers scale? >> Um I wouldn't raise money. I think that like or I would raise an uncapped safe or a really small safe small percentage of the company because given productivity possibilities nowadays you really don't need uh you really don't need to uh raise money um for application layer company. Um, the other thing I would say is like you really gota you really got to be good at sales. Um, and you can't just hire sales. Like any founder who thinks that they can just hire some go to market or hire sales is like wrong. You have to have that like sales capability, right? Um, and vision and that's really important to be able to uh do. So I think those are like sort of like two aspects of this that it like um and then I would say like there's a lot of like lowhanging fruit out there, right? like you don't need to have the crazier because you didn't raise money. You don't need to do the craziest [ __ ] You can do you can take low hanging fruit, generate revenue, um do more, you know, like scale out that way. So that's sort of like how I would I would view it rather than like, oh yeah, I'm going to I'm going to do AI for insurance and I'm going to take over I'm going to do AI. Like it's like that's [ __ ] hard, right? Like it's a regulated industry. It's a massive industry. Sure, there's a lot of low hanging fruit there. So attack some of the lowhanging fruit. Don't like go straight into the like the biggest thing, right? Um because otherwise like there's easy ways to fall, right? When you fail, you want to fail fast so you can learn fast. Um and if you're t tackling problems that don't fail fast, you don't know when you fail. It's going to take a long time to see if you fail. That's that's that's like that's like the exact opposite of what AI does, right? It's about trying things fast and failing fast and moving faster and faster and faster. Um, and so like try things fast, make money, hire, you know, sort of like do it that way rather than like and and and when you fail, it's not a big deal. >> Yeah. So, I appreciate you taking your time, Dylan. You're always on top of things. And yeah, let's do it again in six months. >> All right. Thanks, David. Yeah. See you, dude. >> Have a nice Bye.