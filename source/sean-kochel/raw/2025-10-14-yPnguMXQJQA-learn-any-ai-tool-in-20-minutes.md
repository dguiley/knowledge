# Learn Any AI Tool in 20 Minutes

Published: 2025-10-14

Three days ago, I'd never touched the OpenAI agent SDK, but today I shipped a functioning feature with it. New tools drop constantly, and learning each one feels impossible. So, here's the three-step framework that lets me build with anything in under 20 minutes. We're going to walk through each step using a real technology as an example, and we'll talk about each of the three steps and how we use them. This is the same system that I used to go from I've never even touched Nano Banana before to building an image editing app in a few hours. It's how I integrated Crew AI into an existing CRM without having to actually read the docs. So, the vibe coders that are really winning right now aren't smarter or more technical. They just have a process for translating their curiosity into something they can build with in hours instead of months. So, that being said, let's get into it. So there's two core problems that this system solves. Number one, not knowing the real development patterns of powerful technology. And number two, not knowing how to apply those patterns to your project. So a lot of you probably stare at the world of agents and other cool technology passing you by. And you get a lot of FOMO because you feel like you can't learn it rapidly enough to implement it in a way that people want to pay you for what you've done. So on one hand, you know what's possible, but there's a clear knowledge and skill gap to actually implement on the thing. But that FOMO or fear, it's kind of like staring a gift horse in the mouth, if I got that analogy even remotely correct, because we have these language models that if used properly can help us bridge that gap in our understanding of how those things work and how to apply them to a problem we want to solve. And all we need to know is how to prompt it the right way. So there's three steps here that are going to help us solve that. First is the core research phase. Second is how we refine that research into a technical documentation that's valuable to us. And third is how we take our product requirements and fuse that research together so that we can actually take action on it. So get these three steps right and you can build pretty much anything within reason even as a moderate level beginner. But the key like I said is in the prompting. So let's take a look at our first prompt. So our first core step is the research phase. So if context is king, then research is like our trusted advisor. And the core problem that it helps us solve is this. A lot of the time we want to build with new technology or even just slightly more advanced existing technology, but we have no idea how to do that properly because we just don't know about it. So take for example the new OpenAI agent SDK. Let's say you wanted to go build an intelligent agent and do something with it. How do you optimize them for accurate tool calling? How do you optimize it for its memory management? When do you need to use a super basic model versus a more advanced model? What are the patterns of how agents should actually be structured and orchestrated together so that they work to solve the problem? How should you actually be prompting those agents so that they have enough direction, but then you're not being too restrictive on the system? So, there's a lot of these known unknowns that we know we don't know about those things, but then there's a lot of these unknown unknowns that we might not have even been introduced to those concepts yet. And this process helps us solve for that. So, if we simply went into a tool like cursor and said, "Build me an agent that is a personal training companion," we're probably going to get a pretty vague, pretty generic output that maybe works, but it's kind of useless because it doesn't work the way we want it to. So this research process mimics what an actual engineer or product leader would do if they were trudging off into some unknown territory to build a new system or a new feature suite that was going to require a lot of new technology. They're going to go out and they're going to try to understand from the high level through to the technical details. So here we have our prompt which will be available for free in the description below where we cover off on all of this stuff. So, we're giving it its core goal, the format of the response that we want, the guard rails on the system, what do we want it to return to us, what do we not want it to return to us, and then additional context about our company and what we're trying to do. So, here I have an example of this filled in. And I'm just going to go paste this in to my claw desktop. So, we can see here I pasted it in, and this thing ran for a long time. So, this in total went through 500 different sources and it took an hour and 27 minutes to fully go through all of those resources and process what I was asking. And so, we can look at the research document that we got back. So, we start with a high level of what we asked it to research, which in this case was the OpenAI agent SDK. So, we're getting the highlevel technical philosophy of that framework and what it's meant to do. we start getting details of the different components of the system. So in this example there are agents, there are handoffs, there are guardrails, there are sessions and there are tracing. It then breaks down well what are the decisions in actually choosing to use this or not. So, for example, the agent SDK from OpenAI, it's deliberately minimal abstraction layers, which means if you were going to build something like crazy that needed to be highly performant and very customized, then it might be a good choice for you. But in this case, as someone that's not a software engineer by trade, that's probably a route that is going to be a very big headache. and I'm better off in my opinion getting a proof of concept first with something that has more abstractions in place and we'll talk about that here in a second. So then what it goes through and does is it pulls well what are the top alternatives for this then crew AI claude's agent building capabilities and you could prompt this to provide even more if you wanted to. So it goes on and on talking about what are the foundational concepts that even make this type of system even run in the first place. What is the order of understanding that you would have to have in order to actually build something with this? Everything from understanding chat completions to running an individual agent. Then learning how agent execution loops and orchestrating those agents works, how you're going to manage the state. What happens when you have a bunch of different agents working together? How are they handing off information between each other properly for what you're trying to build? Right? And it goes on and on. I'm not going to go through this entire doc because that would make for a long video. And so the thing I like about this is part of its research is it's pulling in where do a lot of these implementations start to break down in the real world based on what it's finding in its research on places like GitHub, new sources, places where developers tend to hang out. Where do beginners tend to go wrong specifically when they're starting out with this stuff? Which is important to know because if we're a beginner, we don't want to make those mistakes. What are the primary usage patterns specific to our use case here, which is a personal training agent that I'm building for my own use case? And so we get examples of like common patterns that would be used based on again public documentation, how it could be integrated into our app. At what break points in the app would you need to start scaling the complexity? So like a single agent with really involved tools might work for a basic version of this thing, but then you would start adding on multi- aent systems with specialized logic. And then again a beginnerfriendly failure pattern. So things that you specifically don't want to do because they are going to create problems for you. What are some what I like to call shooting yourself in the foot moments where you think you're using a basic feature that if it's not used properly and engineered properly can cause some serious harm and a lot of cost. Now, another important thing to keep in mind when you're building with anything is how mature is the technology? Is there a lot of support around it in case you run into issues? even if you're using a language model to help you debug that issue, are there sufficient resources for it to go out and find what it is that's going wrong in the project? And then at the very end, in this case, it actually told us to avoid OpenAI for our use case and just go with crew AI. And it gives us the reasons why. Perfect for the use case based on what we are trying to do. What I described the MVP of this app was proven to work in production environments. Now I told it I wanted soloreneur friendly options. So there's a quick time to value with using a tool like crew. A lot of this more advanced stuff is abstracted away and handled like how you're going to handle memory management between agents orchestrating the tasks monitoring what's going wrong which can be a super big headache with agents specifically the cost flexibility where we can use any LLM provider based on the task. tons of community support and proven in an enterprise scenario. So, this is already huge because as we could see, it was starting to introduce us to ideas that we may not have been aware of when we set out to build with this technology. And more importantly, it provides us a foundation for knowing the key considerations that must be true if we wanted to use this in our project. But a lot of people would make the mistake of just taking this research report, maybe putting it in a markdown file and just giving that as context to a language model and then just start building from here. And that is a mistake because there's a lot of unnecessary data in there. And what we really want to do now is try to synthesize that research report into technical documentation that we can actually use in our project. So let's look at the next layer of this which is the refinement layer. So the problem that we're now faced with is this. We have this huge body of research, but not all of it is necessarily relevant to what we want to do. And so we need to extract out the relevant bits for our project. And then we need to turn it into something that will actually work for what we're trying to do. So we have this second prompt here, which is the refiner prompt. Now what it does is it takes that and it creates this persona of you're like a developer kind of architect oriented person and you're trying to translate all of that into something that you could show to your product manager or somebody that's going to have to take all of this and prioritize what the team's going to build. So what would that person need to have? So again, you will have access to all of these prompts. So I'm not going to go through them in detail, but we're providing some context about the business and what we're trying to build. And then we're telling it, hey, this is the output format that I'm looking for. I want you to specify very clearly performance standard expectations. The opinionated patterns, if there are any of the framework that you've chosen. So for example, crew AI uses a very specific set of sequences or flows that it recommends users are aware of, right? like what is like kind of the meta layer of how to use the tool the way it's intended to be used and a few other things. And so again, I prompted in with our specific business case where I pasted in this research report which if you're just doing this in the same chat flow, you can just tell it to reference what you have done already. So you can say like reference above for example. So we have this now and we have pasted it in. We're referencing that above research report which is the artifact and giving it a very basic user context. You'd probably want to go in and add a lot more of the options that are in the in the prompt doc that you have access to. But I'm basically just saying I'm trying to build an MVP and here's the current stack that I know for sure that I want to use. So let's look at the output that we get. So there's some highle decision summaries. It's outlining what its assumptions were. It's talking about the tech choices that have been made. So in this case, crew AI using different models depending on the complexity of the task. We're talking about our expected performance standards based on us using crew AI and what we can expect on the technical side if it's built properly as far as like latency, how quickly it responds back to the user, the cost to actually run the system, stuff like that. Then we start getting into important patterns on the development side or conventions that it should conform to. So what domains in the app are responsible for different pieces of information so we're not crossing over where we shouldn't be? How is it going to actually be integrated? How should the error handling work? How is this going to integrate into the high-level service architecture? So like where is it going to fit in specifically to the app? Right? So the nextjs app is going to make requests to the back end via this endpoint and then fast API is going to kick in and actually orchestrate the crew. Since some of these tasks may be long running, how are we going to process those background jobs so that if we get 50 people that come through and immediately burst a bunch of requests that it doesn't break our server? How are we going to store the information? How are we going to know what's going on in the system? Where's like logging going to take place? And then it's talking about some authentication stuff which ideally not entirely necessary for proving out this what we're doing right now, but it's it's in there and we can iterate on that later. So long story short, we took all of the important bits of information about Crew AI and how it should be used and the performance that we can expect and we turned it into a very clear set of guidelines. Now, we have this section here for to be decided. And these are things where you're going to want to fill this out if you have information on it. So, what prompts is the crew system going to actually use to to do this type of stuff? So, we want to go through and answer these types of questions wherever possible. Now, once we have all of that, the final piece of this planning process is we want to take that final output and we want to take what our plan for the MVP is and we want to merge those two worlds together. So if we were to take an analogy of building a house, well, we now know how to think about constructing the house. We need a solid foundation. We know that the walls need to be such and such a way. We know that the ceiling needs to be supported with certain beams because there's a second floor above, right? There are these different considerations that we're now aware of. But now we're layering in well we're building a house for a specific person that has specific use cases for that house and how they want to use the rooms and what they want it to be like living in that house. And so we need to merge those two things together. And so the reason we run this step is that we do not want the language model making game time decisions about how it should handle certain things. We want to make sure we're iteratively moving through the planning process to make sure we're on the same page with all of the decisions that are getting made. So, in this example of a personal training agent, I wouldn't want to just take this technical documentation and say, "Now, go build me a personal training agent." Why? It might decide to build a personal training agent for bodybuilders, which is not what I want to do with this app. Or it might make some crazy agents that are doing some odd obscure thing that is not really the purpose of the app. So I want to be very clear about what my product is, what the MVP needs to look like, and then give this documentation to it so that it can build that into its plan. So here we have our final prompt, which is this like infusion fuser prompt, the fuser 9,000. And what we really want to do is take the output of our last step and we want to infuse it with our actual product requirements. Now, generating this list of product requirements, I have tons of videos on this on my channel. I will link one around here so you can see how to generate that specific doc. But if we go now into our example, you can see what it looks like where we have a little bit of a highle summary about what we're building and who we're building it for and how it's meant to impact them. But then we get down to the level of concrete specific features. So, I've prompted my what my MVP is to the system and it broke it down into user stories. So, for example, in this system, I want it to be where you upload your own photo and a reference photo and it's able to understand the gap between your physique and that physique and it uses that as the basis of the plan it builds for you. And then from there you know you do your workouts, you log your workouts, you log your nutrition and it is constantly giving you feedback knowing that this is the goal you are moving toward. So we have a few different features then that fall into that. So we have this visual goal setting feature story. We have this workout programming story. We have the conversational plan refinement where I could say hey I don't have access to that equipment. Can you swap it for something else? Now, I wanted the app to be focused on people that want to build like functional fitness. And so, there's a emphasis in the application on compound movements and certain things like that. So, we give it all of those user stories and we paste in our final prompt. And so this is what we get out the other side where it's largely returning back to us our initial plan but now all of these like businessoriented success metrics and feature acceptance criteria are based on the actual capabilities of the technology that we have chosen. So we know for example what's going to be the actual cost per user per month on a high level based on again the assumptions of how many times people are going to generate plans and and all of that type of stuff. So the reason I like doing this process is now if we were to look at one of these feature stories. Number one, the actual like story and acceptance criteria for like how do we know that this built properly? It's going to have in its context how the crew AI system actually functions. And so if we were to go down here, we know that we're going to have this dependency for this feature story, which is a crew Aai agent orchestration that has access to a program agent and a nutrition agent. We know that we're going to need to have this API integrated. We know that we're going to need to have some sort of exercise database so it knows what to pull from. We know that we need to engineer it so that we get a response on this plan within 30 to 60 seconds knowing that crew AI may take that long. Well, then there's UX considerations. What do we do with the user in the meantime while that is processing? And so it helps us start fleshing out how is the way that we structure our app and the user stories and the user experience, how is that going to be tied to the tech choices that we just made. And so it's going to go on and it's going to do that piece by piece for every single feature. So again, inside of our compound movement feature story, we know that we're going to have to have a piece of our crew AI overall like agent architecture that's able to pull the exercise classifications from the database and do an analysis on it to make sure that 70% of the program volume is made up of compound movements as an example. So let's zoom out for a second to a,000 foot view. We started with our core research about a domain that we did not know about. We synthesized that down into technical considerations for that platform and then we infused those technical considerations with our actual product development plan for our MVP. So the next question becomes well what would you do with this output? So the next stage of this process that I think is incredibly effective is to run this through a UX exercise. So we want to think proactively through based on these feature stories that I have like the visual goal setting, the workout programming, the conversational plan refinement. Based on all of that stuff, what should the user experience actually be? How do we want the user to feel about all of the different features? what type of value should they get at each stage and how is the system going to be set up so that they get that value. So if we were to think of like a building a website, the first stage of building a website would be wireframing it out. How do you want it to actually be? Where should the navigation be? Why is it there? Where are the calls to action going to be? We sketch all of that out in a wireframe before we start putting pen to paper in terms of the actual style and design of that website and definitely before we actually start coding it. So I love to run it through this type of workflow where we take those user stories and we build out the UX wireframes for those ahead of time. And this is what that type of system actually looks like where we have our UX documentation. We have a list of what all of our features are going to be that we're going to build based on what we just got out of Claude. We have everything we're going to need and then we're just building a task list for it to go out and actually build out our wireframes. So we're not even really coding in this piece. We're really thinking through the UX. Again, if we're in the conversational refinement stage, what are the goals of the chat? How can the chat be modified? What are the success metrics? How are we going to present information to the user in this interface? What does the actual flow of tasks look like from the user saying something with all the options that they have? Maybe they can attach files, maybe they can upload photos, lot of stuff they might be able to do. How are we going to translate that and accept that? And what do we expect back from the system when we do it? So for every single feature, we're working through this so that we can get a lowfi wireframe of what this interface and its primary states and components should actually structurally look like and how does that fit into the plan of how a user is going to actually use this thing. Once we're done with this stage and it's all built, then we can work on the overarching app architecture, making sure we have all our dependencies in place, doing some like beginning style guide creation so that our components start having like color and interactivity and animations and all of that. And then once all of that is in place, we can start orchestrating the implementation of this plan. So that's it guys, three steps to go from zero to hero on stuff that you wish you knew more about. So what do you do from here now that you have this kind of infused product management feature story documentation? You take this output and you use it as the input to the next stage of the planning process which as I just went through for me is going to be the user experience planning. Now I have an entire playlist on my channel that I'll link at the end of the video where I go through that type of process. So my ask you try this out and report back. We have a free group with over 11,000 members that are vibe coding projects they care about, asking for feedback, giving feedback, and learning with each other along the way. So, if you are working on a project, it's a great place to get feedback from real human beings, which is a precious commodity in this day and age, I must say. And not for nothing, but if you found this video practically helpful, I would actually value having you in that group, too. So, if you want to see more videos like this one, join that group and make sure to subscribe to the channel so that you get notified when I put out cool stuff like this, which is twice a week. That is it for this video, though. I will see you in the next