# The ONLY AI Tech Stack You Need in 2026

Published: 2025-11-05

At this point, I have basically already covered all the technologies that I use throughout my content. But what I have never done before is created a single video going over my entire tech stack and why I use the tools that I use. And so that, my friend, is what I have for you today. So, if you're looking to build any software going into 2026, listen up cuz I got some really solid recommendations for you. My tech stack is AI first cuz I really don't see another way to do it these days. And I've been using pretty much the same tech stack except for some of the newer technologies for over a year now. So it doesn't change often. It is very stable. And I consider this a good thing. In fact, before we even get into all of the individual tools here, the biggest recommendation that I have for you is to find what works well for you and just stick with it. Now, you still want to be flexible. Like sometimes there are tools outside of your normal stack that will solve a problem better. you want to do that. But generally just finding what works well for you. The mantra that I always have is capabilities over tools. And what that means for this video specifically is instead of this being like, oh, let's dive into the nitty-g gritties of every single tool here and obsess over them, I more just want this to be a resource for you. If there's ever a certain technology as a part of your stack that you're unsure of, then just take my recommendation so you can get right into solving the actual problem, building the actual software instead of worrying about the tools cuz in the end, problems come first. And so that's what I have for you in this video. All right, so here's how I have things laid out for you in categories. I'm going to start by going over my core infrastructure, the technologies that apply to basically anything that I am building. And then I have things split into the different types of applications. So the tech I use for basically all my AI agents, what I use for rag agents specifically, then agents based around web automations. Then I'll get into my full stack development tech stack. And then I'll end things off with some deployment and infrastructure, and then also self-hosting options for things I haven't already covered because local AI is a big part of what I do as well. And for each of the technologies, I'm also going to be covering alternatives, like a couple of alternatives for Postgress, for example. I think this will really help frame how the technology fits into my stack and also just show you that I'm not just trying to give you one tool as the end- all beall. I want to talk about some alternatives and how that relates to what I end up using and why I use that over some of the other options out there. So, kicking things off with my core infrastructure, the foundation that powers everything. Not that I use these technologies all of the time, but they apply to every type of software that I build. So for my database, most of the time I am using Postgress and I'm either using it through Neon or Superbase generally. So they are both platforms that host Postgress under the hood and I've been using Superbase for longer but experimenting with Neon more recently especially because of their scalability. They both look very similar and operate similarly. Like this is my dashboard for Superbase. This is the one for neon both running Postgress under the hood and then I also have Postgress su through superbase as a part of the local AI package. So a lot of the stack that I cover today that's open source I have that as a part of the single package for you to run everything on your own hardware and so yeah Postgress is fantastic and for anything that's open source going forward by the way I'll have this check mark and oss label right here so I don't have to just like say it every single time because that is one of the benefits of a lot of the things that I'm covering in this video as far as alternatives we have MongoDB and fire store and so just speaking to a couple of NoSQL alternatives And I used to be a big fire store guy, even using MongoDB a bit maybe like four or five years ago. And I switched a lot more to SQL recently because it's definitely the industry standard for building AI agents. And I feel like LLMs understand SQL a lot more than writing queries for NoSQL like fire store and MongoDB. And because of pricing and scaling, I just know a lot of people including myself that have switched to SQL. And Postgress is just the standard for that. So that is my database that powers most things. We'll see Postgress a lot going forward as well. And then for caching specifically, I use Reddus. It is blazing fast. And then also we have Valky as an open- source alternative. That's one of the things I have in the local AI package. And it's completely compatible. So I can use Reddus if I want something hosted and convenient, but then always switch to something local if I want. And oh, did I mention that it is blazing fast? So great tool for caching. And then for my AI coding assistant, honestly, probably the tool that I have open most up on my computer is Claude Code. And I'm always using it with Archon, which is my open source project. I'll link to a video right here. It's knowledge and task management for AI coding assistance. And so this enhances my AI coding experience a lot, but Cloud Code is my primary driver. There are some fantastic alternatives like cursor with their new 2.0. Codeex is definitely catching up to cloud code, but right now it is generally considered the best AI coding assistant, though it is a bit pricier and has some rate limit issues that people are dealing with right now, but it is still my daily driver. And just the features they have around slash commands and sub agents and the new Claude skills is very, very cool. And so I'm using Archon along with it for everything that I'm creating. Like literally all of the different types of software that you'll see in the rest of this video, I'm building it with the help of Claude Code. And as much as I'm using AI coding assistants all of the time, I still love using no code tools to help me prototype what I'm building, especially when I'm creating AI agents. And there are some good alternatives like Langflow and Flowwise. I even covered Flowwise on my channel one time and it's also in the local AI package. But N8N for me is where it's at, and I feel like it's going to be like that long term. It is a phenomenal platform that I've covered so much on my channel, building things like rag agents like you're looking at right here. And so I'll use it as a tool to quickly prototype ideas, validate the tools I'm giving my agents and system prompts, things like that. And then I'll usually move to a coded solution once I'm confident in my prototype. And and is great because of all their app integrations. It's very AI focused. They're building in features all the time to help with creating agents. And of course, it's open sourced and self-hostable. And again, I'm not going to mention that as a benefit going forward, but you'll see the label right here. And as we move on from core infrastructure, the last thing I want to say as I'm going through everything here is that obviously I'm not listing every alternative, but I just want to list a couple to help frame the conversation here. And then also for some tools, I don't actually have alternatives because I just haven't tried something comparable or I just genuinely don't think there's another tool worth looking into. And so with that, that'll take us into the next category here for the tools that I'm using for all of the AI agents that I create. Now, for my AI agent framework, right now, I'm pretty much exclusively using Pideantic AI, which people ask me why all of the time because there are so many good alternatives, even using no framework at all. A lot of people like just using raw LLM calls, and I respect that as well, because a lot of these frameworks are what I like to call an abstraction distraction. You end up fighting the framework more than it's actually helping you because it's hard to really customize things once you get into the nitty-gritty of building your agents. But I feel like I don't have that issue with Pyantic AI. It's a lot easier for me to build agents than just raw LLM calls, especially when I'm swapping between different providers. But I still feel like I have all the flexibility and control that I need as if I was doing raw LLM calls. Plus, Pyantic AI is constantly supporting new protocols like MCPU when that first came out, A2A for UI event streams. We have AGUI, the new Versell uh data streaming protocol. And so it's easy to just build on top of the latest in in AI thanks to Pyantic AI. And then for multi- aents specifically, I love using Langraph. And a lot of times I'll be actually using these two together. So Pantic AI is how I create my individual agents. And then Langraphph is how I connect them together in more complex workflows when the use case actually calls for multi-agent. I don't want to overengineer and always do multi-agent. So I'm only using lang graph for the more complex use cases but it is a lifesaver. It is so easy to manage state human in the loop for more complex workflows routing between my different agents graph persistence. They have a user interface to help us visualize our graphs. Langraph is awesome and there are some alternatives like a lot of people love using crew AI for building multi-agent. Pidantic AI graphs and so I could actually use the same framework to build multi- aent that I use for building single but I feel like langraph is just the most mature handling some of the core components of these more complex workflows like human in the loop for example now frameworks like pideantic AI make it very easy to add tools into our AI agents but what they don't handle is agent authorization and tool security that is where arcade comes in and so for example if your AI agent needs to get permission to access a user's account like to view emails in their Gmail, send a message on their behalf in Slack, the agent needs some sort of way to authorize with those accounts and that is where Arcade comes in. That is a very hard thing to engineer without a tool like Arcade and I don't actually know of any alternatives that do it the way that they do. Plus, they've recently released an MCP server SDK, so we can build secure MCP servers directly with Arcade, leveraging their tool sets, leveraging their tool authorization right within the platform. And so, I'll actually show you the docs really quickly. They have this entire guide now, how we can build our own MCP server. So, it's basically building MCP servers like fast MCP, if you've ever built a server in Python with that before. But now we can bake in the arcade tool authorization right into these servers. And so this is a Reddit example. We got different tools to like get subreddit posts for example, get post content. But then for the ones that need authorization specifically, we just add this decorator here so that when we call this tool, it's going to send a user through a ooth flow. So the agent has access to their Reddit account to, you know, for example, get their username or submit a text on their behalf. So, our agent can do things for individual users. Now, that's the kind of authorization that's very hard to engineer for without something like Arcade. And in a video on my channel that I'll link to right here, I did a demonstration incorporating Arcade into Langraph. So, I have this AI agent where, for example, I can say, "What emails do I have from today?" And take a look at this. The agent doesn't have access to my account yet. And so, it sends me this link. So, I click on this link to go through an ooth flow. So I go through this, I sign into Arcade. Now the AI agent going forward is going to have access to my account to do things on my behalf, but also just with the permissions that I set up in the application. So it's also very secure, very granular. And so authorization successful. Now, if I go back to my agent, it's going to list out my emails. And you can do this whole OOTH flow directly through MCP as well. I just wanted to show you the example from my longer video in case you're interested in checking that out. But yeah, the last thing that is core to all of my AI agents is Langfuse. This is for agent observability. And you cannot skip this step. It is so important, especially when your agents are running in production to be able to monitor them. So for every single run, you can see the token usage, the total cost, the latency, the tool calls that your agents are making. And with their Langraph integration, so just like Arcade, they integrate with Langraph. All my tools work very well together. You can also see the different agents in a multi- aent system. and the decisions that are made like what what agents are being routed to in this execution. So without something like this, there's no way to set up evaluations, AB test or system prompts for example. When you're serious about making your agents reliable, you need a tool like this for observability. There are some other good options as well like Langmith and Helone for example. But I find Langfuse to be the most featurerich. And Langmith is very popular but also not 100% open- source and self-hostable. And so that's one of the things I love about Langfuse. It's another one of those technologies that I have in the local AI package as well. Next up, I want to talk about all the tools that I'm using for rag agents specifically. So, I just covered what I use for all AI agents. So, these four do apply in general to rag agents too, but now these are tools specifically for data extraction. We have data storage, knowledge graphs, and then evalarch I would include in rag. And so first of all for data extraction you don't always need a framework but for more complex documents specifically like PDFs with diagrams Excel files it's helpful to have something out of the box like dockling to help. And there are some good alternatives like llama index has a lot. It's a agent framework specifically for rag. We've got unstructured but man dockling has been crushing it for me pretty recently. This is actually one of the newest additions to my tech stack. a lot of before I've just been kind of doing manual extraction without a framework, but this has just made it so much easier for me and it's easy to use self-hosted models and it's completely open- source unlike a lot of data extraction tools. And then for website data specifically, I use crawl for AAI. It's very fast and efficient. It automatically cleans junk. They have LLM integrations. You can send it into a website and use an LLM and just kind of like ask it for what text you want to extract specifically. So it's very very featurerich. And so think of it this way and I'll go to the documentation here. If you are working with files, use dockling. If you are working with websites, use crawl for AAI. That's my decision process. These are the two core tools that I use for data extraction specifically. And then for storage, I love using Postgress. So not only is it my regular database that powers all my applications, but thanks to PG vector, I can basically use Postgress as a vector database. Now it's not a dedicated vector database like something like Quadrant or Pine Cone. These are alternatives that are going to be faster. So it is a trade-off. When you have a dedicated vector database, they are faster. But the reason I like using Postgress is a lot of my rag strategies, they need a regular database as well. like they just need a SQL database to store document data or to store user data as it relates to rag. And so that kind of thing I really like using Postgress for and it also scales extremely well. And then for long-term memory specifically, the reason I have this here in my rag agent tools is because long-term memory is just a form of rag. It's an implementation of rag and I love using mem cover this on my channel as well. By the way, I'm going to keep linking to videos that relate to these technologies cuz like I said, I have most covered most of them in my content already. But I love Mem Zero because it integrates with really any database that I want. So I can use Mem directly with PG Vector, which is very nice. They're right next to each other and they also integrate together. Um, and it's just super easy to add into any AI agent. So there are some other great long-term memory frameworks. Let's example that I'm not putting here because it's actually more of an AI agent framework focused on long-term memory. But mem zero we can incorporate this with any AI agent like I can build my agent with pideantic AI and then I can search for memories inject them into the system prompt and then extract memories after. So I can kind of just sandwich my agent no matter how I build it with mem zero. And then Zep is an alternative uh that is not open source like me zero which is why I generally prefer it. So that is long-term memory. Now I want to get on to the fun part here with knowledge graphs. a lot of content I've done on knowledge graphs recently. And so for knowledge graphs, there's really two parts. We have the graph database and then generally you're going to use some kind of library to help you insert data and search through data in your knowledge graphs. And so for the graph database, what I like to call the engine, I love using Neo4j. They have a really beautiful UI. It's easy to query through our data and work with it. And then also one of the great things with Neo4j is that it is supported by most knowledger graph libraries like a couple that I'm going to talk about in a second here. It's also very high-speed and very very scalable. Now the licensing is not ideal for Neo4j uh even though it is open source. So when you get into commercial use it's something to look into if you're interested in Neo4j. There are some great alternatives as well like memaph and folklore DB. And now for the library to help us insert data into Neoforj and search our knowledge graphs here. I love using graffiti and so cover this on my channel as well. [snorts] It's a very intelligent entity and relationship extraction. And so going back to our graph here, we have these different entities and then we also have information or metadata for how they relate together. And obviously unless we have a super specific use case where we can somehow extract this deterministically, we need to use a large language model to extract entities and relationships from raw text and that is what graffiti helps us with. So this is where we store the data. This is how we get the data in the format to store and how we search it as well. Light rag is another alternative I've covered on my channel quite a bit. Uh but light rag is more like vector database and knowledge graph. Graffiti is focused just on knowledge graphs and I like to have them separated and so I've even done implementations on my channel where I have a gentic rag. I give an AI agent the ability to search both a vector database and a knowledge graph depending on the user question. Very powerful stuff for evaluation. I love using regos. It is I'm not sure if I'm pronouncing that regos. I don't know if I'm pronouncing it right, but I love using it for setting up eval pipelines. And so specialized metrics for rag like faithfulness, relevance, very very powerful. A tool like Langfuse we can use for agent evals overall, but that's more around like the tool calling of agents. But when you want to look at things like these metrics specifically, that's when Raos is fantastic. And it also helps with automated test data set generation and works with any LLM provider. And then last but not least here, web search. You could kind of consider this a part of web automation agents, but also this just was the last spot I had to fill in this section. And it is a part of rag, right? Like retriegal augmented generation. It's not just searching your own knowledge. It's just searching the general knowledge, the wider web. And that's what Brave helps me with. And perplexity is another great tool for this as well. I definitely use both. Uh this is more of like a highle faster implementation. And then perplexity is more in detail but slower for AI agents to leverage. And Brave is privacy focused and no tracking. So it's not stupid like our AI browsers like Atlas right now. Uh independent index so no Google proxy. And they also have AI search functionality built in that I leverage quite a bit. Next up we got web automation agents. Now the difference between these two is when I do the data extraction like with crawl for the web here. It's when I'm pulling documentation ahead of time to store in my knowledge base. But for web automation, this is when I'm giving tools to my AI agent to pull information from the web live. And so sometimes I'll give my agents a crawl for AI tool so it can extract text from a specific URL live instead of as a part of my rag pipeline. Firecrawl is another good alternative for this. But yeah, crawl for AAI is open source, fast, and so featurerich. And then the one thing it doesn't handle well is social platforms specifically like LinkedIn X, Instagram. Agents that have to work with that, I'll often use something like Ampify or Bright Data. And then for simpler browser automations when I just want to like quickly code up some automations for web testing or using the Playright MCP server for my AI coding assistant to be able to visually validate website changes it makes. I love using Playright. And then Puppeteer and Selenium are good options as well. Well, I used Selenium for years and years and years, but have switched to Playright within the last year here. And so, yeah, it's great multi browser support. It is in my mind the deterministic web automation king. Like I said, the Playright MCP, that's a golden nugget. It's really awesome when you're using coding assistants to work on your frontends. And then last, but certainly not least, I saved browserbase. When I want to take these things further and have an agent control a browser for me live, that is when I will use browserbase. And it is a beautiful tool. I haven't found anything like it. I know there are some alternatives but like man this is the king for me. Managed infrastructure. All sessions are recorded and stored. So you have the stage hand MCP server where you just with natural language describer request. It'll spin up this session for you that has anti-bot detection. It's very secure. It's managed infrastructure. It'll go and navigate websites to find the information that you need. And then you can go back later and actually review the session. So I can play the session live to see what it did to extract the information it needed to based on my request. So awesome platform. And then also they have director which by the way stage hand and director are all built on top of playright and they've extended to work with some of the other tools like puppeteer and selenium. So it's deterministic web automation but putting AI on top of it for browser control. So with director for example I could say get me the latest price for the body fortress protein powder on Amazon. just any kind of web task that I have for it and it'll go and navigate through everything. It'll show me step by step what it did, even screenshots to go along with it. Very, very cool. Gives me the final response at the end. But then the other thing I can do is I can go to the artifacts tab here. I can go to the code and take a look at this. I can actually copy the code directly. So I can bring this into my own codebase, my own automations that I have for testing or just web automations in general. It is an awesome platform and again it's just using these tools under the hood. but applying AI on top. So, an example of one, how I'm using these tools that work well together and then also how I have things in my stack that's very AI first because like I said, I don't see another way these days. It's just so powerful the tools that we have access to. So at this point, I've covered basically everything for AI agents specifically because that is where I focus most of my time, but I still do a lot of full stack development as well, especially because our AI agents still need backends and frontends for a lot of our implementations. Like for example, this is the front-end application that I have built for the Dynamis AI agent mastery course using pretty much all of the technologies that I'll cover with you in the next couple of minutes here. So, a chat GBT like interface here to interact with some multi- aent workflows that I have behind the scenes like this one that you're looking at right here that helps us with SEO research and social media research, competitor research, all in parallel. So, very cool implementation. This is one of the many implementations that I do in the Dynamis AI agent Mastery course. But yeah, I built this pretty much with all of the tech that we're seeing right here. And so, for my APIs, I always use fast API because I like building my AI agents with Python. And so I want to have my API framework be Python as well. Flask is also good, but I think that fast API is more featurerich. And then if you do want to build your agents and backends with TypeScript, then I think Express is fantastic. And then for my database, Postgress like usual. Not going to cover this again. Super super standard. And then for simpler authentication, Superbase has been crushing it for me for a while now. And I know Neon has this as well, but specifically when I've been using Neon, I haven't been using it for authentication. So yeah, Superbase is my go-to. And then also integrates with Ozero when you need to have more enterprise authentication, but you still want to be using Superbase as your database, you can still take advantage of like the roadle security that it offers. But when you have more enterprise needs for uh MFA, universal login with more providers, enterprise SSO with SAML or Active Directory, that's when Ozero is crucial. And there are some other platforms that are fantastic as well like Clerk and Octa. I'm going to be fully transparent here. Ozero, like enterprise authentication is the one thing out of pretty much everything in this tech stack where I I picked Ozero initially and I haven't really tried these other ones. I just know that they are considered to be very fantastic as well. But this is the one that I've been using for the most part if I'm not just sticking with simple superbase authentication. And then for my front-end library, I am just always using React now. It React is just so simple. It's what all of your AI coding assistants will prefer to use and your front-end builders like lovable that we'll talk about in a second here. And then Vit to go along with that for the build tool. And so React plus Vit just leads to very snappy, quick to build, lightweight applications, frontends for things like your agents. I have worked with Nex.js a lot in the past and I still have a lot of respect for it, but especially cuz things have changed so much between recent versions like Nex.js 12, the 13, 14, 15. it keeps like breaking my code. So, I've kind of moved away from Nex.js to be honest, even though I I like it a lot. View is another good option as well. And then for my component library and styling library, a lot of good options, but Shad CN has been great for me. Um, and then Tailwind CSS for styling as well. And so, yeah, not much to say on those. Those are like pretty standard these days and they work fantastic. And then I love using claude code for most of my AIdriven coding, but the one thing it doesn't do the best for me is creating beautiful UIs. And so I like taking advantage of an agentic front-end builder like lovable for example that has a lot of system prompting for their agent builder behind the scenes on how to actually create UIs that are beautiful. So the kind of thing I could just do in Claude Code or my standard coding assistant, but I like using tools like lovable or bolt new or our very own bolt.diy DIY if you want a completely open source version uh for an agentic front-end builder. But yeah, Lovable just has great integrations and their new agent mode that's been crushing it for me recently. Uh and then the last UI library that I want to cover is Streamlit. And so this is like the easiest user interfaces you could possibly make because you build it directly in Python. And so I love using this as a tool to prototype things like my AI agent. So, I still have a nice user interface to chat with the agent, but I don't have to build a full-on React application yet. And so, just defining my UIs and Python code, not having to create a backend front-end kind of connection and things like that. And so, my general process for building an AI agent, you can kind of tell from my tech stack here is I'll start by prototyping the agent in N8N. I'll move it to code, but still have a simple front end with Streamlit. And then when I'm ready, I will create a full React application with something like Lovable. And then that's where I'm really starting to build my MVP. And then for app monitoring and analytics, I like using Sentry. Post Hog is really popular as well. I've used the this and Google Analytics before. Uh but yeah, Sentry just has really great real-time analytics for like everything that you need. And there's working on native AI features, which is why I'm starting to lean towards it over other tools and just all the integrations they have. And then for payments, I've always used Stripe. And so I guess this is kind of similar to Enterprise O with Ozero where I know of these other options like lemon squeezy and paddle. But um yeah, Stripe just has the best developer experience from what I know and fantastic documentation. Next up we've got deployment and infrastructure, everything for getting the code into production. So deployment platforms, things like CI/CD and the testing and AI code review there. And so first up, deployment platforms. And so render is the simplest one that I lean on a lot because of its simplicity. There are a lot of other platform as a service options like fly.io or netlifi. The thing I like the most about render and this is pretty specific. Otherwise these are pretty similar but you can define your infrastructure as code in YAML for render to make your deployments automated. It's just so easy to use. also git based deployments so that you push to a repo to a certain branch it'll automatically update like your front end for example it's free to host frontends and scaling pretty much infinitely with their CDN background workers and cron jobs the one thing I'll say is that if I have a requirement to go more enterprise for a certain client for example because of SLAs's or compliance whatever and I want to use the you know bare bones like AWS or Google cloud I do like using Google cloud uh GCP specifically especially with their serverless functions um it's really really nice you don't really have true serverless this when you're using a platform as a service like render and then when I am running uh GPUheavy workloads like running things with local AI that I want to deploy in the cloud I love using runpod there are some alternatives like tensor doc if you want something really really cheap but not quite as reliable uh lambda labs as well but yeah runpod as far as like super reliable GPU hosting it is the cheapest from what I know and then also spot instances for lower cost and so yeah if you're willing to sacrifice some reliability for cost then you get that as well and it's just like you get your GPUs instantly. There's no queue. It's always going to be available for you at least from my experience. Fantastic platform. And then the last thing for uh virtual machines specifically. So like render they manage the infrastructure for you. If you want to own the machine and manage the machine, the digital ocean is what I use. So for example, hosting the local AI package in the cloud, I do that on digital ocean. I know a lot of others who like using Hostinger with their KVM offering or Hner. Hner is very affordable as well. So yeah, Digital Ocean is a bit of a premium over these two, but very reliable and it's got predictable pricing. I also love the integrations they're starting to add into AI like they have the app platform for managed databases and hosting local LMS. They have things for rag built into the platform. So very featurerich. And then as far as containerization, which is how I'm deploying all of my applications except for some frontends, is I'm using a Docker. So it really is just like the industry standard for deploying applications, creating isolated environments to run things uh to fix the works on my machine problem, right? Like sometimes you host an application on your machine or on some VM in the cloud and you have dependencies there that uh you're relying on those and so when you go to another machine or another cloud provider, it breaks. But if you have everything in Docker, then it's guaranteed if it works in one place, as long as you have the container up and running, it will work in another place. And I know a lot of people like using Podman because of some licensing with Docker that isn't necessarily ideal. So yeah, Podman is a good alternative. Um I've used this a lot before. Actually, my old company that I was working for before I was doing everything with, you know, YouTube and Dynamus, we moved from Docker to Podman because of the licensing cost. It was like hundreds of thousands of dollars for the company. Um but then we ended up moving back from Podman to Docker and uh this was actually after I left the company so I just heard from my team after. So I know that Podman isn't quite as robust as Docker but it is still a good alternative. And then going down to the bottom here for CI/CD I am always using GitHub actions. It's so simple integrated right within my repositories that I also always have in GitHub. It's free for public repos, but uh very generous pricing for private repos. Um and a huge marketplace of actions. And and by the way, it's like it is free for the most part for private repos. I think it's just when you're like adding team members. I I don't know the pricing exactly, but it's very very generous. And yeah, just super easy to get it set up. And AI coding assistants, by the way, are very good at creating the YAML for your GitHub action workflows. They can help you automate things like testing in your GitHub repo. So for Python testing, I'm using Piest. TypeScript I'm using Jest. Like super super standard. Both are really easy to use and help with things like mocking and fixtures that are really important to make your testing reliable. Um and just doing it the right way. Uh and then last but not least in our section here for deployment and infrastructure is AI code review. And I love using code rabbit. And so, for example, within Archon, my open- source tool that I showed earlier for knowledge and task management, every single poll request that we have coming into Archon gets automatically reviewed by Code Rabbit. And man, is it thorough. Honestly, sometimes it's a bit too thorough, but there are ways to customize it within the Code Rabbit dashboard. And the biggest reason that I love using it is because it is completely free for open- source repositories like Archon. So, if it's a public repo, you can get like just infinite AI code reviews that are very detailed completely for free. And it also includes uh security vulnerability detection. And then really quickly, just for some of the open source things that that didn't fit into another section, I love using open web UI as a local LLM chat platform. So, it's like chat GBT, but it's running completely locally. You can add in your own custom agents through functions and pipelines. It's just really featurerich. They got things like rag built right into it. Anything LLM is another good option. And then for completely local web search, I like using CRXNG. By the way, all of these I have them incorporated into the local AI package, including Olama for serving local LLMs. Pretty much any large language model that is open source that you want to run locally, uh you can do it with Olama. And then VLM and light LLM are nice as well. I just find Olama to be the easiest to use and it autoleverages multiple GPUs so you don't have to set up fancy config and stuff. But there also are some things you can configure for quantization like they always have all the different quantized versions of the models. You can configure the context limit for your LLMs to protect your memory. Very very nice. And then for uh HTTPS and a TLS platform so that I can have my domains for my things that I'm running myself. I love using Caddy. And then traffic and engineext are great. I find Caddyy to be the simplest which is why I included it here. But yeah, these are great as well. And I know some people in the Dynamus community specifically that are gung-ho about using traffic. So yeah, it doesn't matter a ton. I just find Caddy to be the simplest. So there you go. That is my entire agentic engineering tech stack. And remember to just take these as recommendations. The most important thing is for you to find what works for you and just generally stick with it. Be willing to be adaptable as well. Because remember, the most important thing is to be a problem solver, not someone who's becoming an expert at specific tools. And so just use these recommendations as a way to fill holes in your tech stack if you're not sure what to use. The last thing that I want to say is that naturally as a content creator, I end up working with some of these teams for the tools that I have chosen to use myself. Browserbased and arcade are two of those. And so I did reach out to them for this video, especially because there's a lot of different ways to leverage their tools. I just wanted to find how they wanted me to showcase their tools. And so thanks to them for working with me on that. And so with that, if you appreciated this video, you're looking forward to more things on AI coding and building AI agents, I would really appreciate a like and a subscribe. And with that, I will see you in the next video.