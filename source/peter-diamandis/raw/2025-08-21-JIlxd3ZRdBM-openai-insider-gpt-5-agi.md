# OpenAI Insider GPT-5 AGI

Published: 2025-08-21

You're like in the middle of the fastest growing but most rapid changing thing in human history. >> We don't always even know what the next model is going to be great at. >> Kevin Vile, the chief product officer >> leads all the the product functions at OpenAI. >> Coming off the back of a storied career in companies like Twitter and Facebook, >> right? I think everybody knows you. For those who don't know me, I'm Kevin Wheel. >> Do you ever look at what the other products are doing and and sort of say that's a great idea or let's not go there. Google is competition for us. They're moving very quickly and building good models. So is Anthropic. So are a bunch of other players. It's motivation for us to also go faster. >> I do have an important last question. Has open AAI fully reached AGI and what is Johnny I delivering for you? >> Oh man, I've been waiting to talk about this since we started. All right, so >> now that's a moonshot, ladies and gentlemen. >> Everybody, welcome to Moonshots. I'm here with my moonshot mate Dave Blendon and we're here at OpenAI headquarters in San Francisco. We're about to have a deep session with Kevin Wheel, the chief product officer of OpenAI. So, let's dive in. Welcome to Moonshots. Kevin, congrats for GPT5. That is a huge milestone. You know, as chief product officer, I can't think of a bigger product to be announcing to the world. >> Yeah. >> Yeah. I It was I mean, probably the most uh anticipated >> Yeah. >> AI launch of all time. the most anticipated product launch. We've been talking about it for a while, but we're super excited. I mean, it we we put a lot into it. A lot of the things that actually people might not even think about like we did a lot of work on the health side. >> So, added a lot of health data because one of the things we see is that people are using chat GBT all the time to ask about health data whether it's, you know, just this thing happened to my kid, what should I do or all all the way to, you know, I just got a cancer diagnosis, here's a bunch of data, how should I think about this? And it doesn't replace a doctor, but it sure is helpful to be to have this super smart thing that you can talk to 24/7. >> I love that part of the launch, by the way. Everyone on Twitter has got different opinions of of that part. I love that part of the launch. >> Were you a big part of scripting that whole day or how did that work? >> Oh, no. We we have a we have an incredible team that puts that together. Um the GPT5 one was fun because we had so much to talk about because it wasn't just health. It's also it's the smartest model we've ever launched. It is an incredible coding model. Um it can do a lot of highly agentic things that you may not see as much in chat GPT but are super uh valuable for developers building on it. You can follow very complex instructions, make lots of different tool calls to different services, integrate things without losing the plot, which has been, you know, a real area that the whole industry is like making models better in. So GBT5 is the best across the board in a whole bunch of areas and we wanted to try and figure out how to show all of these things. Um but we needed a lot longer than our normal, you know, 20-minute live streams >> and the simplicity of one product serves all. It was brilliant. >> Yeah, there's something cool about models that way, right? >> It's like the Google homepage, right, when it was simple search bar, >> right? That's what allowed it to dominate over Yahoo and everybody else. So that simplicity is is amazing. Well, it's also complicated because it's so anticipated. Like you said, probably the most anticipated product launch of of all time, but if you think about an iPhone launch, you know, the features are obvious. >> AI is so open-ended. You know, you can do anything on that stage. And so trying to script that and make it relevant for this, you know, really wide audience, it's got to be >> extra challenging for the team here to to figure out how to do that. >> Well, it's the fun thing about working at OpenAI, too, because we don't always even know what the next model is going to be great at. You know, you have some sense. you can kind of see it coming through the mist at you a little bit, but other times there's something emergent and we're surprised. >> So that's the most interesting thing, the fact that AI's properties and capabilities are emergent and I mean no one predicted any of this two years ago, let alone a year ago, >> right? >> Yeah. So you had you had to have had you in particular got all these comments from the world. >> Yeah. >> Um I mean like >> I was a product of Twitter. I'm used to lots of online >> I mean people are like like super excited and people are critical and so how do you how do you deal with all the feedback and does that feedback actually tie back into how you iterate? >> Oh it totally does >> cuz like I said these these models are so powerful so generic uh there's lots of things that you know we obviously test internally all over the place and we're testing externally in various ways before we launch. Uh but then you you give it to 700 million people and all of a sudden that you know they're testing in all kinds of new ways. >> So we listen a lot. Um people have feedback on Reddit, on Twitter, on LinkedIn, all the ways that you'd expect. We have people coming into our customer support. We have friends who are giving us their feedback >> and then you you're also just looking at the data, right? And the data tells a really good story. We had uh one of our biggest plus upgrades. >> Oh my god, I saw I saw those I saw those numbers. Stellar. But, you know, there also we we heard the feedback. We I think there were a couple things that we didn't quite get right. One is the model's personality was a little bit wooden. >> Um, and so we iterated and shipped and shipped a fix very quickly for that. Um, just like a little bit more of a >> more warm personality. >> Um, that is an interesting subject in itself because there's probably not one personality that will meet everyone's needs. It needs to be fairly sort of dynamic to the individual. I've got to say the voice models and the interactivity as a a voice on OpenAI for me is my favorite of all of the large language models. I mean really it feels natural. >> Um >> oh really cross a tipping point too where if you're on a long drive you can talk to it for hours now. You used to talk to it for maybe a minute or two and then you kind of flip out and move to something else. Now you just go for >> you know infinite time. Yeah, just it's just engaging and interesting. And >> you know, >> to my kids, it's completely natural, by the way, that they would take my phone and just talk to Chat GPT for 20 minutes. >> You're a new dad as well. How How old is your newborn? >> Uh, no, no, we have a Our oldest is 11 and then we have 8-year-old twins. >> Oh, >> so we're we're a little bit into it. We're kind of middle stage. >> I was looking at the photo on your on your baby on >> Yeah. Yeah. That's 10 years old. My WhatsApp photo. Yeah. Okay. So, I mean, you got to admit people were expecting AGI. >> People were expecting GPT5 to be Yeah. I know. I know you will. >> Yeah. >> I'm very confident. Yeah. >> I'm sure you will. So, they had people that were expecting that and then they got actually a very usable product at like half the price point. >> Yeah. >> Which is extraordinary on its own. >> Yeah. Less less than half the price point. And and also what you said a second ago, I really want everybody to understand. Nobody knows what next year's capabilities or even 3 months from now's capabilities will be. A lot of people think like, hey, no one Brown knows exactly what's going to happen next. >> Yeah. >> But it's not true. Like we humanity doesn't know what capabilities will and won't exist because as you scale it's not obvious. >> Are you thinking you're thinking consciousness or what? >> No. Well, no. I I wasn't thinking about >> Noom has a bunch of incredible research ideas and we have some sense and like things are starting to work >> and you have a rough sense of the capabilities but what will that enable? Yeah. >> Yeah. That that's the that's the kind of thing that you only kind of becomes clear as the >> as the model comes together and sometimes not even then to our earlier discussion. Sometimes you launch >> and then you realize the model has these emergent capabilities that you you >> when we were here before I was asking no because I I teach a class at MIT on foundations of AI ventures. How to build an AI company and all these people want to be at open AI because they want to be in the middle of seeing it happen dayto day. Yeah. I said, "Why don't you open an office in Boston where all these, you know, this talent is?" You're like, "At the rate that AGI will arrive, it won't matter. We're not we're not doing that because it won't matter. The timeline doesn't doesn't line up. We're going to keep the headcount small. The AI is going to be the workforce." And by the time we got a building built and got it all populated, it wouldn't matter anyway because AGI will be here. >> So, I don't know if that timeline lines up with what you're seeing because you're on the inside. You're like in the middle of the fastest growing, most rapid changing thing in human history. >> Yeah. it. I mean, we're very we're very optimistic. Um, there's also something magical to being in person to the point about, you know, Boston office. >> Um, >> there is, you know, you're in person, you're like drawing on whiteboards together. It's it's a very researchy culture. >> I keep on telling my team that it's like, you know, >> I want the team to come back together again physically. I want, you know, colllocate as much as possible. Zoom is fantastic, but there's the human nature. One of the questions I'm going to ask you later is what's not going to change in the next 5 to 10 years, right? And I think that human nature is part of it. Every week, my team and I study the top 10 technology meta trends that will transform industries over the decade ahead. I cover trends ranging from humanoid robotics, AGI, and quantum computing to transport, energy, longevity, and more. There's no fluff, only the most important stuff that matters, that impacts our lives, our companies, and our careers. If you want me to share these meta trends with you, I write a newsletter twice a week, sending it out as a short two-minute read via email. And if you want to discover the most important meta trends 10 years before anyone else, this report's for you. Readers include founders and CEOs from the world's most disruptive companies and entrepreneurs building the world's most disruptive tech. It's not for you. If you don't want to be informed about what's coming, why it matters, and how you can benefit from it. To subscribe for free, go to demandis.com/metrends to gain access to the trends 10 years before anyone else. All right, now back to this episode. Here's a question. So, you're constantly creating increasing capabilities within the open AI ecosystem, and you've got to decide how much of that capability to launch to the public and how much to hold back. How do you think about that? because I'm sure you have much more capable models and capabilities than are accessible right now. Um, is that something that's internally sort of constantly you're meteor meteoring it out at a specific rate? How do you think about that? >> Not really. I mean, our mission is to ensure that AGI benefits all of humanity and the way that we do that is to put AGI in people's hands as much as possible. And we believe in this this uh process of iterative development, iterative deployment. So rather than kind of holding it back and then bestowing it, you know, fully formed upon the world, we want to get AI out to people as soon as we feel like it's ready. Yeah. >> And we'll do that early and we'll do it often. We want to do it safely, obviously. So that's that's its own sort of guard. But other than that, like we'd rather put something that, >> you know, we'd rather put something out to people earlier and let them play with it and build awesome stuff with it >> and learn and learn from it >> and learn from it. and then we get their feedback and that helps us build better models. >> It's not a kind of thing where we're like there's obviously a bunch of stuff we have internally that's ahead of what we have launched but that's also stuff that is very much in research mode in development >> and will make its way into models over time. It's sort of the ability to learn to harness it. Um but but we try and put stuff in people's hands because like the fun thing about this world right now I think every service product device we use is going to be reinvented and >> so that answers >> in terms of you know like core model capabilities but what about just raw speed because you know I write code with GPD5 every single day. >> Yeah. >> And you know you watch the lines of code come out and it's it's incredible. I mean as a force multiplier like thousandx >> Yeah. >> more productive than I would be without it. Mhm. >> But I'm watching the lines of code come out and I'm picturing like when you guys are using it internally, it must be many more GPUs blazing fast, you know, lines of code just pouring out of it. Am I Am I right? >> Well, we use we use pretty much the same settings that everybody else does. You're kidding. But, um, that's really just a function of the number of GPUs we have. >> So, uh, I mean, right now we are >> I heard you have a few. >> We do have a few. We have we have a little bit more than a few, >> but we're also completely maxed out at all times. This is one of the reasons that uh we talk about project Stargate where we're going in with a bunch of other groups and building out more than 500 billion dollars of infrastructure. >> It's extraordinary. Computronium covering the planet. >> Totally. I mean just that the more every time we get more GPUs, they immediately get used whether it's, you know, we can take them on the product side and use it to, you know, lower latency or speed up token generation >> uh or launch new products. you know, take a product that's only available to pro users and bring it to plus users or free users or it just means that we can run more experiments on the research side. There's basically infinite demand for GPUs within these walls >> and that's why we're doing so much to build capacity. >> I'm really glad you said that because uh there is a school of thought out there that GPUs will commoditize and it's just so wrong. It's so incredibly wrong. >> We're far from that moment at the very least. >> I think we'll never that will never exist in the world. >> The it's it's one of those things. It's like the internet you know like you every bit every bit that we like lower latency increase bandwidth on the internet people do more things video used to be impossible >> now video is every day because the capabilities are there the network can handle it >> the more GPUs we get the more AI we'll all use >> so last year I made uh I made four trips to India >> uh >> and uh you know population of 1.41 41 billion huge amount of uh of builders there right there massive latent talent for building >> and I heard I saw Sam's uh tweet about building for India and I'm curious >> how do you think about that because I mean India needs that for education needs it for healthcare needs for governance needs it for to help uplift 1.4 four billion people. It's the only thing that's going to do that is how does it enter your mission as a chief product officer? Do you think about that differently from just in general? >> It's a huge priority. Uh I was out there with Sam and a bunch of people from OpenAI. I don't remember four or five months ago. >> Um and the the reception was just incredible everywhere we went. You know, talking to developers, people are using chat GPT, building on top of our APIs. It's, you know, the biggest country in the world. There's so much we can do >> the most youthful also you know one of the things I'm really excited about talk about coding >> today there are something like 30 million developers in the world 30 million people that know how to code >> with a an AI coding model we can give a couple more orders of magnitude of people we can take it from 30 million to 300 million to three billion people >> that effectively know how to code that can create software and when you can create software it's such a general purpose skill you can do You can build personalized tools. You can build all kinds of stuff. And every time you increase something like that, access to a general purpose tool by an order of magnitude, the world changes. So I whether you're talking health or education or just frankly the ability to build software. I think you know this is it's why AI is going to be the biggest transformational force in our lives. And I think in places like India, it's like going to be that much more powerful. >> Yeah. And I mean there are nations that need it more than others and India is most definitely going to be one of the biggest beneficiaries. >> Yeah, we actually just launched uh this morning a uh a paid plan in India just for India. >> Okay. >> Um so it's a it's a much cheaper plan but it gives uh Indian users a lot of access to to chat GPT like 10x more access than you get as a free user. >> Nice. Um but a heavily discounted plan because we're trying to bring as much of the benefit as AI to people in India as we can. >> So how much do you think that's going to unlock a latent talent base because you start in India you think globally there's there's talent everywhere. >> Yeah. >> And a lot of it is is latent. It can't get into a great school. It can't get into a great ecosystem. AI AI is going to be an incredible leveler of that starting with coding. >> So is that is that part of the motivation of going in with a lower price point in India? >> Yeah. There's talent everywhere and there's there's also like hustle and urgency. So, yeah, we want to we want to bring as much AI as we can and we've we've got to we've got limits on GPUs and and all of this. We have to we have to pay for it one way or another, but we want to put this in the hands of as many people as we can. And so, one of the interesting things about OpenAI, one of the things that's different about this company relative to anywhere I've ever worked, normally when you build products, >> you move things behind the payw wall. So there's a product that starts out free and then at some point you make it a paid feature to try and get people to pay, you know, more money for whatever you're building. >> We go the opposite way at OpenAI. Stuff starts in our pro or in plus and so you're paying, you know, $20 a month for it. Our entire goal is to make that a free product because we want to give a more powerful product to more people because we think it makes the world a better place. So if you look at the progression of a lot of our things, deep research started out as a pro feature and then we brought it to plus and now as a free user you can do a bunch of deep research every month. >> So we our goal is actually to just give the most powerful make the most powerful product we can and give it to as many people as we can. >> So you're probably in charge of balancing the the need to create as many GPUs as possible, Stargate and just you need a massive amount of infrastructure and that takes money. >> Mhm. And then you want to balance that against, yeah, but we also want to put this in the hands of as many people as possible as cheaply as possible. That's got to be incredible tension inside the building trying to figure out how do you balance those two objectives. >> Not so much tension actually. You might be surprised because we have just a long-term belief. I I I have a long-term belief that this is going to be we're not going to the idea that we used to live our lives without AI helping us every day is going to feel crazy in a few years. And so if we're building a product that adds a ton of value to people's lives, we're going to put as much as we possibly can available for free, but there are always going to be things that are super heavily, you know, computational and expensive for us that will be in a plus plan or in a pro plan. >> And if we do our job, if I do my job and the team continues to do their job, then th those features are going to be super valuable. They're going to be ever more valuable, right? AI is only going to be able to do more for you. Um, and you know, while you're sleeping, rather than waiting like Chad GPT today is a pretty reactive product. You go there, you ask a question. It can do things for you that would have been crazy two years ago, but you're still asking at first. >> You're still you're starting to prompt, >> but you can you can definitely imagine a world where chat GBT is much more proactive because of what it knows about you. >> You prompt it to be proactive. It's actually proactive. >> Totally. But why isn't it why not think 24 hours a day? you're asleep and it's thinking about what it can do for you, you know? So, there's always more that we can do. >> My favorite model is still Jarvis. I want >> I want Jarvis in my life. It's doing things for me all the time. I still want my AI to do surprise and delight. The doorbell rings and something shows up that I'm not expecting and it says, "I bought this for you cuz I think you'd like it. I heard the conversation you had." >> Yeah. And that for me, that's when when a >> I'll do that for you. I'm going to ask I'll ask Chat GBT, okay, >> what random thing I should buy you and it will show up at your doorstep. We'll see what it does. That's a Peter Demand edition. And >> fantastic. I love it. >> By the way, what what happened to your hand? >> So, um I just had an RFID chip implanted >> today. >> As one does. >> As one does. I was over at I was over at Frontier Towers. That's amazing. >> Over at Frontier Towers, a guy named Cass that runs their sort of longevity and and biohacking. And I had done this. I had, if you can feel it right here, this there's a little ship in there. But cool. >> Um, it's made by a company called Dangerous Things, which is a great great marketing, right? Yeah. But this is the more advanced one. So, I put it so I can open my Tesla with it and like, you know, wave in front of the elevator. >> Wow. >> And Yeah. >> Check out with Apple Pay. >> Exactly. I want my, you know, actually, I will not put my uh my crypto keys on this because then my hand is at risk. >> Yes. >> Yeah. Yeah. Yeah. The the hammer attack. $5 wrench attack. Exactly. Um I'm curious. >> Wait, how big is the chip? >> Oh, it's Yeah. You want to see the photos here? It's >> bigger than you would have thought. >> So, this is the what it looks like, right? >> Okay. >> Uh this is this is they actually put this giant needle in your head about like a straw size of a straw. Make some space and then they slip it in. >> Yeah. >> Yeah. >> Nice. >> It will heal on there. I I'll put this up. I'll put this up on the on the uh video. >> And how how long will the batteries last? Oh, it's not it's not battery. It's a it's a near field. So, basically an electric current comes in after right. So, uh anyway, that was that was fun. It was an hour ago. So, you guys said keep it compressed >> conversations internally. I I have to believe that you I mean OpenAI is like the most progressive but you know between Gemini, Anthropic and Grock and everybody sort of it used to used to wonder would there be a hard takeoff and there would be one company that just takes off across everybody else and it looks like there's really a leveling up continuously across across the pack. >> Do you ever look at what the other products are doing and and sort of say that's a great idea or let's not go there. How do you >> For sure. I mean there's so much there's so much a there's a lot a lot of innovation happening right and there are smart people within these walls and there's a lot more smart people outside of these walls. So we, you know, it's we we watch what other folks are doing. We also look at how people are using our own models and get a lot of feedback about, you know, things they wish they could do, things they love about our models. So I I kind of think of that all as part of the feedback that you take in. >> Yeah. >> But what matters at the end of the day is are we executing because I think we have the best people in the world. We have a very clear mission. People are here because we want to build AGI and we see a path to it. So, like at the end of the day, it's about our own execution, but I think we'd be crazy if we weren't like watching what's happening and trying to learn from it. >> So, I met your EA outside and I asked him, has Mark Zuckerberg called? And uh recently, >> Mark's after researchers. >> Oh, that's got to be crazy. >> I would love to ask you some questions that will help. We have this huge ecosystem of startups that are building AI companies. And, >> you know, it's funny. You you were there when the internet, you know, was everything. And if you're trying to build an internet company, it's pretty obvious that, you know, TCP IP stack isn't going to change. You're going to be right on top of it. It's like, >> compare that to AI today and you're like, wow, it's such a moving target that you're building on top of. >> Oh, yeah. >> And so, if you can help the teams in any way understand like you know, are we going to build our own like windsurf cursor type capability or is that available? Are we going to >> meaning where is OpenAI not going to go that leaves space for the entrepreneurs to go? >> Exactly. Exactly. And I'll give you a case study. So, you know, Mark Orberg, the chairman of MIT, really wanted Sam to come to campus and meet with the president, Sally Cornbluth. And Sam said, "Yeah, I'll come and do that if you introduce me to 50 startups back toback." >> And so, Mark set it all up. And they they did the 50 backto-back meetings. And then >> that's awesome. >> Sam was on stage. But, you know, Sam genuine like Y Cominator background absolutely cares about the startup economy thriving on top of Open AI. So, the mission is right on right in alignment. But then knowing what's going to happen next is harder than anything I've ever seen before. >> Yeah. So any any insight you can give on like >> what's your advice to entrepreneurs wanting to build on top of open AI? You know, we've seen a lot of OpenAI rappers in the past. >> How how what's your advice thought? >> So here's the here's the context that I think is most important. Every single product we use, every single service that we use today, every single device that we use, all of them, you practically all of them were prei. Any of the ones that are at scale were pre- AAI. >> Mhm. >> They're all going to be reinvented. >> It's like adding electricity to every mechanical thing. >> Exactly. It's a really good analogy. Everything is going to be reinvented. >> And you know, sometimes sometimes the incumbents are going to figure out how to do it themselves. if history is any guide not many of them are going to figure it out right and that's that's a huge opportunity for startups for entrepreneurs because we're in this complete transformation so that's super exciting I think it's an awesome time to be an entrepreneur um certainly we're going to try and do some of that reinvention oursel no matter how big we get how many things we do I mean I'm talking everything is different right and it's not just tech it's also the way you inter interact with your doctor is different you So material science is different. So we're only going to be able to do this much. And so our what what we say to the developers is if you're building like right at the at the edge of what the models can do, you're you're so far at the bleeding edge that like the models can't quite do the thing you want, but you can just see little glimmers of hope. >> That's a great place to be building because 2 months from now, we're going to launch a new model and the thing that you've been just barely getting to work is going to sing. And that's going to be awesome. If instead what you're doing is like covering, you know, patching a problem with the current model and you're afraid of the next model launch that we are going to come out with because it's going to, you know, >> disrupt. It's going to it's going to like obviate the need for the thing you're building. Like don't do that. >> Assume that the models are going to keep getting better at a crazy pace and build something that's just at the edge so you're excited about the next model because it's going to make your thing awesome. >> Yeah. Arvin Shernovas over at uh Perplexity talks he calls that AI complete when he was designing the Perplexity business plan. It had to be AI complete >> which I think he just made up. Nobody >> but it means that exactly what you just said. It it rides the wave. It doesn't get swamped by the way. >> Yeah, that's a that's a much more uh concise way of saying what I was saying. >> I I have a question I've been dying to ask you. As the chief product officer, what does AGI look like as a product? >> That's a good question. Uh, >> is it just look like the chat GPT, but it can do anything better, faster? >> Well, I mean, chat is such an interesting um format because it I mean it mimics like how do how do humans communicate? >> Yeah. >> Uh we I can text you, we can write on the keyboard, but I al can also talk and we can, you know, look at each other and and tech like a chat interface kind of gets at that full generality. So it's really powerful as a backdrop, but it's not the only interface. I think when you have AGI, your your model is going to be in real time creating UI on the fly to uh to build the most like economical, you know, sensible solution for the thing that you're trying to accomplish and you're going to have all kinds of software being created and like being thrown away because you can just produce it again in an instant. Yeah, that's the the the vision when it's when you're just talking to it, it's really obvious that it's going to be super empathetic. It's going to it's going to be just but then, you know, you start to see the video generation. You're like, "Oh, wait." >> Yeah. >> Now, now I'm my mind is blown like because it can create scenes for me in real time. It can create images. It can create Yeah. You know, like entertainment, but also if I'm designing something, it can like Jarvis, you know, create the design in thin air. And so now I'm thinking, okay, Johnny Iv is going to be working on something. >> Let's Let's talk about Let's talk about that one second. I always come back, by the way, to the if you've read Ender Game of course. >> You know, like the jewel in your ear. It can see what you see. It can hear what you hear, but it also is super intelligent and connects back to, you know, the information across the galaxy. >> Yeah. >> Like that's kind of I think where we're going. >> Yeah. They lost that in the movie actually. You got to read the book. >> Yeah. >> They So I think we're going to this multimodal world where there's video capturing everything and you're always being seen in your environments and where AGI becomes anticipatory. It knows what you likely want, right? And it's making the world automagical is the term I I use for that. >> So, uh, do I'm just still trying to dig into what does AGI as a product from OpenAI look like. Is it fully anticipatory? Is it just like doing things you don't expect it to be doing? I guess you could turn that feature on. >> Yeah. Yeah. And I think it's also there and I don't even know that we need to be fully at AGI for this, but I think you want you want the product to be taking every whatever AGI is. >> Yeah. Um and and just doing I mean you think about the number of things that you do every day. You wake up in the morning and you have a whole bunch of emails. A lot of those are mechanical probably. Some of them are like ones that you really want to type out every word of response. Most of them are mechanical. They're scheduling. They're responding. I want my AI to have already done all of those for me before I wake up. >> Yeah. >> Maybe every once in a while I need to say, "Yeah, that's right." Or, "I want to edit that sentence." But mostly it's just like, "Be done." >> Yeah. >> Um, and you're going to have that across. How much of your browsing is semi- mechanical? You got to get the thing done. >> Mhm. >> But you actually don't care about reading the words on the page and waiting for things to load and clicking links. You're just trying to get a job done. All of that should be gone. >> Yeah. >> Um, >> but what do you think about the future of media? Because you know one thing that's really interesting about media in general is that everything competes with everything else. >> So you know you don't really think of sports as competing with news but it does because it's it's all competing for mind share >> and clearly AI is going to take a huge amount of our mind share is just so engaging. >> And so you know that's got to come from somewhere that that time and that mind share has to come from somewhere. Do you guys think through like how is this going to affect internet media TV movies all of that >> attention economy? Sure. I mean it probably becomes hyperpersonalized right today. And there there are good and bad things about that. There's something magical to every single person in the US watching the same, you know, two news shows at night. And we don't have that anymore. >> Yeah. >> There's something cool about the shared experience of we can all, you know, the same movie is in the theater for all of us at the same time and we can talk about it. >> But there's also something pretty cool about it. This movie is, you know, totally personalized to me and I'm the only one that it matters to. So I mean you got to think that kind of thing starts to become possible. Also probably though there's always a the sort of you go to extremes. The other extreme is then you value the the thing that was created by humans that much more. >> Yeah. >> It's like sports are the last thing on the the you know the last business model in TV that still really works well. >> Well you're you're an ultramarathoner. You'll still be doing that. I think that >> what's not going to change in the next 10 years. I mean we can list so many things that will. >> Yeah. Well, I think humans are still going to be humans, right? We're still like it us connecting in person is really going to matter. The feel of this is very different. Us doing it here sitting around a table relative to us doing it through, you know, Zoom or something. >> So, that's still going to matter. Uh, you know, a handwritten note is still going to matter. Personal connection is still going to matter. I >> I would think it's going to matter a lot more actually. The way things are you mentioned earlier, you you just love having everybody here in the building. It's just different. >> Yeah. And since you have so many AI force multipliers, you actually don't need regional offices all over the world. And so the the relative importance of of communication inside the team is probably higher than any company you've been in before. >> I I could run my Abundance Summit virtually through the year, but we're five days together in March. >> Yeah. >> And those five days are, you know, just magical in terms of the energy. >> Yeah. >> Yeah. >> So what do you guys think? What what what stays the same and what does AGI look like? I think one thing that after that GBT 5 launch that occurred to me, you know, up until this point, you think about, you know, I had my kids working with GPT2 writing content >> and then GPT3 and then GPT4 and they've been watching this crazy progression. Now it's pretty clear that the AI community is going to try and not change too many things too quickly. Like let the AI become super intelligent. Let it solve healthcare. let it solve, you know, like but don't go rampaging across San Francisco tearing down buildings >> cuz cuz actually that's creating more more problems than good. And it's now becoming clear to me the AI community is really small as a fraction of the world. And the last thing it needs to do is change everything tomorrow, even though it it potentially could. So it's starting to feel to me like, you know, the physical world won't change as much as people might think, while the virtual world will change at warp speed. Mhm. >> I think the importance of purpose >> is still going to be right because one of my biggest concerns about the future of, you know, the end point here >> is when everything is being done for you or can be done for you and you can just sit back and be, you know, a couch potato. >> Mh. >> The thing that's going to make you live in a in a Star Trek universe, not a Mad Max universe, is purpose. >> Yeah. >> Like so that importance and Yeah. >> Yeah. I completely agree with that. I think the I always have a hard time with the futures that people paint when it's like, oh, we're all just going to sit back and, you know, eat grapes and write poetry and receive our UBI because I just I don't think that's what drives us as humans. If you go back and look at we don't have to like, you know, cross the United States on a in a covered wagon. We don't have to to hang our laundry on clothes lines as you know, very much anymore. There's probably, if you go back a 100 years ago, people look at our lifestyle today and they're like, "Oh my god, everything is done for you. what are you talking about? >> Um, but of course we take those time savings and go do more interesting stuff with it. >> Yeah, it's always going to be true. >> It's all about time savings, right? One thing that's true is every single human, 8 billion of us have 7 days in a week, 24 hours in a day, >> right? 365 in a year. And it's what you can do with that time that defines wealth, success, impact, everything. Yeah. >> And AI is the greatest, you know, time multiplier period. And I think it's the most one of the most powerful parts of human nature that we all strive for something bigger than ourselves and you want to leave the world a better place than you found it. And you like that's so innate to humans. It's AI is not going to change that. It's just going to supercharge it. >> So without you know I won't ask you now to tell me what Johnny Ives is is building for you. Okay. >> Uh but uh we are going to interact Yeah. We are going to interact with um >> uh with AI in different ways. So, how do you think about how do you think about that future besides uh it it's been typing and now voice is amazing. >> Mhm. >> Yeah. >> I mean the the the jewel in your ear thing is is the model in so many ways because you don't want take chat GPT, right? It's just one of many AI products that we'll all use. But uh you don't want chat GPT to just like sit inside of a phone app or a browser waiting for you to go there. You want it to be wherever you are. You want it to effectively see what you see um and have all the context that you want to give it so that it can be smarter and act more proactively for you. Um and it shouldn't wait for you to open a phone app to do stuff for you. It should be just sort of constantly chugging away behind the scenes speaking about GPUs, but it should be constantly chugging away behind the scenes taking action for you and saving you time. >> Um so that's going to be much more of the future than today where you like go to a a website and you know ask it questions. C can we come back to GPU for just one second? Yeah. So, >> and let's talk about Stargate, too. >> Yeah. Stargate like so Chase Lock Miller is walking around like he's our MIT classmate alum. Uh and uh you know he's walking around Abalene, Texas with Sam and you know there's concrete and pipes and like just stuff everywhere. >> Yeah. >> And but it's not up and running right that none of the functionality is is delivering yet. Getting closer. Is it getting closer? Is it very soon or is that all secret? >> Yeah. I don't remember what's public and what's not, but I'm we're very excited for that to come online cuz we could use all the GPUs we can get. I'm sure. And and all we know is in the Oval Office there's a $500 billion budget. So it gives us a sense of the budget. But >> why why stop there? >> Yeah. Why why stop there? >> I mean I don't think we will. >> No. >> Yeah. It was about 18 months ago that I partnered with one of my closest and most brilliant friends Dave Blondon to start Link Exponential Ventures. At Link, we manage about a billion dollars of seedstage money based out of Kendall Square in Cambridge right between MIT and Harvard. When Dave and I both graduated from MIT, each of us immediately started companies. But at that age, everything is working against you. You have an idea, you're challenged to raise money, and you can't afford rent. And even with all the accelerators out there, you're competing against thousands of other startups for the same pool of investors. Both Dave and I have spent a big chunk of our lives focusing on how do we inspire and support founders to knock down those barriers, to go big, to create wealth, to impact the world, to build and scale as fast as possible. Especially in today's AI everything world, we're seeing so many companies reaching multi-billion dollar valuations in just 2 to 3 years faster than ever before. Some companies are adding millions or tens of millions of dollars of value in just weeks. So, we started asking ourselves, how do we help these founders go faster and not skip a beat? As an example, a couple months ago, we bought an apartment building adjacent to MIT where a graduating entrepreneur can move in immediately without slowing down their tech build. while they search for a place to live. And so, we're doing everything we can to accelerate builders and their super smart teams. Of course, funding is part of it, mentoring is part of it, connecting them with my personal network of abundance-minded CEOs and investors is part of it. We house 66,000 square ft of purpose-built incubator space, and 26 AI startups call Link XPV their home. And the returns have been amazing. I have nothing to ask, but if you are building a company in the AI era, check us out at link ventures.com. Now, back to the episode. So, I just got back from Brazil. So, I was there delivering five keynotes, talking to entrepreneurs, builders, and uh they're all asking how what will AI what will what will sovereign AI look like for us? How do we make sure we're not passed over, right? Same question being asked probably in India and other parts of the world. how you know speaking to those entrepreneurs and they're extraordinarily passionate. What's the advice to the to the leadership in in those regions, South and Central America? >> I mean, a part of this is why we try and offer everything. I mean, a CHBT is a free product. >> Yep. >> Download it from the app store or on the web. You don't even need to sign in. You can just go and get access to the greatest intelligence the world has ever seen. >> Yeah. >> For free on your phone at all times. And like you said, we launched GPT5. We cut prices dramatically. Like if you look at prices today relative to what you know GPT4 costs when it came out, >> even as models have gotten way more intelligent, they've gotten like a 100x cheaper. >> So you're on this crazy cost curve and we want to keep going because the more intelligence we can put in people's hands, >> the more they can do with it. >> Do you feel like that ever would have happened if Open AI hadn't forced the timeline? because you know you were you've been at Meta, you've been at Twitter, you've seen like if you know if this stuff had stayed inside Google's labs and OpenAI hadn't come into the world and said, "Hey, we're going to make this available right now because right now, you know, Google is throwing it out there the same way OpenAI has." But that's because it's a it's a reaction. >> It's a reaction, right? >> So, you think where do you think we would be if OpenAI hadn't existed in this? Would it all be hidden somewhere still? We wouldn't even have access to it. >> I mean, we shouldn't we wouldn't be where we are, right? Competition is great. as a friend of mine likes to say, capitalism is undefeated. Like this, it's amazing to have competition. And by the way, Google is competition for us. They're moving very quickly and building good models. So is anthropic. So are a bunch of other players. And that that, you know, it it's motivation for us to also go faster. >> Do you remember the moment >> consumers and businesses benefit is great. >> Do you remember the moment in your life when you first said, I want to go work at OpenAI. I need to I need to go get in that building and meet Sam and get there. Uh yeah, I so uh I've known Sam for a bunch of years. Not super close, but just, you know, we were friends. We could text, that kind of thing. And I would call him whenever I was like thinking about going from one job and, you know, doing something next because he's such an incredible thinker and futurist and, you know, connected. >> He's highly connected, but he's also just involved in interesting things. So I'm a physicist by background and um before my previous job is like four or five years ago I'd called him and he introduced me to uh some companies building fusion >> and I almost went and and worked at one of those companies. So I just, you know, periodically would talk to Sam and this last time I called him, he said, "Well, actually, uh, and so, you know, I hadn't even really thought about it." And then I came in, met a couple people and was just like, >> "This is the most interesting thing I have ever seen. Like, I will work for free. Please just let me in the door." >> So you could literally be working on magnetic containment for fus fusion reaction somewhere completely unrelated. >> Pretty amazing, right? Like like 37 venturebacked fusion companies. I would have never imagined. >> Are there 37? Yeah, >> that's I mean I love hearing that. By the way, I'm so glad that there has been a renaissance in deep tech and investment. >> Yeah, it's like you know their their venture back rocket companies and fusion companies. It's like you know okay this stuff is becoming real. >> Yeah, we need more of it. >> Exactly. I How do you how can you possibly keep up with the speed of change? I mean I I I think in your role trying to keep up with how rapidly the tech is progressing. Um how do you think about that? >> Part of it is staying as connected to our research teams as we possibly can. >> Yeah. How big is the research team here? >> I don't know. Um >> order of magnitude >> a few hundred. Yeah. >> Something like that. Um so >> and it's a very it's a very so it's a very independent it seems very independent, right? people can work on a project and and sort of begin to launch features. >> Yeah, it's um I mean there's kind of a spectrum. Parts of the research team are super academic. They're doing like uh you know novel research that may or may not may or may not work out, may or may not uh see the light of day for a while. >> Um because this is such a new field, there's a lot to discover. You're not just productionizing things that somebody else figured out. You got to figure out this stuff from scratch. And then there are parts of the research team that are much closer to product where you know you're taking a model and helping to post train it and making sure that it's good at certain things that are really important for for our customers in various shapes. >> And you kind of have everything in between. Um so it the one of the things that I think differentiates open AI is how closely product and and engineering and research all work together. Because like I said, there are parts of research that are very that are very separate. But the parts that when we work closely together and we get a tight iteration loop from like building model capabilities, turning that into a product, getting feedback, taking that feedback back, improving those model capabilities and iterating that way. Like that's how we built deep research. That's how we build agent functionality. Like the best stuff comes from that. So in your role you know so here's research you know ultra science then here's product features and functions you know this voice this this button then over here you got data centers that do you span all of that as a CPO >> no no uh just the the the products that you use so think the API think uh so Mark Mark is overseeing all the >> yeah Mark Mark leads research um Greg leads everything uh sort of data center infrastructure scaling all that kind of stuff got Okay. >> Yeah, there's a lot going on. So, uh, so we we divide and conquer. >> You know, the feature I'm looking forward to is my BCI connect. >> Oh, yeah. >> Yeah. So, a friend of mine is involved in, you know, merge that was just announced, leaked, I guess. >> So, you know, we have 100 billion neurons, 100 trillion synaptic connections. >> Yeah. >> And being able to have a feature set that lays on top my neoortex. Do you actually do you think that far ahead in your conversation? >> Is Merge, by the way, is Merge doing uh are they going invasive or is it sitting on your scalp or how are they doing? >> I I know the details of the company. I don't know what I can say about it. >> Okay. >> But there are a multitude of companies that are invasive and a number that are external. Uh and there are those that are subranial but above the dura of the brain. So, >> lots of different layers there. But >> I'm super excited about that, too. >> So, Oh, yeah. I mean, >> I would do it in a heartbeat. Would you? >> No. No. Absolutely not. But that's only because well, look, I use AI literally six, seven, eight hours a day. >> Yeah. >> And it's getting so far ahead. There's no there's, you know, the original vision there was I need to increase the bandwidth of communication between my brain and this really slow laptop. >> Uhhuh. >> But now the AI moves so fast that it's clear that I can give it a concept and it can just run with it. And I I haven't had the next concept yet. Like the increasing the bandwidth between my brain and the laptop no longer matters. the AI is just just way too fast. >> So listen, Alex Weezer Gross, who's one of our our friends and partners, was on my stage at the Abundance Summit and he was talking about the importance of coupling like if AI is taking doing a real takeoff and human and humans are linear, can we couple with that? Right? And that coupling is going to need to have this kind of an interface. So here's the question to you. Would you would you do a BCI coupled to OpenAI? >> Uh I would I would personally do it. I would I would personally do BCI. >> Yeah. So I >> like when it's safe, I'll do it in a heartbeat. >> Yeah. I mean, I just I tend to do experimental things in the first place. >> Yeah, I was gonna say, says the man with a RFID chip in his hand. But uh No, I would totally do it. I think it'll be amazing when you can access the world's information, not by like typing into one of these things, but at the speed that you can think. Um and then you have like this. I mean, we will be a different species. It'll be super cool. >> Yeah. And we are going to speciate. Um, and there'll be those who decide they want to, you know, I like it the way it is. I don't want that in my head. And others that I want to see this, I want to understand quantum physics. I I want to have infinite knowledge. I want to be able to be interf like Yeah, I understand what you're saying completely. Like you got the Amish over here and you got the technopiles over there. That's not what I'm saying. I'm saying that when you surround me by monitors >> Yeah. and it's creating things on those monitors at the speed of AI right now. There's no there's no bandwidth increase beyond well I can't absorb any more information than that anyway. I'm at the limit of what I can think about, >> but maybe not with your eyes and not maybe not when you have to type it in to a thing and then, you know, wait for it all. I mean, it's really hard to beat. >> But we've talked about the fact that visual visually you can you can look at an image and get whether the data is correct or not, right? Versus if you have a text, you have to read every line. So anyway, we'll see. We're going to find out. >> Yeah. Well, I guess you you and I will be the the AB test and or we'll be the A and he'll be the B. >> You'll be the A. If you're still alive, you'll be a baby. >> If I'm still alive. Yeah. >> Yeah. Peter's having it done tomorrow. I might wait a year and then we'll see how that goes. >> Yeah. Well, as long as you can upgrade. You want You don't want to get version one and then >> it is true. >> So, you know, you've worked at some amazing companies. Um, you know, I I I love what Planet's doing as well. >> Yeah. >> Putting a layer of imagery on top of the planet. Um but there's I can't imagine that the speed of iteration of products is uh any place faster than it is here. >> Yeah. Nothing in my experience is compared to OpenAI. >> Yeah. >> Uh I thought Facebook and Instagram when I was there moved quickly and they do. >> Yeah. >> But nothing compares to OpenAI. >> Do you feel like uh so you're doing what a 1020 billion capital raise is at 500 billion something like that? I'm just reading the news. I don't want to >> No, you're just reading the news. You tell me. >> Okay. But um do you feel like you know Google's got about 100 billion of free cash flow? You know Amazon's huge and they have massive data centers in advance. Do you feel like there's a vulnerability at the at the raw compute and budget level? >> I mean it's why we are so focused on building out our own capacity. Um they've got big data centers. They've been doing this for a long time. They've built great technology. They also support a whole host of things. Um they also you know they they Google builds a lot of products that we all use. Mhm. >> We build one product. We have one mission. >> Building AGI is existential for us. I think that's an advantage. >> I love that simplicity, right? It really goes back to Google's earliest roots where they were just just a search engine, just a box on a white page. >> Mhm. >> Right. >> There's something, you know, if you're a researcher, there's lots of places you can go work that'll pay you a lot of money. >> But if you want to work at a company that is maniacally focused on getting to AGI, you work at OpenAI. >> Yeah. Yeah. Yeah, I asked I asked GPT how many core researchers are there at Google, >> you know, just just in the AI team core Jeff Dean Demisabas and it's like five six thousand roughly assuming GPD is right. I don't know. >> Um, so it's a much bigger force, but then it feels like >> they're working on protein folding. they're working they're very dispersed in what they're working on and it wasn't clear to me how many just like right down the fairway working toward AGI there were relative to because it feels like you know with that GPD5 launch the coding completely caught up or past everything else out there at at a fraction of the price >> so the momentum seems to be great and so but you know the headcount is got to be smaller >> yeah but that's I mean that's every startup's advantage right agility Yeah, >> it's all about agility. >> Yeah. >> Uh we've had some conversations on on the Moonshots podcast about benchmarks. >> How much do you think about benchmarks? Because it looks like many of the benchmarks are getting saturated >> and reinventing benchmarks. You've created a healthcare benchmark that you use and one of the questions we talked about was creating some benchmarks that are are around AI's ability to solve grand challenges, solve fundamental problems. >> Yeah, I love that idea. >> Yeah. And so like we we called it a series of abundance benchmarks like is it you know and measure all of the AIS against something like it's a proof of work >> right instead of a proof of stake. Yeah. >> Yeah. It's a it's a really interesting thing. It's a really important too because we're we've had all of these different benchmarks that we've used for you know the last bunch of years in AI and they're almost all saturated now. >> That's crazy. Um it it shows how good the models are getting uh very quickly but it also means that we need we need harder benchmarks and there are a bunch of these things that are frontier math and archi and some of these but increasingly we're also looking at these sort of I'll call them softer uh benchmarks which is a challenge in itself but like the the health bench we've got benchmarks that that you know that are around can you build a financial model for a company >> you know can you do Because when you talk about AGI, one of the ways that we define AGI is can you do um can you do economically valuable tasks? >> Sure. >> And you look at what people are doing every day if they're a doctor, a lawyer, a banker, etc. And you're looking at can you do those tasks? >> Yeah. >> But they're also they're also sort of softer. It's not it's not obvious. There's not one way to build a model for a company uh like a financial model. Um there's you could do it in a bunch of different ways. If you're doing a math problem, there is one right way and you can grade it very easily. >> So at the same time as models are getting smarter, we're saturating the things that are sort of easy to grade. >> We're off in these harder problems that are also a little bit tougher to grade. And they don't have to be deep science or anything. You can also look at creative writing. How do you grade creative writing? There's way more than one way to write a story about any particular thing. >> So true. So true. And increasingly important, right? >> Yeah. Yeah, the stuff is running wild in areas where the evals can be built >> and then, you know, it can't run wild in areas where there's no eval because it's there's it's just unable to self-improve. >> But any place you can score yourself, >> I saw some a recent um metric on its ability to predict the future. >> Okay. >> So, I found that fascinating. Right. I mean, there's I mean, this is going back to sort of Azimov's uh you know, work in found in the Foundation trilogy. Like can you is there enough clues out there, right, that we can gather to predict what society is going to do in the next 12 hours or or 12 days or 12 months? >> Uhhuh. >> Yeah. >> Peter wrote a book that the future is faster than you think. I don't know if you read it. It's it's my favorite of the Peter book. There are many great Peter books, but it's my favorite because it talks specifically about concurrent technology that nobody's figured out how to glue together. Uhhuh. >> And you know normally there'll be two or three things like oh we have lithium batteries and we have you know we have control systems let's make EV tall you know two or three things. But with AI >> there are so many things that got cracked in the last 6 months. >> Yeah. >> That haven't been glued together yet into products services or whatever. It's just and it's just accelerating. And you know there there's this flaw in human psychology where something is mind-blowing and then you take it for granted like three days. >> Yeah. Yeah. Totally. >> And then you then you miss the center. You miss the the the mental breakthrough that wait I can glue that together with it. Snapchat is my favorite example. It's like that company 20 billion. Well, John Jarvey from MIT is a >> he's is his favorite story is how he he Evan Evan Spiegel was a roommate of his son. >> Yeah. >> Uh or frat brother of his son at Stanford and he got first look at it and he said that's just too simple. There's no way. >> And then it was a 20 billion dollar IPO. Yeah. his biggest mistake of his investing, probably the only big mistake of his investing career, but it it was like, look, the the phone has a camera. The camera is high resolution. This functionality is just the assimilation of texting and camera. >> Yeah, >> that's all you had to realize. But, you know, those two things kind of grew in parallel and people didn't stick them together. Now, you've got 40 things you can do with AI that you couldn't do just a few months ago that can be glued together in all these different ways. is, you know, all the combinatorics are interesting products waiting to be invented. >> Yeah. And I think where AI is today, if it if it just stopped, if progress stopped where, you know, GBT5, >> you'd still have a complete transformation of society over the next decade. >> So true. >> But it's not going to stop. It's going to keep going and it's going to probably keep going on the same essential exponential and >> Yeah. >> Yeah. >> Yeah. Should uh update the book. Well, the the next the next book that's coming out in uh in March, I'm releasing at the Abundance Summit, is called We Are As Gods, >> and it's a realization that what we do between breakfast and lunch is godlike to our ancestors, >> right? I mean, and we take it so much for granted, but our ability to manifest the future to to literally know anything anywhere, connect with anybody for free. I mean, >> yeah, >> it's crazy. AI is one of the first things the transformation that it'll bring about. Uh and you got to think it's just the beginning. You kind of grow up and you you're thinking back to when your grandparents grew up and you know you're like oh I'm so glad that I'm living at the time that I'm living. So you get all >> best time to be alive. AI is the first time and you look at like what's happening in biotechnology and and all these other things, brain computer implants, and it's the first time I've been like, man, I am jealous of my kids. >> Yeah. >> Because the year60 is going to be so cool. >> Well, you'll be here. >> I mean, I hope I'm here, but >> I mean, come on. This is why >> I mean, the work you're doing, I hope I'm here in 2100, right? Like, >> I mean, it's the reason for me it was, you know, I grew up passionate about space. I wanted to see uh space play out. You know, NASA never did it. You know, Elon's gone heads down and you know, Bezos and others and so it's fantastic. But when I read Ray's book, The Singularity is Near, it was like, "Holy this this convergence of these technologies is going to blow and acceler blow everything away and accelerate it." So, >> yeah, I want to see I want to see the interstellar missions. I I want to see what uploading consciousness looks like. I want to see all of these things. And there is I don't think there's any limitations beyond the laws of physics as we know them of what we're going to be able to do. >> So, >> and it's going to keep accelerating and like yeah >> talking about your your twins are how old now? >> Eight almost and mine are 14. >> Okay. >> And so I think about their future um and I am let's let's you know speaking to the parents listening. How do you think about educating kids today in an age of AI? Um, you know, I'm just livid about the schools that are saying you can't use AI at all in school. >> Oh, yeah. >> It's like, you know, listen, my kids are going to be using it the moment they graduate every place everywhere. >> And I think one of my challenges is that if you give uh a eighth grader, you know, eighth grade homework to do with AI, it's meaningless. But if you give them like graduate level work to go and you know design a starship and and figure it out, I mean that's amazing. That's what we should be doing. >> Yeah. Like assume that chatbt exists and use it to take to make students a learn how to use the technology but b go deeper than they ever would have been able to do in a classroom setting. >> Yeah. >> Like they should emerge stronger with using AI with their education. Actually the best book that I've read on this at least is by Ethan Mollik. Have you ever read his book? It's called um it's called Co- Intelligence, I think. >> Okay, great. >> Short book. It's like a 90 page read. You do it in an hour, but u he's at he's a professor at UPEN. I think he's at Wharton. >> For you guys, >> and uh just a just a great quick read, super practical. The way he uses AI, he he leans into it. He's actually a very good Twitter follower as well. >> Nice. Um, but he's incorporated into his class and has just sort of changed the way he teaches to assume that everyone is using AI and to to use that to take them way deeper into a topic than they would have been able to do and raise the expectations on the final work product as a result. >> Exactly. Right. But and I think that's true for all of society, you know. So, as we get >> to let's forget about a AGI and talk about ASI, right? intelligence is a a million fold or a billionfold more more capable. What do we do with that? All right. And so I was inspired by Star Trek and Apollo. Those two things lit my fuse. And uh I you know my first >> what I call massive transformative purpose was making humanity multilanetary. Built a whole bunch of companies built a university in space and then focused on on other areas. I, you know, as we start this incredible capability, humanity needs to go for these grand challenges. We need to have these epic visions. >> I couldn't agree more. >> Otherwise, we will will fade into insignificance. >> Yeah. There's a um uh Oh, yeah. It's another book that's that I really loved this by Robert Zubran, The Case for Space. >> Yeah, I know. Bob Bob has been a friend for for many many years. Um he he makes this point very eloquently in the in the book about like the human need for frontiers as one of the reasons why space is so important because there are >> you know the bottom of the ocean is kind of still a frontier on Earth but there aren't that many of them left >> and when there's a frontier no matter how you screwed up wherever you live on the frontier you can start again. >> Yeah. Yeah. Space for innovation and refreshing and renewal and like um Yeah. So when do you think that we will be multilanetary? So I listen I well we'll see there's a uh hopefully a Starship 10 launch this Sunday. Um you know Starship will get us to the moon on a recurring basis by hopefully end of 26 definitely 27 and then Mars you know my my guess is boots on Mars by 2030 but there'll be Optimus robot boots on Mars. Um, and then >> and you're limited in your iteration speed there because you only have a, you know, >> you are, but launch once every 18 months, >> but you're going to send robots in advance. You'll send the robots to the surface of the planet. You'll send robots to the asteroids to go and mine materials. And the way I think about it, right, everything at the end of the day is one way or another driven by economics. And everything we hold of value on Earth, metals, minerals, energy, real estate is in infinite quantities in space. >> Yeah. And so, you know, the the Earth eventually will be a crumb in a supermarket filled with resources, >> right? And that's a be that's a beautiful thing. >> How's that going to evolve? Because, you know, Mars is an obvious target now. Everyone's been working on it. >> I like the moon better personally. >> Better than Mars. >> Yeah. I mean, stepping stone or as a place to set up. >> Go start go start a city. You know, there's these lava caves under the surface of the moon where you get protection from radiation. If you fill them with air at 16 gravity, you can strap on wings and you can fly. >> That's awesome. >> I do this. I do this on my foot. It's much fun. >> How How big are the caves? >> Is there a massive cave system? >> There are huge caves. Yes, >> you could build you could have thousands, millions of people in there. >> Uh I don't know that. I mean, I can imagine easily imagine thousands or tens of thousands. And then, of course, the recent announcement that uh NASA's planning to go put a nuclear reactor on the south pole of the moon. Mhm. >> So cool, right? In order to literally hydraulize the ice that's on the South Pole and create water and oxygen and Yeah. So, >> I mean, we're finally living into that science fiction future and it's accelerating. >> Yeah. And hopefully fusion soon. >> And hopefully fusion >> will solve a lot of problems here on Earth and open up new vistas for space. >> So, Sam is like what 2028 for Helon, I think is the current current target dates. and uh and and Cambridge um is coming on in 2030 thereabouts. So, >> it's amazing how, you know, a lot of these things bust loose when there's a single person that's just got an idea and they're incredibly passionate about it. >> Mhm. >> And now with AI as a force multiplier, the odds of those passionate people becoming empowered and actually achieving that mission is so much higher. >> Yeah. >> Than it was 2 years ago. >> Yeah. And then you get the right density of startups and you have competition, you have different approaches, the ability to learn from different approaches and the probability of success grows >> and and just trying to outdo each other and have fun and you could be and in this future like where it really is a Star Trek future instead of a Mad Max future. It's like what what ambitious super cool thing can you go for? >> Yeah. And it used to be just small number of people. It used to be just the kings and the queens and the robber barons could do anything impacting people. Now it's anybody using these tools. >> Yeah, >> it's amazing. So I have a question as a chief product officer. Who who names your models? Ouch. >> Cuz it's like, you know, okay, I'm trying to understand the logic and the rhyme and reason. >> Yeah. Yeah. Yeah. We we take a lot of well-deserved flak for the naming of our models. Sorry. >> Sorry to give you a >> d by the way. No, it's totally fair. We uh we lean into it. Um the the fact that we had both 04 mini and 40 mini at the same time is uh >> something to be proud of >> and then make the user choose if they have any. And then on the other side there's just chat GVD simplicity. >> Yeah, it's good. >> Yeah. You know, in all seriousness cuz I by the way we deserve all sorts of uh flack for that. So um totally totally acknowledged. But one of the reasons that you have that is the philosophy of iterative deployment. We could have waited like you have some new capability like reasoning for example. You know the up until you we launched GPT40 >> and it could do a bunch of new things like you know you could speak to it rather than just type to it. >> It's amazing. >> Yeah. We'd been working on the ability for models to reason, right? To not answer right away, but to to actually sort of think through the problem, try a bunch of different approaches, test them out, you know, just the way you you would if I asked you to do a crossword puzzle or a sudoku or something, right? You would you don't just like spout out the answer. You've got to try things. You're like, "Okay, if that was a that was a, you know, sixletter word starting with a there, but it's got to have a B and this. Okay, it could be that. No, not the A." Right? and you're you're testing hypotheses, refuting some of them, uh accepting some of them, and then kind of moving on. We it took a while to teach the models that it was one of the big, you know, breakthroughs uh from coming from OpenAI. The first model that could do that was 01 >> and it was easier for us and faster for us to launch a model that just did that and like wasn't an ideal model to ask for relationship advice or to you know ask who is the third >> Holy Roman Emperor or whatever like all the sort of normal things that you can ask JGBT. It was easier for it to be a very specialized model. It was very good at like thinking hard about you know scientific problems in particular >> and launching it as a separate model allowed us to iterate faster and allowed us to put to put this thing in people's hands >> and see what they did with it and what they wanted to do and you know what its shortcomings were and where it excelled >> and so then we iterated a bunch that way. So you have GPT4 you have 01 and then O2 and and all that and then you have the mini models which are sort of smaller faster versions of those things. Yeah. >> And GPT5 for us was the moment where we kind of brought all of this stuff together and had one experience. >> Elegant is >> but I expect in the future that we'll have other things that where we have some new capability and we want to test it out faster than we can like integrate it into one massive thing. So I wouldn't be surprised if we have these kind of offshoots again in the future and then we integrate them as they work and we kind of gain mastery over them. >> Yeah. >> Eric Schmidt talks about learning loops. >> Mhm. >> Right. The speed of innovation is the speed at which you get learning. Put it out there, see how people think about it, give you feedback. >> Yeah. >> Yeah. And I mean, especially with these these we're all kind of uncovering what these models can do. >> So, it's especially valuable for us to get it out in people's hands and let them build. >> Yeah. The reasoning was just shocking actually. I don't know if was that true here, too. Like, nobody prior to 01 >> would have thought that chain of thought reasoning was going to be such a huge unlock. >> Yeah. Yeah, I mean it's just he starts with iterative reprompting which just worked far better than anyone ever would have guessed and that evolved into 01 and then 03 and I guess O2 was oxygen. I don't know what happened to O2 that trademark issue something >> trademark. Yeah. >> Yeah. >> But yeah, I'm sure there'll be other offshoots because it because again the capabilities are always surprising like even even the best researchers in the world don't know exactly what's going to come next. So >> So I'm curious. It's interesting right? We we just cruised through the passing of the touring test and didn't notice. >> Isn't it amazing? >> It's crazy. It's like >> it was held up for like 50 60 years as this pinnacle and then we just like whooshed by it. >> What is the effect? People don't talk about it for granted like so quickly and they miss they miss the implications because they're already on to the next. Oh, I took it for granted. Like no, you got to think about what took now. It's it's it's like right here in our hands. >> Will will we pass through AGI the same way? It was like oh yeah, it happened. I think I really think so cuz >> arguably AGI is here. >> It's just unevenly distributed, >> right? And there are lots of ways where the model is way smarter than me already >> and I would never choose myself over the model. >> Mhm. >> And then there are lots of places where the model is definitely not smarter than me yet and I would choose myself. But over time, I'm kind of staying, you know, I'm improving a little bit hopefully, but the model's getting better a lot faster. The the level of water is rising. So, I just saw GPT uh GPT5 Pro >> was measured at an IQ of like 148. >> Okay. >> On the Mensa on the Mensa Noi Mensa scale. >> Wow. >> Uh that's impressive. >> Yeah. I mean, it won a gold medal at the IMO, right? >> Congratulations. >> Was second uh at the >> But one of the programming competitions. I mean, >> I I have to So, it Yeah, I was interesting, right? So I I looked at the IMO the international math olympiad stats and you know the US came in second um and uh I think it's out of how many is that of 36 points I think. >> Yeah 36 out of 42 out of 42 and the US had like between 32 and 36 >> the Chinese team that came in first had perfect score across all six Olympiads. >> Wow. >> I was impressed. So, our podcast mate, Alex Wisner Gross, who's total genius, uh he's been tracking that IMO score as the benchmark for self-improvement because, you know, that solving those problems is very very correlated with with also iterating through the algorithm. >> Yeah. >> So, I think there's a lot of belief now that we're going to go into this really rapid acceleration of capability because of self-improvement until the GPUs run out. Some >> Yeah. Yeah. >> Some But, but the electricity runs out first. >> Well, I think Yeah. interesting because the GPUs are constrained. The electricity won't run out quite yet because we can't make the GPUs fast enough to keep up, >> but the software improvement is unconstrained, right? There's there's this period of time, I think it's coming right now, >> the algorithmic improvement. >> Algorithmic improvement that we swagged it on the podcast at between 100 and,000x, but recently there's some new news coming out that indicates maybe it's even higher than that. Yeah. >> I don't know if you guys have a theory on that internally or not. Like, >> well, there's now there's two dimensions now that we're scaling intelligence, right? one is via pre-train which is kind of the traditional thing and now it's test time. How how long are you willing to give the model time to think and how long can you kind of keep it on track as it does? >> Yes. >> Um so with 01 03 in chat GPT you kind of get you know the model will think for like 60 seconds and then it'll come back and give you an answer. Most people don't want to wait too much longer than that. Deep research though will take sometimes 20 30 minutes to go do a bunch of research and iteratively compile everything that it gets, figure out what it's missing, go back and get more. But there's no reason that you can't have a model think for two days, two weeks, two months, two years. >> You know, Andrew Wilds didn't solve FMA's last theorem by thinking for five minutes. He worked on it for seven years. >> And and we see continued evidence that the longer the models think, the smarter they get, the harder the problems they can solve. >> So I mean there there's this other dimension of scaling that today at least, we don't see any um >> Do you have a whole >> like we see a lot of continued growth there? Yeah, there's a lot of work going on for a custom chip design that's designed by AI to specific. Do you have a whole strategy around that? Are you working with with you know? >> Yeah, that's I mean that's one of those areas where um where you can let the model think and it's a pretty well constrained problem. Yeah. >> Right. There's there's a great simulation that you can climb on and you can run tests and understand if your layout is better than the previous layout. >> Yeah. >> And the more time you give the models to think about it, the more breakthroughs they make. So I I actually I'm with you. I think that's one of the areas where we're going to see I mean we already are seeing real innovation, right? I believe Google has been public about the fact that they've designed their TPUs and improve them with AI. >> You know, we're doing similar things. >> I think if you if you talk to Nom Shazir or anybody over there, the the historically the TPU team has been way the hell over here and the algorithms team is way the hell over there and trying to translate your algorithmic idea into something that the hardware guys understand is just a nightmare. So that's been a very slow process, but now because the AI will do it for you. It'll do the chip design right off your software design. That's going to be the big unlock. And I don't know if it's like this month. It's not It's not more than what >> Oh, I think it's already happening. >> Yeah, >> it's already happening. >> And you have a Do you have a team here doing specifically that? >> Yeah, we're working on our own chips and we would be crazy if we weren't also using AI to improve our chip design and layout and everything. >> Do you have all the manufacturing and fab all figured out too? Is that >> We're working with partners on that for sure. Um but uh but yeah it's it's there's this class of problem where you have a a fairly well it's a it's a specific problem and you have a way that you can grade it in this case you know speed of of the chip that you design >> and in problems like that where you have you have these well specified problems you can just iterate and iterate and iterate and apply arbitrary amounts of GPU and so far I think we're going to see arbitrary amounts of improvement. I I totally agree. It's it's crazy exciting. Is is that fertile area for startups or should they stay away from that because it's just where the big boys play and >> uh I totally think it's fertile area. It takes a lot of technical talent to do it. >> Yeah. >> Uh but but I think that's an interesting spot. I know some startups doing uh some exciting stuff there. Material science and others. >> Yeah. Material science unsung hero and it will be a huge unlock. >> Yeah. >> Yeah. Hey everybody, there's not a week that goes by when I don't get the strangest of compliments. Someone will stop me and say, "Peter, you've got such nice skin." Honestly, I never thought, especially at age 64, I'd be hearing anyone say that I have great skin. And honestly, I can't take any credit. I use an amazing product called One Skin OS01 twice a day, every day. The company was built by four brilliant PhD women who have identified a 10 amino acid peptide that effectively reverses the age of your skin. I love it and like I say, I use it every day, twice a day. There you have it. That's my secret. You go to onskin.co and write peter at checkout for a discount on the same product I use. Okay, now back to the episode. >> Oh, it' be amazing. Yeah. >> And 10 Lieutenant Colonel Wheel. >> Yes. >> June 13th, you're inducted into the Army. >> Yeah. >> Uh >> super excited about it. >> Super excited. Did you go through Army basic training? >> Uh we did a version of basic training. It was kind of an accelerated version. >> I mean, you're an ultramarathoner, so I mean >> probably not. Yeah. So, but you know, we we went and we've uh we've all passed our army fitness tests. >> Um uh so tell us about how did that materialize? You get a call one day. >> Yeah. Uh I got a call from Sham who uh Sham Sankar who leads the CTO of Palunteer. He's been there forever. Um and he and some of the folks uh at the top of the army were thinking about this program. Um >> I mean it's really smart. I mean I was impressed. >> Yeah. And uh I mean kudos to the army for being willing to take a risk on some crazy people like us. >> But I think it's awesome. Um you and by the way I hope it there's four of us today. >> Yes. >> Um so it's myself, it's Sham, it's Bos who's the CTO of Meta and then Bob McGru who used to be the head of research here. >> Um the idea is to bring us in and um you know basically to create a group like bring tech and the military the DoD closer together. Yeah. >> Uh, take a bunch of expertise that you get from, you know, working in the tech industry, a bunch of expertise that you get from being in the DoD and um, and doing all the incredible things that the Army does and merge them together so that because we we will be better together. >> I mean, I imagine the Navy and the Air Force need to do something very similar. >> Yeah. And there's a huge push across the DoD to integrate AI as there very well should be. Like does us no good to have the best models in the world if they're sitting on the shelf. >> Yeah. while the you know the PLA uses inferior models but integrates them everywhere. >> Yeah, no doubt. >> So it's super super important. Um the idea here was >> because there's lots of efforts you know to bring AI across the Palmer Palmer Lucky is a friend and he's been doing an amazing job at >> Oh totally thank God for them. Um but uh but you know you could have done this as a consultant but I think getting us in on the inside first of all I mean wearing the uniform you feel a responsibility. you go hang out with people who are um who are I mean literally giving their lives >> but also just it's such a it's such a incredible institution that you wouldn't get that sense on the outside. I didn't have that sense before you know I respected it obviously but you being on the inside is a different thing. Obviously I have a ton to learn. We're just getting started. Um but uh I think us being on the inside will allow us to to be more effective. Um, and when we go to wherever they would like us to go to help, I we'll have that much more of a sense of how everything works and we'll be a part of the team as opposed to being a consultant from the outside. >> Yeah. >> So, um, you have to go through the whole top secret clearance process and all the background checks and all that. Was that a >> I had one already. >> Did all four of you have it already or? >> Uh, not all of us, but um, but yeah, they had us go through. So then once you're inside, you know, on base, whatever, just access to everything. Is it how's that work? >> I mean, it's still very uh, you know, when top secret stuff is pretty heavily compartmented. So there's a there's a need to know basis for most things. >> Yeah. >> So they certainly don't just, you know, open up everything. But weird, things that are important for us to know, we can know and we can help in deeper ways than if we didn't have that access. >> Is there a schedule where like you you you go once whatever and >> it's a little more ad hoc than, you know, normal reserves duty. here are kind of like a weekend a month and two weeks in the summer. And this is much more um uh just because of the jobs like it's harder to be a weekend a month, but it's also we can go, you know, maybe deeper longer for specific uh things. We're also each going to take our own kind of focus >> that um obviously we have to watch out for conflicts and so um we they've designed our focus areas based on that. What's your what's your focus is that >> one of the things I'm going to focus on is um uh uh like physical performance and how because you can imagine a lot of ways to use AI to monitor and improve physical performance >> for sure >> you know like I've got a Whoop I've got an Aura I've got an Apple Watch >> by the way which gives you better sleep data you think or Whoop >> um you know they disagree and I never quite know >> I know I've got my I've got an eight sleep as well I got one of my best nights sleep last night I got a 94 score on Yes, that was great. >> That's amazing. The one thing mine agree on is I need to sleep more >> and deep sleep more. >> Yeah. >> Yeah. Um let's let's wrap with uh advice for entrepreneurs right now. So, a lot of entrepreneurs, a lot of builders here. Um you know, as a chief product officer and they're building products, how would you h how what what sage advice do you have for them? >> Oh, man. Uh, I think lean into the AI in every way possible and assume that it assume that it will continue on the super sharp steep curve that it's on. >> Um, and if you're >> build just imagine things that should be true and are not possible today. And I think a lot of them are going to be possible to build 6 months from now, a year from now, two years from now. And the people that see that and are building for that future, counting on the models to get there, like that's going to pay off because the models are going to get there. >> Yeah. All right. I I do have I do have an important last question uh for you. Um and uh it's this uh has OpenAI reached fully reached AGI and what is Johnny Ives delivering for you? >> Oh man, I've been waiting to talk about this since we started. >> Really? Okay. >> All right. So, [Laughter] and that's a cut, ladies and gentlemen. So, that's a wrap. Obviously, uh we didn't get information from Kevin that's exclusive on Johnny Ives or AGI as much as I would love to, but hopefully if you're a builder and entrepreneur at home, this was super useful for you. I know it was for me. Every week, my team and I study the top 10 technology meta trends that will transform industries over the decade ahead. I cover trends ranging from humanoid robotics, AGI, and quantum computing to transport, energy, longevity, and more. There's no fluff, only the most important stuff that matters, that impacts our lives, our companies, and our careers. If you want me to share these meta trends with you, I write a newsletter twice a week, sending it out as a short two-minute read via email. And if you want to discover the most important meta trends 10 years before anyone else, this report's for you. Readers include founders and CEOs from the world's most disruptive companies and entrepreneurs building the world's most disruptive tech. It's not for you if you don't want to be informed about what's coming, why it matters, and how you can benefit from it. To subscribe for free, go to dmmandis.com/metats to gain access to the trends 10 years before anyone else. All right, now back to this episode. [Music]