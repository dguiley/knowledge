# Is AI a Bubble Experts Debate

Published: 2025-08-27

MIT study reports 95% of AI pilots are failing. Big firms are running pilots but struggle to scale. Metapree's AI hiring. Is there an AI bubble? >> Sam has a dinner where he says that there could be an AI bubble. >> Well, here's another bubble. Here's another scam that I called out that many people have yelled at me for. >> A new risky bubble could be forming at the same time. >> Absolutely not a bubble. It's the biggest shift in human history. I would argue that in AI we've actually crossed the singularity like the pace of change is faster than we can process it. >> We're about to get general purpose humanoid robots that are running foundation models, but they're going to be running locally at ultra low latency. I think this is an incredibly exciting idea for AI. >> The worst thing you can do is not get on board and and ignore it. That's the worst move you can make. >> This is what's going to help us uh continue on this accelerating curve. The new economy is coming and and some things need to be rethought just for speed. >> Now that's a moonshot ladies and gentlemen. >> Everybody welcome to moonshots. Another episode of WTF just happened in tech here with my moonshot mates Ismael, Dave Blondon, and Alex Wezner Gross. Gentlemen, uh as I like to say to our listeners, get ready to add 20 IQ points this morning. There is a lot going on in the world as usual. >> Oh my god, a crazy amount. >> Yeah, >> we we were in California what one week at OpenAI headquarters and come back and about 50 things have happened that we need to talk about right away. >> It's unbelievable. >> It's you know lit literally the team and I and all of us spend like 20 hours getting the slide deck ready trying to figure out what to put in it, what not to put in it. And you know like last night like we got to add this, we got to add that. >> It's a goddamn full-time job at this point. was ridiculous. >> I tell you, we are we are full boore in self-improvement and singularity mode. The rate at which things are popping now, it's not going to stop either. >> I would argue that in AI, we've actually crossed the singularity. Like the pace of change is faster than we can process it. >> You know, you're talking about like-minded souls here. We're all going to agree on that topic. And it's funny, you know, I I you know, hung out with the family over the weekend, saw my my nephews, and they're just not aware yet. They will be very soon, but it's it's just crazy. But they're watching the pod, so they're they're keeping up. So, let's uh let's accelerate them today. >> Yeah. Well, and I appreciate that. I mean, I the number of people who have reached out and said, "Oh my god, I love WTF. I love moonshots." It's been really heartwarming. And Alex, they love seeing you, too. So, welcome back >> as our fourth here. >> Very kind. Yeah, super excited to be here. >> Yeah, there are a bunch of topics today that are very technical and hopefully you'll be the one guy on the planet who can explain it. So, very much looking forward to that. >> Hey, Salem, you look like you're at a space station someplace. Where are you? >> Uh, I'm at Newark airport, uh, trying to do a podcast, so this is not conducive from an environmental perspective. I found a corner of the airport. Hopefully, it's okay. >> Okay. Well, hopey no one shows up. If they do, just yell bomb or something. >> If I get dragged away, you'll know why. >> Okay. >> All right. Oh my god. All right. Well, let's let's jump in. Like you said, a lot's going on. You know, the very first subject it's the AI war is always AI is accelerating everything. We'll cover that. We'll cover robotics. We'll cover BCI together today. We'll cover a number of different subjects, but uh it's a it's a heavy AI digest and we're going to begin with the latest on GPT5. And Dave, like you said, we were we just recorded a podcast uh with Kevin Wheel, the chief product officer. Hopefully, people are enjoying that podcast. It was really a beautiful setting and uh a lot and then literally a week after we're there everything continues popping. It's great. >> So podcast by the way was absolutely a mustwatch. It was an awesome awesome episode you guys did. >> Yeah. >> Thanks. Yeah, we missed you there so what you guys had really good questions even that even if I wasn't there the questions were really good. I was in the hot tub with my my son this weekend talking about he's at Wayfair right now and I said you got to get into that building. Go to San Francisco. You have to get into that open AI building. History is happening in real time at light speed and you know just find a way to to navigate in there, meet a couple of people. The energy in that building is like nothing else on the planet. >> Yeah. Well, I mean, like it's that way, I'm sure, at the Gemini team at Google and at the team X. >> Yep. >> Yeah. So, here's here's the first article. Um, here's an IQ curve. This is the Mensson Norway test. And by definition, it's a bell curve, and we've got the average human IQ at 100. And I've been watching this. I mean, of all the metrics, uh, Alex, that we speak about, uh, I've been watching IQ just because it's a humanizing effort, right? And here we see GPT5 Pro, uh, come out at an IQ of circa 148, uh, which is pretty damn good. I'm not sure if it's you, Alex, but it's pretty damn good. Uh, I'm hoping, Alex, we can trigger you on a rant about how we we we crossed the Turing test and nobody noticed and now we're we're crossing barriers that would have been unthinkable two years ago and people are like, well, you know, >> it was my mission is accomplished. I I have uh Dave, you you telling me ahead of time what I'm going to say. This is great. Um, yeah. Yeah. No, I I I think this is yet another sign that benchmarks that are based on the average human population are saturating. We're we're running out of sigma on a a bell curve here to to benchmark GPT5 Pro, arguably the strongest generally available model at the moment. And we need, as uh you know, Dave wants a conventional rant. Here it is. We need new benchmarks. uh we need new harder benchmarks that arguably look less like the average distribution of the human population and start to look more like specialist knowledge that isn't generally accessible to uh a test that would be administered to the broad human population. You know, we talked to we talked to Kevin while Kevin Wheel about the idea of an abundant set of uh benchmarks where we're looking for AI to solve the biggest problems in the world and and he liked that. So maybe we'll see some benchmarks. But anyway, it was GPTO3 at like 120 or 136 and we bumped up another 10 IQ points here. And it's going to be interesting when we start seeing IQ points that, you know, are beyond 200 and therefore really immeasurable and not making any sense anymore. >> At some point, uh, one might expect tests like this to to start to factor in AIs. Right now, this is based on the distribution of unaded human individual meatbody brain capacity. What happens when AIs start to merge with humans and the curve itself gets dragged upwards? Uh, we're going to talk about that for sure. That's a fun one. All right. >> I I have my usual rant against this, which I won't get into now, but you know, the neoortex is about the size of a dinner napkin, right? And what happens when AI makes it the size of a tablecloth or a football field? What do we do then? >> We listen carefully. Okay. Uh, here's our our next article. So, AI models hit consumer hardware in 12 months. No. So, using a single top-of-the-line gaming GPU like Nvidia's RTX 5090, which is about 2500 bucks, anyone can locally run models matching the absolute frontier LLM performance somewhere in the next 6 to 12 months. Alex, thoughts here? I I think there are two stories here. The superficial sort of cliched story is that this is about consumer privacy and empowering individuals with personal super intelligence, enabling individuals to to have conversations with chatbots without needing to reach out to a server. I I think that sort of superficial story completely ignores the actual story here which is these frontier models are starting to incorporate new modalities actions in in physical world uh video modalities and the the net upshot of all of this is we're about to get general purpose robots humanoid robots that are running foundation models like chat GPT or its now numerous frontier competitors but they're going to be running locally at ultra low latency. So, so when these curves cross, if they cross, and even if they don't cross, if they come close enough together, this is going to give us GPUs embedded in general purpose robots, ultra low latency that are performing general world human complete AI complete tasks. >> Yeah. And that that's a very very big deal for the consumer experience. You know, talking to your car, talking to your personal robot, having it say intelligent things back to you. I think for industrial use, everyone's going to want the best of the best. They want to go up to that next curve. you know, when you're writing code or when you're trying to design a rocket, you need the best of the best. But when you're trying to interact with day-to-day life, the other sort of 98% of use, it's you're going to have a super intelligence locally that's more than good enough to know exactly what you want, what you want. You know, clean my house, drive my car, all of those things. So, that's imminent. That technology is here right now. There's the other part which a lot of companies don't want to you know give their sensitive data or interactions over to open AAI over to Microsoft over to Google and the ability to run all of this locally and have that capability in your in your phone u you know wherever you want it I think is is super important >> this is absolutely critical because you know even you have MCP where you can do but your queries still go up there so if you're a law firm or an accounting firm or government uh any kind of sensitive government, you don't want your queries being uploaded into the model either. And so this is a huge deal. And I think as we embed it, you know, you'll have a lawnmower having this stuff embedded in it and it'll be having a little LLM checking the weather and when it's going to rain, it's going to be have that much more intelligence in it. >> You know, I just uh reread Hitcher's Guide to the Galaxy with my son Jet and uh I I enjoyed, you know, Marvin the Depressed Robot. I can imagine having a lawn mower, having an attitude about, "No, I don't want to cut the grass today. I'm tired. I did that last week. I want to do something different this week." >> He was so ahead of his time, Douglas Adams. Um, just unbelievable. I'm going to recount my favorite quote from him where he said, "Anything in the world when you're born, we call it normal. Anything that's invented when you're young, that's called a career. And anything invented after you're 35 years old is just bad for the world. It's just bad." Dave, you were saying, >> "Oh, anyone who missed that 1x robotics podcast, go back and watch at least the first 10 minutes of it where Peter's interacting with the robots and they they're, you know, they're a little clunky when they're moving and that'll get fixed very quickly, but they are perfectly vocal when they're talking to you. It's it's just unbelievable. Everything you say understands perfectly and then its reactions are perfect as well. So that part of the interface is just is already >> you know it was interesting when burnt uh burnt borneck the CEO of of 1X said you know we need to have the compute you know you said why do you have the compute in the head why don't you have in the cloud uh and he said well because we can't afford the delay time uh the time for the you know for the electrons to get back and forth from the from eyes to to brain from brain to you know actuators crazy >> that that's it exactly so uh maybe to tie tie a bow on what I was saying earlier. I think this is actually about latency in the long term. Privacy considerations. Yes, sure to first order, but the the reality is I think exactly as See was was gesturing at ultimately you want new knowledge that that isn't already pre-trained into the model that requires reaching out to the world and then privacy gets lost. >> Every week my team and I study the top 10 technology meta trends that will transform industries over the decade ahead. I cover trends ranging from humanoid robotics, AGI and quantum computing to transport, energy, longevity, and more. There's no fluff, only the most important stuff that matters that impacts our lives, our companies, and our careers. If you want me to share these meta trends with you, I write a newsletter twice a week, sending it out as a short two-minute read via email. And if you want to discover the most important meta trends 10 years before anyone else, this report's for you. Readers include founders and CEOs from the world's most disruptive companies and entrepreneurs building the world's most disruptive tech. It's not for you if you don't want to be informed about what's coming, why it matters, and how you can benefit from it. To subscribe for free, go to dmmandis.com/tatrends to gain access to the trends 10 years before anyone else. All right, now back to this episode. All right, let's move on. Uh this is a related subject in that we're things are continuing to move and just again our mission here is give you a sense of how fast this is going and how this is progressing and there have been no barriers no ceilings that have been witnessed. So this is a article that's uh labeled AI scaling laws have been shattered and this is a 32 billion parameter model that broke the paro frontier for AIM 24 and AIM25. Going to you again Alex what are we seeing here? >> Yeah there are overhangs so-called everywhere. uh an overhang in general uh term of art in in the research space in AI is this notion that there are capabilities that are latent just waiting to be unlocked literally waiting to burst out if if only we know where to look for them. Uh so there arguably was a compute overhang when uh large language models and even before LLMs uh some of the earliest machine learning advances were around because we had GPUs lying around from video games just with all this compute waiting to be unlocked for this new purpose. Similarly, uh arguably that this paper here uh which uh announced a new capability that was labeled uh uh branded as data efficient distillation is pointing to the notion that there's a arguably a new class of overhangs that are just waiting to to burst out and unlock new performance uh with relatively low cost. And and this is this idea of distillation. Distillation means taking a larger so-called teacher model and using the teacher not unlike human education to train a smaller student model with the best of the teacher's knowledge. And the core idea from uh the paper behind this chart is that with a properly structured curriculum with a proper data set with uh with a a teacher model explaining step by step the teacher's knowledge and a number of other innovations that it's possible to take a relatively smaller student a smaller costefficient student and have the student demonstrate an enormous jump in capabilities. So I I think innovations in distillation and uh and the organization of training data sets are yet another overhang that's just waiting to to yield 10x 100x improvements in model performance. D >> one of the things that that we always see in these charts is you you see these um logarithmic axes and you say well what's the big deal that red star is not that x-axis is a log scale. So the the red star is 1/100th of the training corpus of the purple star to its right. So the the point here is that you can have the equivalent knowledge with 1% of the compute in the training process. So 100x difference and and so the implications for startups trying to build foundation models that are specific to use cases is unbelievable like you know with a because you tend to get intimidated by open AI and by Google having you know a billion dollar plus training budget but if you can build equivalent capability with 1% of the data and then specialize it with data that's you know specialized in reading X-rays specialized in designing parts for rocket ships then you can actually build a as intelligent as any other intelligence in the world specific model within a reasonable you know budget. >> Awesome. All right. Uh this is one of my favorite articles of our of our day here our conversation is that GPT5 can predict the future. So the concept here is can these systems actually predict economic performance of complex systems or human social societal you know performance of where things are going and uh we're going to find out but these rankings on a brier score uh are pretty impressive. Again Alex how how much credence should we give this? Do you really think we're going to see AI models predicting, you know, sort of the S&amp;P 500 or, you know, the Olympics Olympic winners this next, you know, next cycle? Well, what what's wonderful about predicting uh financial indices like S&amp;P is they immediately get priced into the market. the the the moment that there's an amazing crystal ball for predicting market performance, every financial institution, every quant fund will will race to the extent they haven't already, probably have already uh incorporate these uh these LLMs and foundation models to to trade better. So in in some sense I I think one can separate predicting financial markets where uh as the meme goes uh don't worry it's already priced in uh versus the rest of the universe where I think quite frankly I think this starts to look like Isaac Azimov's psycho history uh for forward prediction and then something I I hear almost no one else talking about what about retroprediction can we predict the past or retrodict the past so much of our past is is a black box to If we can predict the future, can we do a really amazing job of retrodicting what came before us to very high resolution? And I think >> I love that. So you mean like we have data points of ancient Greece and ancient Rome. Can we fill things in? Is that what you're speaking about? >> Exactly. To ultra high fidelity. Some have called this aspirationally quantum archaeology. Could we retrodict the past light cone to quantum level fidelity? And I think, ironically, predicting the past, retrodicting the past might be even more exciting than predicting the future. >> I love that, Alex. That's amazing. I mean, we t you and I have had the conversations about going out, you know, thousands of years out to the light cone and looking back at Earth and being able to see what happened if we had the technology to do that. >> That's right. >> Uh I I think this is an incredibly exciting idea for AI. >> Selene, what are you thinking? It's it's fascinating because you know history is always written by the winners right so the narratives and the types of u publications around history were always coming from one side and just gives us an opportunity to balance the playing field um in my office you may notice uh when I'm there the stack of books behind me called the history of civilization by wer and they spent their entire lives trying to document objectively what actually happened rather than the Romans saying this after they conquered something. So now we can actually go and really fill it in. Be amazing to see how you would rewrite that. You could almost create a Wikipedia of this of what actually happened and let that be a referenceable model in itself. >> I'd go even further and speculate and maybe this is what mature civilizations do. They they attain a certain level of super intelligence and then some fraction of of their compute gets allocated to naval gazing and figuring out where they came from. Dave, what do you think is going to be interesting to predict in the future if we really get this right? >> I was going to ask Alex that question because this benchmark is another one that looks like it's getting saturated in a hurry and the concept, you know, the headline there isn't exactly eye-catching. You know, we used the mean squared error like everyone does, but but what are we what are we going to do next to predict the future in kind of a benchmark way? I mean, there's so many options there, but what do you think is coming? I I think at some point predicting the future starts to become indistinguishable from innovating. So what's you could ask like what's the the next major scientific invention next year? Well, to predict that accurately, you actually have to make the scientific discovery or the invention itself. And I think that's that is as as we've discussed previously, that's the thing that happens the day after super intelligence. We start to get this flood of scientific mathematical engineering discoveries. >> The best way to predict the future is create it yourself. Yeah. >> Exactly. is doing. >> Can you can you lay down a specific challenge? You know, Eric Brenolson has a whole new class coming in soon. If you give them a challenge, they'll rise to it. But what would you want to measurably want to predict that's just fun and cool? >> Uh how how about the the details of of the next 20 Nobel Prize winning discoveries? >> Super cool. >> All right. >> I mean, honestly, >> what happens then >> is where do you invest your money, right? So if you have the ability to predict you know given the fact that you know you can distribute your capital across the board but you know is there a higher likelihood ROI on one specific technology other than you know what we're seeing is uh is digital super intelligence you know put your capital all there for hedge funds I think this will be amazing >> yeah for hedge funds and I I think if you can boil it down into predicting something that's happening in near real time so people can follow it play by play. So here's what the AI says is going to happen next, you know, either in a in a sport or in a news event, you know, and then they can track it because people people love their poly market and they love their cult sheet. And so if you can say here's the here's the AI benchmark and here's the the resolution happening almost instantly. People get super engaged with that. >> You can do that right now with fusion, right? because there's all these things breakthroughs of can we hold the magnetic field for x amount of time and once you can hold it for a certain amount of time it means we can actually extract the energy out of it. Uh and then that's a huge there's a sequence of known steps there that you could probably lay on a timeline and and track in real time to see what happened there. >> Amazing. I'm I'm taking this to Vegas with me that's for sure. All right. GPT5 Pro develops new mathematics. So, I think one of the things that I really want to track on this on this uh WTF podcast uh every week is the breakthroughs in math, in physics, in biology, in chemistry, in material sciences cuz that's really where the juice is going to be. This is what's going to help us uh continue on this accelerating curve. Uh so, the researchers entered an unsolved math problem into GT GPT5 Pro for convex optimization paper. the model producing new proof improving the paper's attempt. Uh GPT5 Pro has had similar breakthroughs in physics, other scientific domains. Alex, you've been talking about this forever. >> Yeah. And I I I want the to to flash the meme, you know, it's here. It's happening. I I I think we're we're just at the very leading edge now of AI starting to bulk solve math, science, and engineering right now. It's a trickle. It's it's sort of an interesting newsworthy moment when uh a a weak improvement arguably over an existing uh optimization theorem was proven independently by GPT5 Pro. It's it's remarkable just this one little proof but the trickle I think is going to turn into a title wave over the next year or so possibly by the end of this year. So I think what this is going to turn into is basically bulk proofs of math, bulk discoveries of in science and bulk inventions in engineering all happening at once which right now culturally we have no precedent for >> Alex I really want to get your like I know for a fact that we're in full boore self-improvement right out of the Leopold Dash and Brunner paper but a lot of people are in denial and you know having worked in neural network research hands-on writing the code for seven years of my life I can tell you that what's happening in this proof is exactly the kind of things you do when you're researching neural networks. And if you can do this, you can self-improve. I'd love you to comment on that just to to reinforce it. >> Yeah. So I my mental model is there's an innermost in computer science, you have this notion when you're trying to make a program faster of looking for the innermost loop. Usually there's there there are loops inside loops inside loops. and you're looking for for sort of the the core engine of a computer program that's the most time-sensitive most critical path part that you want to optimize with with accelerating technology with the singularity if if you like that formulation arguably the innermost loop looks like optimization if if tomorrow we can use AI to discover a better optimizer that offers orders of magnitude improvement there's there's almost no other uh uh there's almost no other juice that's worth the squeeze mixed metaphors uh other than developing better optimizers and developing optimizers that are better at developing optimizers. That certainly smells like the innermost loop of our civilization right now. >> Exactly. Exactly. I'm so glad you said it and and we you know we swag the the software only really rapid improvement at somewhere between 100 and 10,000x and that was in a slide a few podcasts ago but now you saw in that slide we had a couple a couple minutes ago 100x just in the in the data selection you know in in the choice of which so there's 100x on just one of those I think we had like eight dimensions in that slide of improvement that are all multiplicative when you put them together >> but if you have a 100x in just that one then our estimate was if anything on the lower bound. So the implications of that are just mind-blowingly big and and because a lot of the deniers are saying, well look, as we throw more compute at this, we're getting diminishing returns on this curve over here, isn't this all going to slow down? And they're right on that one dimension, but the acceleration in these other dimensions is so much bigger than that slowdown. And that's that's why people are going to underreact. I want to I want to connect back to the previous discussion around history here because imagine you take all of this capability now and apply it to all of the hundreds of thousands of experiments. You know, somebody did an experiment with a thousand lab mice giving them something with a control group or whatever and they're looking for one specific pattern. Now you have an AI that look for all sorts of other patterns that they human being couldn't possibly see. And I think we'll see unbelievable breakthroughs coming just to analyze and do better analysis of the experiments, thousands and the thousands and millions of experiments that have already been done. That will be really incredible. >> See, I mean, I would say that's overhangs everywhere, including an overhang of previous scientific discoveries that are just waiting to be reanalyed and reinterpreted. >> Amazing. Amazing. All right. Uh let's watch a quick video here from Sal Alman about the Indian market for GPT5. Uh again I labeled this slide the land grab. I want to talk about that the idea that you know we have these companies going out to deliver capacity to nations at a time. We've seen this in the UAE. We've seen this in Saudi. We've seen this in other places. All right let's listen to Sam here. India is India is now our second largest market in the world. Um it may become our largest. We've taken a lot of feedback from users in India about what they'd like from us. Better support for languages more affordable access uh much more and we've been able to put that into this model and upgrades to CHPT. Um so we're committed to continuing to work on that. >> So India 1.41 41 billion people uh you know the vast majority 80 90% uh in severe poverty half of those in squalor. It's a nation that needs AI more than anybody for health and education. Uh and OpenAI wants to go there and give it to him. I'm going to link this article with the next one uh which is OpenAI in talks to provide GPT plus to the whole of UK. Uh, and it's not this article on its own isn't critical, but here we have these these companies going in and saying, "Hey, let's give your population, your school kids, your you know, your factory workers, everybody access to our model." Um, and I do think it's it's sort of a land grab. What do you guys think? >> I cannot wait to hear your thoughts on this, guys. Uh, something is going on beyond just the cover story here. I know it for a fact because when we were at OpenAI, not this trip last week, but the prior one about five weeks ago. >> Yeah. >> Uh I I said, "Why don't you guys open an office in Boston? We have like 10 times more computer scientists in Boston than you you have here in Silicon Valley. Incredible talent pool." And they said, "Well, not going to do that because AI, you know, strong AI is imminent and this workforce is going to be all AIS." But then they go a couple weeks later and open this huge new office in New Delhi. and like okay you skipped right over Boston and New York and went right to New Delhi that's not coincidence and if you look at the demographics of India it's the biggest population in the world just crossing China right now but the age is right in that you know 20 to 35 sweet spot is much bigger >> than any other country in the world and also Meror is now at a10 billion valuation you know the Brendan foody story which we can talk about if we have time but but Meror is almost entirely ly operating in India now in terms of recruiting talent for the big AI companies and so something beyond just the it's the biggest market in the world is definitely part of this plan. your thoughts. >> We were talking about overhangs, right? The intellectual overhang in India is unbelievable. Uh I don't know if you know the story of the mathematician Ramanujim um this is a obscure accountant in India 100 years ago and he sent him to Cambridge and he got a lot of racism so he came back died in obscurity and then his widow handed in all his mathematical notes after he died and they found that there's like seven problems in mathematics that have never been solved for like a thousand years and he solved five of them and and so they've got teams of PhD students reverse engineering the notes now how the hell did he do this and this is a epidemic across India. I think the bigger issue here is the infrastructure and energy and bandwidth and so on that need to be solved first because you're you're hitting people at the you know as you mentioned Peter a large number of Indians are below the poverty line right and so this will give them this has a double effect of allowing them to get out of that if you can get them the compute and infrastructure to uh uh scaffold themselves out of there. potential is unbelievable. >> Yeah, I tend to uh to agree broadly that there are several maybe two or three feed stocks to what we perhaps think of as global abundance and abundant intelligence or abundant super intelligence is arguably one of the most important inputs to Salem's point are arguably abundant energy is another one of those feed stocks. If if the world is just drowning in intelligence and energy, maybe materials query whether material scarcity just follows or is resolved automatically with uh energy and uh intelligence post scarcity. I I think everything else all of these global abundance challenges that we speak of I think all of these are downstream of of those those inputs those feed stocks and uh and can be resolved uh and mitigated much more easily. That that's one thought. The the the other thought regarding UK specifically is this starts to look like a prime example if if it were to come to fruition of what one might call um universal basic compute UBC. Uh and UBC maybe call that a special case of larger class of approaches, universal basic services. uh sort of the supply side uh duel of universal basic income and looks the future looks very interesting if if every every citizen of a country is automatically supplied with a basic level of compute. You know, I also think this is going back to your question, Dave, is this is an economic play. You know, if you can go in and get your software in as the basis to a billion people on the planet who are going to use your software to create more income for themselves and get a better life and then be able to pay for your software. I mean, you know, isn't this just an ability for them to, you know, I'm trying to find a good analogy without going to to drugs and giving, you know, giving the school kid a taste of a drug just to make sure that they start to use it. I mean, this will become addictive to entrepreneurs and educators and healthare workers and government workers over the next, you know, over the next few years. And the question is if you start using open AI chat GPT5 and six and so on would you switch or this become baseline for a billion people in India. Let's go to our our next story here and uh this is just part of OpenAI's mission. You know Dave you and I spoke about this when we were up at uh at OpenAI headquarters last week. So, OpenAI's global data center dominance. Uh, opening up two large compute centers, one in Texas, Texas Stargate, up to 5 gawatt capacity. Again, note we're measuring the data centers in terms of power, not numbers of GPUs. Uh, and then the Norway mega center, 290 megaww, uh, in this case 100,000 GPUs powered by hydro. Um, it's interesting. I was in Brazil talking, you know, Brazil is a very energy-rich country and I was saying, you know, look at what's happening with OpenAI in Norway. They're going there for the hydro power. If you want data centers down here, you know, make sure you get your access to power and make it available. Power is sort of the uh, you know, the pheromone that attracts the data centers there. Uh, Dave, what are your thoughts here? >> This came up in a big way when we were at OpenAI last week. Uh because I was asking Kevin Wheel, you know, is there a vulnerability for open AI in this area because the the big competitors have, you know, Google has massive data centers from years of GCP and Microsoft has huge data centers and and Kevin's answer was, yeah, well, Stargate, Stargate will be online. Uh and these are the biggest data centers, biggest investments humanity's ever made. Uh but you know, OpenAI is starting from not having any data centers at all. He did confirm also that they're doing their custom chips. I don't know if that was public information. I guess it is now but but doing custom chips as well. So I think you know all the horses in the race now are running in parallel with huge infrastructure build out buildouts custom chips and then now you know the new thing is the AI designing the chips. >> Yeah. And the data centers um and and soon the energy supply to the data centers and soon predicting which politicians are going to support the data centers. So, you know, it's all AI all the way down. All right. Uh, I want to play a short clip from CNBC here. This is with uh with Sarah Frier, who's the CFO at OpenAI. This is going to sort of wrap up our OpenAI only segment. We'll go to the rest of the AI world in a moment, but here it is. OpenAI hits 1 billion per month in terms of revenue. CFO warns of huge compute demand. And there was a a buzz about uh some remarks that Sam made about is there an AI bubble. We'll talk about that a little bit. >> Developer outcome was actually great. I think our numbers were up something like 50% just week over week on the number of tokens and so on being used. What we see is um tokens in particular for agentic behavior and so on almost doubled. reasoning, which is what I get really excited about because that's a place where I think we've really extended our lead, was up 8x in terms of usage of the reasoning components of the model. So, >> okay. So, tell me about this. Sam has a dinner, >> I believe, out in San Francisco. >> He does. >> And he says at the dinner though, this is the famous dinner in the last week where he says that there could be an AI bubble that's taking place. Do you believe there's an AI bubble? And I say that in the context that there's apparently a secondary sale of some of your private stock uh that some of your employees may be trying to sell at a $500 billion valuation. >> Amazing. So Dave, is there an AI bubble >> there? There's definitely not a bubble. Uh and two things. Sam, first of all, is now in full board downplay mode because he doesn't need to hype it anymore. He's exactly where he needs to be. Uh so he's in full boore downplay mode. We've seen that before. Uh, and then there are plenty of bad investments out there, all kinds of charlatans running around raising capital and those companies will fail and then people will say, "See, I told you it was a bubble." But that's not true. It's that the tailwind is like nothing we've ever seen and everybody is now, you know, whether they know what they're doing or not, they're all kind of jumping on the ship. All the business school people are coming out of the woodwork getting getting involved. And so, yeah, there there's going to be some bad investments and then people will say, "See, I was right. It was a bubble." Absolutely not a bubble. It's the biggest ship in human history. >> And and the worst thing you can do is not get on board and and ignore it. That's the worst move you can make. >> Salem, >> for me, the smack of trying to manage your market cap. You've got employees trying to sell their stock on secondary and you're like, "Oh my god, I'm trying to raise money out here separately. This is a total disaster. I have to do something. I have to say something." So this this is what it looks like for me. Those numbers that Sarah was quoting were the jumps in users and compute right after the GPT5 announcement because there's a lot of conversation, right? Just to be clear, this is the biggest announcement on the planet, right? This was hyped not necessarily by by OpenAI but by the world. Open AAI has got to GPT5, right? The uh the Leopold Ashen Brener paper was like we're gonna have recursive self-improvement when we get there. So hard takeoff and I think everybody was expecting you know again AGI and we got you know a simpler model with lower costs and uh not what was expected but uh the world has responded doubling and redoubling on their use of open AI. Alex what do you think of the GPT5 model? You've been playing with it. Is it is it everything it's been cracked up to be? >> I've been very impressed. Uh, so prior to GPT5 thinking and GPT5 Pro, I 03 and 03 Pro were two of my favorite models and GPT5 thinking especially is increasingly my go-to model for most tasks. It feels like a a credible improvement. And I I also think more broadly on this point of trillions of dollars being spent on data centers, as long as the revenue growth continues to to grow spectacularly, I think the party can continue for capital expenditures on data centers. The way that I Yeah. >> Sorry. There's there's just something else here that's really important, Alex. In our last podcast, you talked about the fact that GPT5 uplifts 700 million people into free models, right? And that that is a massive massive jump. And we're going to just start to see the bailings of that over the next few weeks and months. >> Totally. And and there is a recursive element to it in the sense that if 700 million people, many of whom are now using reasoning for the first time, are using reasoning and then using that to increase their productivity and their intellectual output and their economic output. that starts to recurse back through the system and feed back more more available capital more real capital into the system to build more data centers and empower more people. And it's it's it's a wonderful positive feedback loop. And then hopefully >> yeah really love Alex's thoughts on this downplaying of expectations because we we now have infinite appetite for compute which has never existed in the world before. Like you know if I'm running spreadsheets and I have a billion computers, who cares? Like it's still a spreadsheet. But now all of a sudden it's completely inverted. We have infinite appetite and Sam has to be very careful about what he can promise to the world because it's all completely constrained at the compute level. And so when when you demonstrate like a V3 capacity, people get very excited about it, but then you realize, oh wait, I have way too many users and I can't I can't actually deliver it. So that's I think what's driving the Well, hold on, guys. We're where we want to be. We're capable of doing a lot more than we wanted to show on GPT5 launch day, but if we show it, then people will want it and we just can't deliver it till Stargates online and even then it'll be constrained. >> Yeah. So Dave to to to your point, I I think what we're starting to see emerging, albeit in latent form at the moment, is a a microeconomics of productivity per token. Some tokens are if we assume just naively that every token is equally expensive to to deliver or to generate. Some tokens are much more economically productive than others. So one could imagine uh per token maybe some sort of spreadsheet agent very productive unlocks huge productivity but maybe video generation relatively less productive per token. So I I think we're going to start to see a new microeconomics of token level productivity emerge. Fascinating >> which will be managed by an AI of course. Of course. Of course. Hey everybody, there's not a week that goes by when I don't get the strangest of compliments. Someone will stop me and say, "Peter, you've got such nice skin." Honestly, I never thought, especially at age 64, I'd be hearing anyone say that I have great skin. And honestly, I can't take any credit. I use an amazing product called One Skin OS01 twice a day, every day. The company was built by four brilliant PhD women who have identified a 10 amino acid peptide that effectively reverses the age of your skin. I love it and like I say, I use it everyday, twice a day. There you have it. That's my secret. You go to onskin.co and write peter at checkout for a discount on the same product I use. Okay, now back to the episode. All right, let's go to the AI wars for the rest of the field. Um, and again, just to be clear, we're been speaking about about OpenAI and GBD5, but we're about to see Gemini 3 coming online and then Gro 5 coming online, and it's just a literally leveling up week on week on week. So, in the rest of the field here, uh, Claude Sonnet 4 now supports a million tokens of context. A million tokens is a good amount. I mean, I remember in the early days being able to only put in a few pages at a time. A million tokens is about 750,000 words. Uh 3 to 4,000 pages of text. I asked for an analogy. Uh and uh and GPT5 said, "Hey, it's the entire Harry Potter series." And we're seeing uh what uh Grock probably somewhere in the in the 5 to 600,000 tokens. Uh right now GPT5 is around 250,000 tokens. It was a nice step up. Uh any thoughts on this, Dave? >> Huge, huge, huge, huge. Everybody thinks I don't need that. What am I going to do with a million tokens? Then what happens is the AI is so productive for you. If you write code, if you're writing text, it's so productive that you end up with a massive amount of stuff you've created very, very quickly. and it will forget what you did the day before because you've moved so far in a day. So expanding that context field allows it to remember a lot more of what you're already working on. And you know on the first day you don't care. By day three you care tremendously. I I've written more code in the last two weeks than in the prior 40 years of my life. >> Wow. >> And and it's functional. It's incredible. It's working. It's self-documenting. But now my hard drive, I have literally what almost a terabyte of code and text that I've created in the last week and it needs the context to remember everything that it was already working on. And so it's it's never enough, you know, at the rate that everything's accumulating, it's just never enough. So this this helps a lot actually. >> Is there an upper limit to the context window or is it just purely compute-based and RAM based? There there's no theoretical limit that I'm aware of right now to to an upper limit for context window sizes. I it do you remember when 64 kilobytes should be enough for anyone. It feels like we're we're in we're in that era now where one can reasonably foresee a few years out maybe we'll have effectively infinite context. And when we find ourselves in that world retrieval augmented generation rag maybe that goes out the window. Maybe fine-tuning of models goes out the window completely. Why bother doing any of that if you can just dump your entire company's corpus of knowledge, code, documentation, emails, all into the context window and get effectively free marginal intelligence. This is exactly why Blitzy is signing deals as quickly as they can have meetings because Blitzy has this infinite context window coding capability. And it took them a solid year and a half to develop and and and now it can take an infinitely large context and restructure it to fit into whatever windows available. >> So, so Dave, just take a second because we we're going to be doing a a podcast with the CEO of Blitzy. Take a moment. is a company that you incubated, you supported and link ventures uh basically financially backed. Give me some context and appropriately here on Blitzy. >> Yeah, so Blitzy is uh it's two best friends from Harvard Business School. One who went to West Point who's an organizational genius, Brian Elliot, and Sid Pardeshi, his co-founder, who's a technical genius from India, also came to Harvard Business School. Uh they founded the company together in our office. um is still in it's taking over the office space like a Borg right now. Just eating eating desks. Uh like I said, signing deals as quickly as they can have meetings. Also, their Harvard Business School professor joined the company. So, you know, that's a good sign. And then my youngest son also jumped on board because it's just it's >> what do they do? >> Sucking everything up. So, they uh they write, you know, two, three, four, five million lines of code in a night that's all fully debugged and functional the next day. And the original use case was, hey, there's all this legacy code, mainframe code that hasn't been touched in a decade, incredibly expensive to maintain. Can AI come in and just rewrite all that in a modern language, make it much more efficient, move it to the cloud. And so that's a lot of their bread and butter. But now they're moving on from there into green field like, you know, what what can we create from scratch that didn't even exist in the world before? And you know that the specs for these before you even launch the code the specs become these 100 200 300page documents all written by AI and it's just hard to keep up and even proofread them before you hit the go ahead and build it launch button. Uh so they're they're really on the forefront of building really big things in really short time frames and having the system debug and and fix itself and something fully functional comes out the other side. >> I love that. Love that. All right. Coming out the other side, we have Perplexity making a $34.5 billion bid for Chrome. Uh, you know, you guys really love Perplexity. I've just started using it uh to, you know, look at it, compare it to Google. Uh, so this is a $34.5 billion unsolicited offer. You can imagine you're sitting at Google headquarters and someone comes up and says, "I want to buy your favorite child." Uh, here's 34 billion. So uh the offer is larger than perplexities reported valuation and I guess the concept here is that you know Alphabet and Google have been under incredible regulatory pressures uh that could force them to divest you know to split it up. You're making too much money. You're dominating the field. They are the you know projected winner of the AI race by a lot of the uh a lot of the you know experts out there. So uh thoughts here? I mean, is this is this anything other than a PR play? Sem, >> I think two things. One is a PR play, I think. Second is here's what I predict happens. I think the Trump administration gets involved and says, "Well, you want to give us 10% of Chrome to help you help you keep protective." That's what I think happened. >> Oh, good. Yeah. Well, so what was going on here, though, is um Google was claiming that Chrome can't be split from from Google because it's useless without Google and nobody would want it. and Perplexity wanted to show the FTC, we'll take it and we'd be willing to pay for it. So, it absolutely is not inseparable, irrespective saying, "No, that's absolutely not true." Um, and it's all part of the the grand strategy. I think they would buy it if if Google is willing to part with it. Um, but uh it's it's more, you know, it's not PR, it's it's business strategy trying to keep the FTC active in this breakup. >> All right, I love this next sequence of stories. Uh, so Metafreez's AI hiring after going on a blitzkrieg, we'll use that term, and offering everybody, you know, I haven't gotten the call yet. I'm not sure if you got the call yet, Dave, and I guess I'm not going to expect the call yet from Zuck. Uh but after hiring 50 plus researchers, you know, with salary packages in the tens of millions to reportedly a billion dollars, uh Meta has stopped its hiring. It's reorganizing its AI teams into four groups, AI products, super intelligence, infrastructure, and fundamental AI research. And I'm going to match that story with the following story, which is now Microsoft is is fighting back. It's uh you know uh what's the what's the Star Wars analogy here? Attack of the clones or the Empire Fights Back or whatever it might be. >> Empire Strikes Back. >> Empire Strikes Back. Yes. And Microsoft is the Empire. So Microsoft is now offering multi-million dollar pay packages matching the enormous offers that Meta was making. Uh and it's trying to raid the Meta coffers. Microsoft created an internal most wanted list of engineers and researchers. It's great. then a they a fast-tracked hiring process. Uh and it's been said like if it's critical AI talent, you can receive an offer within 24 hours. Um >> now now I think I think the backstory here, somebody should make a movie immediately about this, but the backstory is really interesting too. There was complete peace and dant for a long time between Apple, Microsoft, Google uh with you know they basically settled in this mode where Apple you keep cranking out the phones. Our Microsoft phone failed miserably. we'll give up on it. Microsoft Office, that's our cash cow. Google Docs, you need to sit there and not threaten Google Docs. And in return, Bing will not threaten Google search. And you know, it's all not all written down anywhere because that would be illegal. But it's clearly stable. And that that lasted for what 10, 12, 15 years of stability. Now they're colliding and fighting like you would not believe over AI. And it is fullbore going after your best people. anything I can do to get a head start on you. But we've never seen all the tech giants going after one brass ring before. And so it's it's really great for startups because we have turbulence and chaos, which is always great for the new guys coming in. >> Dave, that is beautifully said, buddy. That is beautifully said, Salem. >> Well, there's seven big companies and there were seven kingdoms in the Game of Thrones and it feels to me like that is what's going on. I totally agree with Dave. This is full. I mean, I was in at Yahoo and you'd see people very politely moving between companies, but it was very very delicately done and there were back channeling non-stop to kind of make sure everybody was okay with it. It was one of the really great models of co-opetition that was out there. But now the gloves are off. >> Yeah, it is a winner take all. And and here's the other side of the equation. Um, you know, interesting. Here we have unlikely bed fellows. Elon tried to enlist Zuck in a hundred billion bid for Open AI. This is more just uh um this is just soap opera land. I don't want to say anything more than that, but uh that was fascinating. This came out in the news. And then I want to close this segment on on on companies going after each other's employees on this CNBC article. It says AI deals creating zombie startups. And yeah, you you go in and you hire the CEO, the CTO, and you leave the rest of the team there sort of like, oh my god, how do we we just we just took, you know, $100 million of capital and we can't deliver our products. Um Dave, are you seeing this zombie zombie companies? I mean, this is the best friend model. Yeah. >> You know. Yeah. >> Yeah. No, it started with character AI. You know, Google bought Noom Shazir back for wow, six billion or something like that and that started the wave and now it's all the rage. But that Windsurf deal was the real bellweather and because Windsurf was a you know very young company 18 months something like that uh acquired for $3 billion and a huge windfall by OpenAI. Oh wait, Microsoft blocked the deal and then it turned into an aqua hire of the talent into Google. But what did the shareholders get? And that's still in flux. You know, I'm I'm polling our seed stage friends that are in that deal saying, "Did you get ripped off and wiped out by this or you know, what does this mean for the venture world?" Venture capitalists I talked to are not super worried about it. It's not like you it's not affecting that many of their investments, but it's uh you know, it really wrecks the whole venture landscape if this becomes the the de facto standard uh you know, kind of endgame for a great startup. There's a whole meme around the fact that VC the C as a category is going to be ending soon around this with this as one of the U jigsaw puzzle pieces that breaks the whole thing. It's a really bad uh problem from a a VC perspective just because if you don't know what's going to happen with that startup, what are you going to do with it? Especially in a hot area, right? Traditionally, that's where you funded it. >> If somebody comes and licenses the tech and then hires all the people, you're left in it with a shelf. If this becomes systemic, this will be a big problem. >> I mean, part of this is >> expect to see a bunch of lawsuits coming out of this. >> Probably a lot of this is also the antitrust laws, right? There was a lot of challenges in being able to acquire companies. I mean, companies, there wasn't an IPO window for the last number of years. Finally, that's opened up. And so, you try and acquire the company and then antitrust would say, "No, you can't do that." So you'd buy, you know, as with Alexander Wang, you'd buy, you know, 49% of the company and effectively get control of it. And now instead, why don't you just, you know, hire the talent? Um, >> yeah, that that's the deal. It's a you buy 49% non- voting uh so that doesn't trigger the FTC and Hart Scott Readino and all that. Uh and then you move all the best employees over with huge pay packages. And then there's a commercial deal where you license all the technology and that's not disclosed. So you have no idea what's buried in there. It could be like you owe us all of your children for the next 10 generations for all we know. And you just don't know. But that's the standard deal because it doesn't have to go through the waiting period. And so in the race to AI, the big tech companies are are desperate to move as quickly as possible. So this is a really, you know, if you read accelerando, Alex's will recommend Alex will recommend that to you all day long. Manfred man the character in the beginning the whole structure of the way things are created has to get rethought because of the pace of AI and this is kind of the first foray into that new terrain that we're seeing and and just in terms of the venture community you know we we have multiple companies reaching multi-billion dollar valuations in under two years prior to this wave of AI I only counted seven times in the history of the world that that's ever happened now we have three in a single portfolio so the tailwind for venture is unbelievable like bigger than ever, ever, ever before. So I don't want to leave the impression that something's about to fall apart in venture. These are relatively rare deals, but it is the first bell weather on the new economy is coming and and some things need to be rethought just for speed. >> A few quick articles about XAI. So XAI co-founder uh Igor Babushkin exits to launch an AI safety venture amid growing executive turnover at XAI. uh Kaparthi Kaparthi is who headed Tesla's uh AI systems is thought to be coming in for XAI. We'll see if that gets announced. Uh Alex, any thoughts on this one? >> Yeah, I I loved Igor's farewell note regarding XAI. He told his sort of his life story of how he first went into AI because he wanted to solve science. So in some sense now this this is the perfect time now that AI is arguably on the verge of solving science for him to strike out and and fund ventures in that area. >> Nice. Uh I love this article again in the Elon X universe. So Elon on AI increasing birth rate. So here's a tweet. AI is obviously going to oneshot the human lyic system. I love that. Uh and this of course is uh the idea that you know why get married? I have a AI girlfriend. I have an AI uh you know robot. I p but he goes on to say I predict counterintuitively that it will increase the birth rate. We're going to program it that way. So a couple of couple of quick thoughts here. One, we're going to program it that way. Uh your AI is subtly telling you, hey, you should have kids. Hey, go get another girlfriend. Hey, you know, Elon's got 15 kids. You should have 15, too. >> So, I I looked at, you know, when I saw this in the prep for this, I don't understand any one of those statements at all. If any of you could explain any of those, what do you mean AI is going to oneshot the human limit system? How will that happen? This So, any insights from any of you, I would really love it because this makes no sense to me at all. Mhm. >> So I under I I I I think I understand it. I just don't want to comment on it. What what what I what what I what I will say though is putting aside understanding uh any change um AIdriven or otherwise and the birth rate would take decades to be felt in demographics and the changes that we're seeing in in AI otherwise right now are much shorter time scale. The time scale of months to low numbers of years, not decades. So I'm not sure it really ends up mattering either way. Well, so just taking a second to think about the decreasing birth rate. We've tal we've discussed this at length that places like South Korea, Japan, China, much of the world other than what we've seen in India and Africa is below the replacement level of 2.1. Some countries are dangerously as low as.7. Uh and they're literally sublimating. They're evaporating. Uh and the question is why is a birth rate going down? Well, a couple of things. One, women's education is going up, so women are desiring to stay in school more. Number two, you know, as people move into the cities, it's more expensive to bring up kids. Number three, the you know, the child mortality rate is lower. A lot of children in, you know, god, the the the uh rate of ch, you know, number of children per family back in 1950s was on average globally above five. uh and we've seen this precipitous drop because kids are living. You don't need to have an extra two or three kids to make sure they're there to work the farm. So all of these have reduced the uh the birth rate. And the question I think logically is if we do have abundance, if you have access to robots for helping raise your kids, if you have access to AI and uh universal basic income of some sort to help you uh with income, you know, can we shift back to building families instead of having to work or instead of having to, you know, you know, make choice between work and a family? Uh, that might be part of, you know, sort of the Elon Musk counterintuitive approach. >> Well, this this quote I I know Alex needs to keep his reputation pristine because he does a lot of work for government agencies and and also nobody wants to irritate Elon. Uh, but but this this quote from Elon goes hand inand with the one he had a year ago where he said, "Look, of course, AI is going to be smarter than all of us. We're not as smart as as we think we are." And basically the undercurrent here is look, AI is going to be incredibly persuasive very soon. And >> it is persuasive already. It's more persuasive than the best humans. >> Well, so then the the purpose of that last quote, I don't know why he's being so honest about this, but yeah, the natural state is the birth rate's going to plummet to near zero. But the AI, we're going to program it to convince you that it's a good idea to have kids as a way to stabilize human population. That's a danger that's a dangerous message that we're going to program AI to influence you on anything. >> Yeah, exactly. That's why why it's kind of hard to touch this slide, but that is exactly what he means. I don't know why he's saying it because the backlash would be huge, but but he's saying it. >> Uh, all right. I I love this. Musk acknowledges Google's the lead in AI. So uh Elon concedes that Google currently has the highest probability of being the leader in AI citing its massive compute infrastructure and data reserves. Google's dominance is backed by 85 billion in AI related capital expenditures and strategic investments uh like at a 14% stake in anthropic. So we look at all the prediction markets and we saw even in GPT5 when GPT5 was announced we saw the prediction markets all of a sudden flip to yeah Google's going to win the race by the end of August by the end of the year. Uh Alex do you do you believe this as well? I I think this is more a reflection that winning quote unquote is a combination of spending enormous amounts of capital to to build out data center and compute capacity plus default distribution that could come with billions of users from an existing service or from a new service like chat GBT that's that's just emerging and and reaching toward a billion perhaps by the end of this year. that winning combination of both enormous capex for compute and default distribution. That's what I I think this this quote and more broadly the the conventional wisdom right now suggests is what it takes to to win as a frontier lab in AI. >> Salem >> um two things kind of positive and negative here. The positive is I think well the negative is I think as a building kind of cutting edge AI we've always seen that a small team will outperform a big company always and so therefore this is the state the investment entropic and so on is super super smart here but Google itself I don't think will do it it'll rely on some of these uh external teams on the positive their access to compute and infrastructure is so ridiculous and as Dave mentioned earlier now that upper end is simply there's infinite the demand for compute that that may be the reason why they win. >> Yeah, maybe. I think the real race actually under the covers and the real race is between the TPUs at Google and the dojo chips at XAI or Tesla wherever wherever those are theoretically made. The Elon chips because you just signed that $16 billion which is really more like a $40 billion deal with Samsung to manufacture those chips. That's a lot of chips. I think I think you'll get the data centers to put the chips in. The question is the the relative performance of the dojo chips compared to the the TPUs and and the other next generation chips that are getting designed right now. So, uh it's a it's a foot race. It's not he's conceding because he wants to kind of just look don't look over here. I'm going to be working on this over here >> perhaps. So, you know, at the same time that Elon's making that that statement, here is some interesting data. Users are choosing Grock over Gemini. So, in terms of the uh you know, the star rating of of Google Gemini at 4.8 and 394,000 uh downloads or and ratings versus Grock at 4.9 and 502,000 downloads and ratings. Uh it's interesting. Um, uh, maybe, you know, listen, part of this, part of this is that Elon's got the largest megaphone of everybody being able to on on Twitter on X be able to say, "Hey, check out what X can do. Download it here." That works pretty damn well. >> That's exactly exactly right. And he's using it aggressively. And in theory, Google has a bigger megaphone because Google search is actually bigger than X. Uh, but it cannibalizes. So that's, you know, that's the issue. If if Google were to push this as hard as possible, like the extreme would be to say you could only use Google search through Gemini, then they then they'd bypass Grock in a heartbeat, but it would cannibalize their entire revenue engine. And Grock doesn't have that hangup. So So it's really an interesting little balance in this great war that's going on. >> What I love is what I love is the fact that the with the ratings like 4.8 in 4.9, regardless of who's ahead, the the users win. >> Yeah, that's that's a good point. Dave, there's a there's a another point here worth discussing that you and I have discussed in the past, probably not on the on our Moonshots podcast, which is having a celebrated CEO who's out there makes a big difference, right? So, you know, Elon, love him or hate him, uh, and I would never bench bet against him, is out there constantly putting himself out there tweeting, you know, 30,000 times a day. Not literally. And I've been with him at parties and events and he's in his phone, you know, tweeting away and then he'll pop up and have a conversation with you and he's back into his phone. So, you know, it's him to a to a large degree. I'm not sure anybody else is is posting for him, but we don't see that from Sundar. Uh we see this from Sam. Sam is out there as much, but doesn't have the platform yet. I'm I'm certain that OpenAI will eventually create their own platform equivalent. Um we're seeing a little bit uh from Dario and Enthropic. Uh but I think that's so important. You want to speak to that? >> I I totally do. I'm so glad you brought it up cuz you when Elon did Saturday Night Live that was the turning point where you know the definition of what it means to be a great CEO completely flipped on that day because here's the busiest guy on the planet and finding time to go to New York and be the host of Saturday Night Live. Like why why would you make that choice? It's not random, you know? It's not ego. It's part of a strategy. Why why are you doing this? Because it clearly works for recruiting and capital raising. It attracts talent and you it's like you've been saying forever, Peter, you have to have an MTP. You has have to have a massively transformative purpose that improves the world. But just having that purpose and not broadcasting it doesn't recruit. If you have the purpose and you broadcast it, then talent floods to you. Like they're coming to Elon, they're coming to Daario because you're out there and people recognize you. And you know, social media is the cheapest form of media in the history of the world. And if you don't embrace it and get out there, it it's just it's just the way you win as an entrepreneur now. You you embrace it. You get your voice out there. You get your face out there. Again for the entrepreneurs, you know, we have incredible population of entrepreneurs and builders who watch this podcast. And just a piece of advice, you you know, if you are passionate, if you want to change the world, it's not enough to just be on your computer putting out code. Uh either you or your co-founder, uh someone on your team needs to have an outsized personality out there letting people know what you stand for, what you're doing. You know, I think it's critical. All right. Uh let's move on here to our next article. Uh and it's Google drops AI model that runs on 1% battery power. So Gemma 3 270 million uh parameter model. It's tiny smart AI model that runs right on your phone. It can handle 25 chats using just 1% of battery power on a Pixel 9 Pro. So again, this is AI that's being infused power efficiently into your phone and soon into everything that you touch, feel, and use on a day-to-day basis. Uh thoughts, gentlemen? >> I'll chime in and suggest I think this may actually be more instructive regarding what the future of foundation models and frontier models look like than say the the large high parameter multi- trillion parameter sparse models. I I my suspicion is that uh if I had to predict what is the most futuristic possible frontier AI model look like, I think it probably will look like some sort of nano kernel, maybe with far fewer parameters even than Gemma 3 with 270 million. Maybe it'll only have a few million parameters. Maybe it'll dispense with the notion of parameters entirely, but be sort of like um a a small diamond nano kernel of an AI that doesn't have memorized the the world's knowledge. that's all externalized to some external database or knowledge base, but it's it's multimodal. It understands video and text and and audio. It's able to reason, but it's everything else everything else is externalized. And I I I think this sort of gem, this sort of perfect crystallized super intelligence is where all of this ends. >> Fascinating. So, I mean, the the value, the reason we're going to these small models is simply power. Part of it is just the desire to push inference compute to the edge to to enable like local chat bots on phones. Uh but I think ultimately these uh SLM's small language models are going to power the largest uh the largest LLM's frontier models in the data centers as well. The question is what is given that we arrived at this AI revolution by compressing all human knowledge into as small a model as possible. Is there another phase transition where we can compress it even further and figure out what that nucleus of super intelligence looks like? I think we're going to get there in the next few years. >> Well, more importantly, more importantly, this enables that lawnmower checking the weather LLM type thing, right? Because you can embed this into everything. I think that that granularization, it allows you to go up a little long tail of edge cases, which there are an infinite number. >> Sure. Sorry that vision, >> no that that vision that Alex laid out, there are two two parts of it that I'd love to add to. One is that when you take one of these, you know, 1 to 10 trillion parameter mega neural nets, all world history is baked into those parameters. Just a massive amount of information, most of which you don't need. So there has to be this diamonds nugget that that Alex was describing that has to exist where it can call on data, you know, just by looking things up. but it has the same level of brilliance as the big model just doesn't have all that waste. And then the other thing is, you know, if you talk to the liquid AI team, they're really fixated on this notion that these Apple devices have an incredibly good neural processor in every single phone, every single laptop, and it's largely unutilized. And if you can move that diamond nugget into that latent compute that's in, you know, hundreds of millions of devices, it unleashes a huge amount of intelligence, especially during this next kind of 2 to four year window when big data centers are struggling to catch up. So there's a there's a big short-term opportunity in unleashing all that compute in some useful way. And so this this takes advantage of that. >> All right, I'm going to move us along. Next article is from CNBC. The US government takes a 10% stake in Intel. Oh my god, what a story this has been. Right. So, the White House invested I think actually the White House and and the Chips Act actually granted uh Intel $8.9 billion. They're turning that grant into an investment. Uh I'm so curious about what conversations took place in the White House when uh Lipu Tan met with the president. Uh but uh we've seen Intel shock stock you know rise on this news our friend Leopold Ashen Brener who took out call options on Intel has made a killing in that process. Dave you and I were talking about that the day we discovered it. Oh my god what a trade that would have been. >> Well hey watch the podcast. Listen closely. Get those tips. But we we didn't know that that Lipu would be in Donald's office 2 days after the podcast came out. All all we knew is that that Donald Trump had called him to the mat. But remember, we said on that podcast that what'll happen next is Lipu will meet with Donald Trump. And when they come out of that room, you'll know whether they cut a deal or struck a war. If they cut a deal, what you'll see is Lipu stays in place and Trump says really nice things about him. So, go listen to the podcast. we said and that's exactly the way it played out >> and was followed up by the >> call option priced at when when we had that conversation. >> The short-term ones are up 100x from that day when I texted to you. I don't know what Leopold bought, but >> it was at like three cents to call the call option then jumped up to three bucks. >> That would have been that would have been the investment for sure. I'm I'm gonna every after every one of these podcasts I'm gonna call you Dave and say, "Okay, what's the what's the investment today?" You know, this this uh uh this actually was done a little bit by Obama when the 2008 financial crisis hit. The US government gave a huge chunk of money to the car industry to save the car industry and they got paid back in space because it turned into kind of an investment and then they re liquidated. So, this is very similar to that. >> Yeah, >> this is a really big big big big deal for Intel, too. Uh we we met with Greg Lavender, the CTO, back before Gellisinger got fired. Uh and he said, you know, that chips act money has so much crap attached to it, so much baggage because, you know, the way these things go through Congress, they add garbage to it to the point where it's useless. And so they received, you know, $10 billion of unusable money. >> So it was of no value. So you know, Trump being the business guy has restructured that into an equity investment. Now they can just use the money. >> Nice. >> So you you'll see some serious motion coming out of that money. Uh at the same time, we're seeing Amasan from SoftBank signing a $2 billion investment deal. And of course, uh SoftBank also owns 90% of ARM, uh whose chips power 99% of smartphones. And it's, you know, really smart following what MASA is doing here, getting into the chip industry. I don't spend more time on this, but you know, we need we need native chip capacity. Uh we're seeing uh Samsung investing in chip plants here, Intel, uh we're seeing uh our friends from Taiwan coming to the US. A lot's moving here. >> The the other point here is that the Intel is too big to fail, too strategic to fail >> for sure. I mean, that would have been that would have been the obvious conversation as Intel's price. I mean, the question was whether Intel was going to be, you know, broken up and sold to other US companies. Um anyway, uh here from Bloomberg, Apple expands iPhone production in India for USbound phones. So all iPhone 17 models are being built in India, not China. And they're being built by Foxcon, right? So Foxcon that built all of this in China. You know, literally took over the Chinese economy, has moved it now to India. Uh they're going to be shipping this next month. Uh that's a big deal. Slim, >> I'm actually getting on a plane to India right now. So, um, go check the >> Have to go to India to get your iPhone. Did they ship it to you? >> I I want to make sure the production quality is high because in India, cop quality is a bit of a question sometimes. >> Oh my god. Uh, all right. I just It's It's interesting, right? So much pressure to get out of China uh right now. This is wait let me just let me make one more quick point about that. This is a very very big deal because one of the problems that India's always had is this perception that you can't build highquality things there >> and this will shatter that perception. I think a floodgate of manufacturing will start to move to India. uh one of our closing stories on AI and uh we're going to be going into robotics soon. And by the way, I just just mentioned that we're going to be leaning more into crypto. Uh crypto and uh you know, tokenized economies are going to be so important, especially as they connect to AI. So, uh for those of you, we'd love to have you tell us who do you want us to interview in the crypto space. Uh, we're going to be talking about crypto and AI because it's going to just be it's going to drive the future, especially with agents being able to trade and manipulate currencies. Not manipulate currencies. That's probably not the right thing to say. >> That's the AI part. >> All right, let's jump into this article here from CNBC. Albania wants to replace its corrupt government with AI. So, Prime Minister Edi Rama has advocated for AI ministers and prime ministers. Uh, it's a big deal. We've seen a little bit of this in uh in the UAE and a few other governments, but uh this would be a fascinating move. Salem comments. >> I I yeah, I think so. I met Eddie Rama a couple years ago. Um um part of the circle of kind of heads of state that revolve around our exo world. And he did an incredible job turning around uh Tana, the main city as mayor. and then went to the thing and then he found that the the the government is corrupt enough that you need to do something and you can't get it out get out of it in an easy way and coming at it top down with AI is a super smart thing to be able to do. I expect to see this across the board. At the very least, having AIs that are monitoring activities of ministers and so on that that allow you to to reduce corruption, right? Um in Colombia, for example, there was a port being built and all the the government folks bought all the land around the port and then sold it for like a 100x just after that announcement. So, you have that kind of institutional corruption like Congress people, congressmen and women in the US can have insider trading. That's kind of incredible to me that the public allows that. And so this is the kind of thing where AI can oversee some of this and start to make a kind of hacking into that problem space which is huge because the corruption problem is multiple trillion on the global economy. >> All right. So Dave to you here. MIT study reports 95% of AI pilots are failing. Companies have spent 30 to 40 billion in generative AI yet 95% see no financial return. The adoption rate is high. 80% are testing but and 40% deploy but the impact has been low. Big firms are running pilots but struggle to scale. So uh I'm going to hit the next slide as well for a little more data and then let's let's talk about it. So in this study 95% of the failure is is a failure to deliver financial benefit and uh the study goes on to say that it's principally because the companies don't understand how to use the AI tools properly. there's a learning gap. Uh, and companies that buy existing AI solutions succeed twothirds of the time and those that try and build it internally uh do not succeed. Only a third of them do. We saw a huge stock market uh dive as investor fears uh sort of hit on this. Oh my god, is the AI bubble real? Uh and then interestingly enough and I think this is one of the most important things Seem you and I talk about in the exo world is that startups achieve a much better return on investment regarding AI because startups have fewer int entrenched bureaucracies and business processes. They don't force AI uh into existing workflows. They are native in AI and they reinvent their business based on AI. >> I can't stress this enough. We're finding, you know, we've been working with CEOs for the last couple years on this. It is imperative to structure yourself as an exo, right? That's one. There are two failure modes that we see companies, an exo is exponential organization, right? >> Yeah. So, this is the model that we've been pushing though that is now shown. I mean, companies using this model are delivering 40 times the shareholder returns that companies that aren't. I mean, it's just absurdly obvious once you see the model. There are two failure modes that we see. One is people jump into the water without looking where the rocks are. We we came across a medical CEO who had uploaded all the sensitive patient data into Chachi PT and now has huge legal exposure because of that. So that's one bucket of challenges. And the second bigger one is the cultural resistance because you try and people in people inside the company if you don't kind of get the culture right people are scared it's going to take their jobs and it's a mess. So those are two big huge buckets that this is essentially pointing out here. Dave, you're living this world right now with all of the startups settling ventures. >> Yeah, I'll tell you, don't don't read these reports. It's not it's not worth the time. Uh I got to be careful what I say here a little bit because we we all love MIT like no place on the planet. Um uh and the disconnect between the students and the faculty is like nothing I've ever seen. So I work with the students every single day, all the startups, and they are killing it. And you know, in back in 2020, we did this little research thing and about 14 MIT alums all time out of 140,000 alums had become self-made billionaires. 14 as of 2020. Now, you know, Greg Brockman at OpenAI, Alexander Wang just got acquired, you know, by by Google. Um, Mark Chen, I mean, they're everywhere. They're absolutely thriving in the world of AI. >> Correction, Alexander Alexander got acquired by Meta, not Google, right? >> Oh, sorry, sorry, by Meta. Yeah. So, actually, you've got top guys at Meta, OpenAI, and Google, uh, coming out of MIT, in Greg's case, dropping out of MIT, uh, and they're just they're just killing it out there. Uh, meanwhile, the administration keeps cranking out these documents saying, "Slow down, chill out. Why what are you talking about?" Well, what it really is is we didn't invent it. Dennis Assabas got the Nobel Prize. Jeffrey Hen got the Nobel Prize. I wanted that Nobel Prize. This isn't really happening. It's It's something else. We need to actually the the theme in all of these reports is there's still a missing component. Some self-reflective self-thinking thing still needs to be invented to make these truly AI. >> Well, I I I think part I think part of this is we're still early and we see these board of directors, the C, you know, the chairman goes to the CEO, listen, what's your AI strategy? You need to have an AI strategy. and the CEO or the CTO is basically uh just, you know, throwing money at this without properly thinking it through. And it's the impedance mismatch between an established large company that's doing everything they've the way they've always done it for 10 or 20 years trying to, you know, force AI into the mix. And one of the the last points on this chart here is companies are wasting AI potentially by focusing on marketing and sales versus cutting the cost of back-end processes and operations. What are the juices? >> Yeah. So let me let me can I just say a couple so there's only one path to navigate this for companies. The bigger the company, the more this has to be followed. Smaller companies, as you mentioned, Peter, can adapt very well. And and Dave, you're exactly right. This is a a boom that's just going to keep going. So don't slow down. Don't let this affect you at all. For a big company, there's only one model that's going to work. And this is what I've been advising when I talk to the big company CEOs that we talk to. Go create an edge organization that's replicating the functionality that you're trying that whatever you're trying to do. Let's say is building cars. Create an edge organization that's completely AI native >> and start automating use cases bottom up one by one. and and then you create new you create a a young entrepreneur mindset with the youngest employees possible and let them loose with AI copying the functionality of the big and now you have you're essentially doing AB testing and seeing who can do it better and over time over time that you can move the you can deprecate the mother ship and little by little move all of this to to and that becomes a new gravity center over time. Do not try and transform the mother ship. do not >> and that organization the organization on the edge that CEO of that team this is this is locked skunk works equivalent needs to report directly to the CEO don't put them underneath the other organization need to be independent allowed to iterate and do stupid things this is where you know Kodak goes bankrupt even though they invented the digital camera >> and just to plug just one we have solved this problem folks so Anybody struggling with this, just call us. There's a 10- week engagement that we run. In a big company, the default answer if you try anything disruptive is no. Everybody comes very French and they go papla can't do it. Da da da da. We have learned in 10 weeks how to switch that default answer to a yes. So that's all you need to do. But then you need to do the thing on the edge because even if you switch to a yes, you can't get out of the old models quickly enough. You have to do this thing at the edge and let these let the gravity center over time drift to that. I'll get off my soap box. Totally. Totally. >> There's a lot of energy. >> The other thing, the other thing, get your corporate venture fund back up and running. A lot of them like Intel Ventures got shut down just trying to save money. On that prior slide, Google Google owns 14% of anthropics. That's that's a 14 billion position by itself. Like get that corporate venture fund up and running again and then be a development partner for some of these startups. Try and be their first or second customer. Be super supportive of them and invest in them at the same time. And so then that group that you've invested in plugs into your internal edge group that that Selene just described. And that's how AI knowledge is going to actually get into your organization because because the reason these corporate things are failing is not because the AI is failing. It's because you're just throwing it into a group of people that have no idea even how to start using it and they kind of don't want it to take their job away. So they don't have a huge incentive to try to make it work. >> So our next subject here, open evidence gets perfect score on the US medical licensing exam. Uh this is this is huge right so we've we've seen the data before uh a a human diagnostician gets 72% a human plus GPT4 was getting like 74% and GPT4 on its own was getting 92% accuracy in diagnostics here we see another another version of this that uh in the US medical licensing exam again this is to become a full doctor right you've done your internship and residencies uh Open evidence is 100%, GPT5 at 97%. Again, uh this is AI taking taking the lead. Uh pretty extraordinary. >> I I love the I love the fact that 40% of doctors in the US are already using this. That's very inspiring to me. >> Yeah. Uh listen, every doctor is going to be using this or they're not going to be uh a practicing physician. Uh but here's the real topic I wanted to hit on. Uh Sam Alman is getting into the BCI, the brain computer interface race with a company called Merge Labs, who's targeting the combination of gene therapies and ultrasound as a mechanism to be able to read and write onto neurons. And I I know the company well. Uh I don't know what I cannot say. Uh but I'm hoping to have this company on stage with me at the Abundance Summit uh in March. Uh, also super pumped that Kevin Wheel, the chief product officer, has agreed to come on our AI day and be there and talk about, you know, how fast GPT5 and when we'll have GPT6 and what we'll have AGI. But check this out. You know, there's probably, my guess, Salem, uh, I don't know, 20 BCI companies, probably about four or five that I'm I'm tracking that are extraordinarily, uh, effective and and moving rapidly. Again, when, you know, when Ry made his prediction of high bandwidth computer, you know, brain computer interface by 2033, I was like, Ray, you got this one wrong. And no, he got he's got this one right. We're gonna see that. Uh, extraordinary >> man. The man is incredibly annoying. >> Yeah. Incredibly annoying. And and Alex, you know this, you know the team here and you know one of the co-founders as well, right? >> Yeah. No, my fellow Herzfellow ML Shapiro is a co-founder. I'm a huge fan of the company. My sense is this is such a rapidly moving space. I would love to see Merge Labs and all of its competitors deliver high bandwidth BCIs in the next few years. I I think if if that window of the next few years for high bandwidth BCIs isn't achieved, the risk is always that we achieve sort of a pure AI economy that completely decouples from the human economy and BCIs I think are our best hope if they can deliver quickly enough at keeping the human and machine economies. >> And you were on stage with me at Abundant Summit two years ago talking about the idea the importance of coupling, >> right? So either we are on the AI team fully and we are literally coupled and this is the quote from Sam. So Sam Alman says the merge can take a lot of forms. We could all just become really close friends with a chatbot but I think a merge is probably our best case scenario. We've seen this from Elon as well. uh the idea that being able to connect our neoortex to the cloud and being able to ride on top of AI's acceleration versus being left in the dust. Fascinating stuff. All right, let's uh uh this is equally and again this is just showing that AI and science are are going hand in hand. So, OpenAI's GPT4B. And you know, I gave I gave Kevin Wheel a hard time on on his naming protocols for his for his models. Uh, anyway, >> super funny. >> Yeah. OpenAI GPT4B designs proteins to reprogram cells as stem cells. So, you've heard me talk about the Yamanaka factors. This is a Nobel Prize won by uh Professor Nak um professor Yamanaka in Japan funded by Mark Beni off. And what we've seen here is GPT4B being able to come up with uh a new version of these transcription factors that's 50 times more effective. I remember Alex when you when you showed me this, you were like, "Okay, here comes longevity escape velocity." >> That's right. I I want to get out my Ray Kerszswall is right hat for for this one. This is what AIdriven longevity escape velocity at least the the early glimmers of it look like. Uh a generalist model making seemingly a breakthrough discovery in in longevity. And I would encourage everyone if you haven't if you use chat GPT and you haven't played in with the built-in molecular biology support and biochemistry support uh in the form of RD kit RDKIT I would encourage everyone to try for themselves with with any recent form, you know, >> go go go develop a new pharmaceutical. This is now table stakes. >> Well, this is where this is also where Dennis Hosabus has the opportunity to become the most important figure in human history because because he is, you know, he's the Nobel Prize winning dem. He's spending all of his time on the cell simulator and the, you know, just solving all disease, but he's also planted within Google. He has access to immense amount >> of compute and and academic freedom to work on it. Uh and so with that and a Nobel Prize, he's he's in a position to change the world more than anybody. I can't wait to talk to him. Uh but but the the rate of progress here is unbelievable. And his insights will be >> when people say, "Why are you so excited about, you know, longevity and health span extension, it's this it's the impact of AI. It's uh it's nothing else that's going to move the needle this fast." We saw it on my podcast with Dr. David Sinclair. uh his using AI for you know creating these uh these molecular equivalents of what was only possible with gene therapies before. Um >> we we almost need a whole episode dedicated just to the intersection of AI and biotech and protein folding and Yamanaka factors and all this stuff. >> We'll get Demis on this podcast. We'll have that conversation for sure. >> All right, let's close out with robotics here. uh can't avoid uh the robot revolution. The robots are coming uh this year at uh at uh Abundance 360 in March. My plan is to have at least four of these companies, maybe five there with their robots so we can play with them, see them, meet the CEOs. Uh all right. Uh, one of the key things that's going on out of China, we're seeing these robot, you know, clusters, uh, in the United States and principally in China, we've seeing the first humanoid robot games in Beijing. Think hip-hop, soccer, boxing, and track. A quick look at the video. So, here's the hip-hop portion. The end opening. Here's a soccer portion. A little bit of boxing. and uh and track. [Music] >> All right. Uh in in the uh in the track section, uh Unitry, I had Unitry last year at Abundance sets 1500 meter world record, but it's still 91% slower than a human. All right, quick look at the video here. But, you know, the the real news here is what China is doing, right? Creating these these games and creating these clusters around humanoid robots. Uh they're iterating the cycle much faster. It's amazing. Uh >> yeah, >> I think that's the key part. The fact that they're they're making a co-public competition. This feels to me like first robotics uh on steroids in a in a funny way. I will say make a prediction that these type of h robotto robot games will fail just because we we watch the Olympics for the human factor not for the speed of how somebody ran. So that's my prediction. >> Yeah, that's probably a good prediction. >> I think the higher level topic is really important though. Benchmarks are critical for inspiring people to keep moving forward and this is a form of benchmark. Yeah, you're right. It'll come and go, but there'll be some other benchmark. And as long as you're inspiring people to show off what they can do and compete, then this thing is going to drive forward very quickly. >> Yeah. All right. Uh, you know, I I remember seeing this. Remember Scott Hassan's company on robotics? Um, >> yeah. They spent forever trying to get a robot to fold laundry. >> Yeah. And and here we go. And uh this is our friends at figure AI. This is figure 2. Uh and this is fully automated. This is not teleoperations, which is really important point to make. Uh and here we see it folding laundry. >> I still think there's a human being in there. >> Well, they said it's not, but Oh, you mean inside the robot? Okay. Uh and I I found this fascinating as well. This is Hel figures Helix. And again, here we see a robot company, in fact, every robot company we've seen that had been partnered with a frontier model firm has started building their own AI models. Figure is no exception. Uh Brett Adcock said, "We're building Helix, which is their sort of uh AI for navigating the physical universe." And here we see figure two walking through a very rough terrain in a very human-like fashion. I mean this is pretty extraordinary >> you know >> also you remember when we were talking to Bern Borick a couple weeks ago at 1x Robotics we said how do you debug whether it's physical or mental that's not working when it has a mistake and he said well we have a tea operator try and do it you know with their hands or with their own feet and that tells us if the robot can do it or not and then if if the robot could do it then we know it's in the brain if the robot can't do it then we know it's in the robotics and the in the gears But you can see in that in those videos that that's reaching the end of its life cycle because you know when it's folding laundry there's no tea operator that can be moving the the hands remotely at that speed and dexterity. Uh, so he >> he mentioned that when we interviewed him. It's >> Yeah. Go ahead, Dave. Sorry. >> No, he mentioned that when we interviewed him that that he was, you know, right at the edge now of where that mode of debugging was going to continue to work cuz the robots are getting ahead of anything a remote control operator can do. And what we just saw in the video there for those of you listening is a figure two walking along this uh junkyard of wood of planks of you know and just you know almost tripping but catching itself and walking elegantly across which was pretty amazing. Uh you know it's been rumored for some time that Apple would get into the robotic business. Uh you know they went almost into the uh electric car and autonomous car business. What we're seeing here is Apple is expanding uh a new set of AI enabled devices including a tabletop robot. This is sort of a iPad on a stick that can look around. Uh they're going to go into smart speakers, AI enhanced human security cameras. Uh hopefully some type of version of Siri that can spell my name correctly. I I don't know. And the thing that frustrates me the most about Apple is I'm texting, you know, two people, their names are obviously there in the text line and they spell both names wrong. Just drives me nuts. >> Drives me nuts. >> Um I I was going to close on this article out of China and China is developing the first humanoid robot with an artificial womb. Uh this is Kawwa Technologies is creating robots and carry a fetus in a synthetic womb with fluids and nutrients. uh the cost of 14K. Maybe this is part of uh Elon's prediction of AI and technology reversing the decline in birth rate, you know, if you don't need to carry your own your own child anymore. But seriously, there's surrogate pregnancy. One of the things that's interesting and uh I'll have Ben Lamb on stage at the Abundance Summit. Ben uh is the CEO of Colossal. It's the company that's deextinguishing the woolly mammoth, direwolves, many other dodos. And in order for him to actually hit his marks, he needs to build artificial wombs. But they're not going to be carried around by a robot. They'll be stationary. They'll be physically in a room carefully guarded. >> See, >> I don't understand this carrying around bit. I mean, you know, this reminds me of Brad Templeton saying, "You have all these robot horses and people are spending huge amounts of money creating robot horses. Give me a male horse and a female horse and I'll grow you a horse." Oh my god. Uh I don't know. But I am going to read this final closing line and we'll uh maybe we'll we'll comment and break on this. This is from a guy named Dr. Singularity. I love the quote. He says, "In the 1960s, Star Trek envisioned a distant utopia, placing warp drives, replicators, advanced societies centuries away. Uh, even though even through the 80s and 2000s, the future was imaged as a slow linear march of progress. But reality no longer moves linearly. We're extremely close to having AI agents, researchers, matching the brightest human minds. Soon we'll see millions or billions of them. a Star Trek world wouldn't wait for the 2,200s. It would arrive by the 2030s. Uh, amazing prediction. And >> I think it's a great way of closing out this episode. It's exactly where we are right now. >> Yeah. And I would just, you know, I I would add Star Trek is such a strange future in the Star Trek universe. It's energy rich. They have warp drives. They're traveling around the galaxy. It's biotech poor. So longevity was outlawed in the late 1990s in the Star Trek universe. And it's AI poor. Everyone's surprised when a new AI pops out, human level or superhuman AI pops out of the holiday. Whereas I think the future and the present, frankly, that we're finding ourselves in is going to be rich and abundant in all three. >> Amazing. >> Great points. Well, after we did that Kevin Wheel interview, I I started reading the future is faster than you think again. Uh just it's in it's on my bookshelf. Why not read it again? But Peter, that's that book has so many things in it that are coming true right now. >> It's unbelievably preient and uh so I think it's worth everyone grabbing a copy and and and looking through it. It's actually much more relevant today than even when you wrote it because there's so many new converging technologies. So you have some examples in the book of technologies from I guess that was 10 years ago. Uh was it that long ago? >> No, it was it was a 19 2019. Yeah. Yeah. So, six years ago now. Uh but but so many things have happened since then. It's infinity. No, it's we're living in dog years here. It's compressed time. But there's so many things that that book predicts. It's worth worth reading again. >> See, where are you what are you doing in India, buddy? >> Uh I'm going for a bunch of conversations. The singularity summit is happening there and and um they've asked me to do the opening. Um so I'm back in country of birth uh doing running around having a bunch of meetings. I'm in like six cities in five days. It's going to be pretty ugly from my the carpentry of this is going to be pretty ugly but I mean India's it's there's just a piece of my soul that's always there. So >> I love it. Love it. Alex, what's the next week look like for you buddy? >> Oh my goodness. Well, given this flood of of AI innovations, uh just uh immersing myself in it wherever possible, uh I advise number of startups on how best to incorporate AI advances into their work streams, but really I I think smoothing out the singularity is the name of the game at this point. >> Fantastic. And and Dave, anything uh are you ending up this summer any place in particular? >> Yeah, same as Alex. I have two weeks to grind through AI models uh and finish some things and then we're back at Stamford for the you we were at Google on September 8th uh and then Nvidia that night and then Stanford all day on the next day you know 2,000 people the Blitzy launch will be then we'll we'll do the Blitzy podcast right before that and then it'll I think we'll we'll release at that same moment and then 60 backto-back startups presenting um on Stanford's campus. So, so I got a little rest bit to finish a whole bunch of AI work before all hell breaks loose the first week of September. >> All right. Well, wishing you guys an amazing end of summer here. What a great time to be alive, everybody. I hope you enjoyed this podcast. We work, you know, to give you hopefully, you know, an increased IQ bump, excitement about the future, uh give you a positive vision of where things are going. So, if you enjoy this, please let us know. Uh we love your feedback. Tell your friends. >> Next episode, more crypto because there's a ton happening there as well. >> Yeah. No, we are going to be diving more into crypto for sure. So, if you're a crypto fan, let us know who you want us to be bringing on the podcast for the conversations. Uh we're grateful for you. You know, we do this cuz we have a lot of fun. I mean, this is for us the way we keep on top of everything, actually doing the work, doing the research, discussing it here. We hope it's beneficial to you. Uh anyway, thank you gentlemen. A real pleasure and honor. Every week, my team and I study the top 10 technology meta trends that will transform industries over the decade ahead. I cover trends ranging from humanoid robotics, AGI, and quantum computing to transport, energy, longevity, and more. There's no fluff, only the most important stuff that matters, that impacts our lives, our companies, and our careers. If you want me to share these meta trends with you, I write a newsletter twice a week, sending it out as a short two-minute read via email. And if you want to discover the most important meta trends 10 years before anyone else, this report's for you. Readers include founders and CEOs from the world's most disruptive companies and entrepreneurs building the world's most disruptive tech. It's not for you if you don't want to be informed about what's coming, why it matters, and how you can benefit from it. To subscribe for free, go to dmandis.com/metats to gain access to the trends 10 years before anyone else. All right, now back to this episode. [Music]