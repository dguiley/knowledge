# I made a pro-level news app in 25 min with Gemini 3.0

Published: 2025-11-24

Gemini 3.0 just dropped and the internet is calling it the UI god. Now, I've been called a lot of things in my day, but a UI god is definitely not one of them. So, we're giving Google's new golden child exactly 25 minutes to turn me into one by cloning superhuman AI, but for news. So, 25 minutes on the clock. Let's get into it right now. So, we're going to pop over into Google's AI studio. I'm going to zoom the screen in a little bit. And we're going to come in and we're going to say clone me superhuman AI, but for an AI powered news service, it helps people digest news stories faster and get AI summaries from them. I'm going to let this thing run through for a little bit and then we are going to let the timer keep going. We're about 30 seconds in and then we will uh we will come back and check out what it did and start adding features in. All right, so that was we're about we're about 3 minutes in. So let's see what we've got. So I mean the big thing that makes superhuman what it is is all of these keyboard commands. And we can see the keyboard commands are supported. I'm just hitting J and K to move around and then I can jump into a specific news story and I can start taking some actions on it. So, looks like E maybe marks it as complete or something like that. If we hit S while we're on one of them, it's actually going to go through and it uses the built-in Gemini services, which is pretty cool to build out an actual brief for us. So, first shot from like a UI perspective, I think it's pretty nice. It's a little bit too bold in some areas and I think could be dialed a little bit. We could ask it like for example, when are we going to Mars? I don't know what type of response we would even get out of that. Context doesn't provide that answer. So, it's basing it on the news story. So, let's go through and actually start adding some features into this thing. So, we have our like our base layout right here. And this looks a little zoomed in because I am in fact zoomed in. If we go out to the full screen, it uh it looks a little bit nicer. So, what we're going to do now is we're going to come through. We're going to start just trying to add UI features into this thing. So, I have this little thing that I spun up and I said, "Hey, brainstorm me some features around these things that I know I would want in here." And so, we have this core feature set, speed of navigation, and then this AI powered intelligence where it's actually like extracting information from the story and then displaying it to us somehow. And so, I am going to go in and I'm going to tell it to do all of that. And then again, we'll pause and we'll hop back in and see what it does. But again, on the whole, I think it's done a pretty nice job so far. Um, really nice accenting. I I really like how all of this is looking. It's obviously using some like stuff that I I don't love. That's a little smells of AI, like the types of icons and things that it uses, but if we were to export this out to our own project, we'd be able to handle that. But on the whole, uh, looking pretty nice so far. Let's see what happens once we get a few more of these features. And again, we are currently about 19 minutes and 50 seconds into this or left in this shall I say. Okay, so that took like two roughly 2 and 1/2 minutes. I think we're at 17 minutes and it added in a bunch of uh a bunch of stuff. So let's go look at what we actually have. So command K pallet uh is working. So, if we hit command K, we're able to hop into different areas and look at like these categorizations of things. If we were to go into an article, we now have this option to load a deep dive analysis. We also have um some functionality up here to look at like more compact views of things, which is pretty cool. But if we say load deep dive analysis, let's see what we get out of this. Okay, so it it did what I asked, which is it gives you a context timeline. So this is like everything over recent history basically that has led up to this specific event. So in the context of the future of generative AI um it's going from you know 2023 forward to now. So again for like a basic UI mock this is cool. I though I wish this was popping out from a sidebar. So let's go in here and let's say make the additional intelligence tools load up in a right oriented sidebar instead of in the main article. Also add features for full view versus compact view verse twoliner AI wrap-up. So what I'm specifically thinking here is that I want this to have options where people can look at the entire article from different perspectives. So, while that thing is uh running, again, I'm going to pause for a second. We're about 10 minutes about 10 minutes into this thing, and I I think it's looking pretty nice so far. I would want to beef up these command K shortcuts and all of the other like keyboard shortcuts. That's stuff that we could dial in. I'm trying to really speedrun through this thing to see what we can actually build. Now, while that's running, one thing I want to show you guys that I think is part of the reason this is so so great is that it has a very good integration that typically works like OneShot with all of its builtin services. So, for example, if you want to do like AI powered image generation, it's surprisingly good at that. Um, it can use search data. It can basically use any of the Gemini APIs and it can use them in a really impressive way. It doesn't just kind of break and give you some stupid implementation of their APIs. It is really good at it. So, for example, in this app, I might want to integrate some sort of deep research using Google search data maybe so that we can actually beef up the uh capabilities in here. for example, if someone comes down and asks a question that is not in the context of the article so that it can go out and actually search for those things. But it did what I asked. It moved it into the sidebar here. And so now if we were able to uh run this thing, we should get some more insights popping out. So we can see that entire timeline. We can see like a bias detector. Um so again, pretty pretty awesome. I'm going to come through and I'm going to give it a few more features to build. So, we're going to come back in. We're going to go boom like that. We're going to send that through. And again, we're going to keep going. We're at about 11 minutes 55 seconds. We're going to see what we can really uh burn through with this thing. All right. I just found something in here that I I didn't even know was in here. But again, pretty impressive. If we click on this read button and we come through here, it actually helps us read through the article and we can speed up the words per minute, right? Right. So, we can actually like read through this thing incredibly quickly. Um, so I mean, this is pretty uh pretty cool. Now, we could hook in like the audio APIs or like voice APIs to make this so that it's actually voicing it for us or maybe making a a video or a brief of our day. Um, there's a lot of cool stuff that we could do again because it's so well integrated with all of Gemini's tools and their landscape. So, it just finished with that batch. And the thing that I like is it's going through like it's knowing to go back and actually update our command pallet each time, which is pretty cool. So, for example, we know that like H is going to be the snooze button. So, if I want to snooze this article to read later, it's just going to snooze it for me, which is pretty cool. So, I can really start flying through this stuff. Maybe I'm interested in this article about this climate bill. I can have the AI immediately summarize it and then snooze it for later so I can come back later. So, this is looking pretty cool. We also have this AI smart triage which batches and ranks article based on categories. Okay, so failed to call the API there. That's fine. But again, looking pretty awesome overall. We have this briefing section that we looked at. We have really basic summaries. If we just want to get like a oneliner, we can run the deep analysis. Again, given that we've been doing this only for about 18 minutes, I'm pretty impressed with the amount of stuff we have in here so far and how it actually looks. And so, what I'm asking it to do now is I want that in this intelligence sidebar that it actually extracts entities out of here. So, maybe there's like recurring people or events or themes or companies or locations that you want to now explore that topic further. You should be able to interact with that in some way from this sidebar. so that you can dive deeper into specific topics that you're interested in and see why exactly certain things are trending and get more of a holistic understanding of of that landscape. So, we're going to let this thing run through and then we will check it out. All right, so I've asked it to make this a little bit more compact cuz it was feeling a little bit too all over the place for me and it it did go through and do that which is nice. So, that's looking a lot nicer now. Uh if we run this deep analysis on this right hand side bar, we should be seeing a different UI in here now with the different entities and all of that type of stuff that we asked for. So we can see that now it updated the UI here for like the sentiment analysis. It gives us the context timeline and then we have this knowledge graph of like things that are related to this specific point. So, for example, if we were really interested in how this was driving electric vehicle adoption, we could click on that and then this is actually using Google's search API to go out and find other news stories related to this specific thing. So, again, this is like really awesome, the amount of really cool UIs I think that we've been able to build in just a really short amount of time. So, let's go through and see if there are any other features that we would really want to add in here. It did the speed read mode. Um, I mean, it did honestly a lot of what we asked for. So, if any of this seemed like something that we really wanted to continue adding in, uh, we could we could do that. We could build in stuff where it cross references things that seem to be contradictions and goes and like looks that up and reconciles it. we could use Google's built-in uh deep thinking capabilities again through the integrated Gemini API services. So really a lot of uh awesome stuff here that we've been able to get done again in just about 20 minutes. We build out a pretty nice looking UI. Now one thing that's still bothering me a little bit here is that I can't like I can't collapse any of these sidebars. And so I want to make it so that every se every section within the view should be slidable to expand or reduce the overall size, right? Because I don't like how it's like stuck with this column width. So I want it to be so that if I want to really read this entire AI intelligent section, I can expand it out more into the view. It lets me collapse it right now, but that's not exactly what I want. So we're going to let that thing run through and then we will take note of everything we were able to do. So we're really getting down to the wire here. I'm waiting for this thing to finish up and then I have one last thing I really want to dial in because it's bothering the out of me, which is that this smart triage doesn't work. And it should be showing the user triaged stuff right here. So, I'm hoping that we're going to be able to get this thing uh done, but it's looking like we might fail on that side of things, but only time will tell. Okay, so that just finished literally right after I paused. It looks like they did do it here where I can move this thing around. Didn't do it for this one. That's something that I could dial in. They have this little annotation feature. And so I could come through here and like annotate this and say like this should be, you know, similar to this one. I'm not going to go through and mess with that right now, but that's pretty cool that you can go and you can draw things say, "Hey, move this over here." We have this smart view filter working where someone can get like a bulleted list for example of the key points. Maybe they can choose that to be their default view. They can choose which one they want to be their default view. and then maybe they choose to expand in and read the full text if they're actually uh interested in it. So, lot of stuff that we could build on top of this, but again, I think for a 25minute exercise, we were able to build some pretty impressive looking UI that I mean could be a real um a real thing. So, the overall verdict, Gemini 3.0 is actually really pretty good, especially when used inside of a tool that is really built for it. So, Replet Designer designs really nice screens with Gemini 3.0. Google's AI studio obviously builds really nice stuff with Gemini 3.0. What I have noticed is that if you use a tool like Cursor with Gemini, not as good as you would expect it to be, but then if you look at Google's anti-gravity IDE that they just launched, it is very good with Gemini uh 3.0. So I do think that a lot of stuff is trending in this direction where we're almost getting these like full stack model providers where their stuff becomes a lot more powerful when you use their models with their tools. Claude code was the same way where people would say ah it's not really that much different when they were using it with cursor and comparing it to codeex. But if you were inside of cloud code it was a complete beast. And so I think this is the way things are trending. If you're using the model providers own tools, it seems to be getting a lot better at using their models with their stuff and you have the benefit with Google's AI studio that it has really good integrations with its own APIs. And I think that's going to be a really powerful point moving forward for everything that they build with Gemini. So, that being said, that's it for this video. 25 minutes. We built a pretty awesome looking UI. Granted, we were cloning superhuman, but still pretty dope. Now, if you want to see a video where maybe we take something like this and actually get it to the point where we could deploy it because obviously there's a lot of backend going on here, let me know in the comments below and I'll consider putting a video together about that stuff specifically. So, that's it for this video. I will see you in the next